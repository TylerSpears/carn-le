{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PITN Model Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "import ast\n",
    "\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "from pprint import pprint as ppr\n",
    "from box import Box\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "import einops\n",
    "import torchinfo\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import pitn\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = f\"direnv exec {os.getcwd()} /usr/bin/env\"\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# Will need CUDA for finding eigendecomposition of these large volumes.\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    # Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(\"CuDNN convolution optimization enabled.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"])\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup.\n",
    "\n",
    "params = Box(default_box=True)\n",
    "\n",
    "# 6 channels for the 6 DTI components\n",
    "params.n_channels = 6\n",
    "params.n_subjs = 48\n",
    "params.lr_vox_size = 2.5\n",
    "params.fr_vox_size = 1.25\n",
    "\n",
    "# Data params\n",
    "params.data.fr_dir = data_dir / f\"scale-{params.fr_vox_size:.2f}mm\"\n",
    "params.data.lr_dir = data_dir / f\"scale-{params.lr_vox_size:.2f}mm\"\n",
    "params.data.dti_fname_pattern = r\"sub-*dti.nii.gz\"\n",
    "params.data.mask_fname_pattern = r\"dti/sub-*mask.nii.gz\"\n",
    "\n",
    "# The data were downsampled artificially by this factor.\n",
    "params.data.downsampled_by_factor = params.lr_vox_size / params.fr_vox_size\n",
    "params.data.downsampled_by_factor = (\n",
    "    int(params.data.downsampled_by_factor)\n",
    "    if int(params.data.downsampled_by_factor) == params.data.downsampled_by_factor\n",
    "    else params.data.downsampled_by_factor\n",
    ")\n",
    "\n",
    "params.data.eigval_clip_cutoff = 0.00332008\n",
    "\n",
    "# Needed for downsampling shape correction.\n",
    "params.train.in_patch_size = (24, 24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Preprocess Ground Truth DTIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: Box = Box()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "    \"406432\",\n",
    "    \"803240\",\n",
    "    \"815247\",\n",
    "    \"167238\",\n",
    "    \"100408\",\n",
    "    \"792867\",\n",
    "    \"157437\",\n",
    "    \"164030\",\n",
    "    \"103515\",\n",
    "    \"118730\",\n",
    "    \"198047\",\n",
    "    \"189450\",\n",
    "    \"203923\",\n",
    "    \"108828\",\n",
    "    \"124220\",\n",
    "    \"386250\",\n",
    "    \"118124\",\n",
    "    \"701535\",\n",
    "    \"679770\",\n",
    "    \"382242\",\n",
    "    \"231928\",\n",
    "    \"196952\",  # Hold-out subject; for visualization, ensure never in the train or val sets\n",
    "    \"567961\",\n",
    "    \"910241\",\n",
    "    \"175035\",\n",
    "    \"567759\",\n",
    "    \"978578\",\n",
    "    \"150019\",\n",
    "    \"690152\",\n",
    "    \"297655\",\n",
    "    \"307127\",\n",
    "    \"634748\",\n",
    "]\n",
    "HOLDOUT_SUBJ_ID = \"196952\"\n",
    "selected_subjs = selected_ids\n",
    "selected_subjs = natsorted(selected_subjs)\n",
    "\n",
    "for subj_id in selected_subjs:\n",
    "    subj_dirs[subj_id] = Box()\n",
    "    subj_dirs[subj_id].fr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.fr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    subj_dirs[subj_id].lr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.lr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    assert subj_dirs[subj_id].fr.exists()\n",
    "    assert subj_dirs[subj_id].lr.exists()\n",
    "ppr(subj_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dict will contain all ground truth data.\n",
    "subj_gt: Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for Dataset loading.\n",
    "\n",
    "# Data reader object for NIFTI files.\n",
    "nib_reader = monai.data.NibabelReader(as_closest_canonical=True)\n",
    "\n",
    "# HR -> LR patch coordinate conversion function.\n",
    "fr2lr_patch_coords_fn = {\n",
    "    \"lr_dti\": functools.partial(\n",
    "        pitn.coords.transform.int_downscale_patch_idx,\n",
    "        downscale_factor=params.data.downsampled_by_factor,\n",
    "        downscale_patch_shape=params.train.in_patch_size,\n",
    "    )\n",
    "}\n",
    "fr2lr_patch_coords_fn[\"lr_log_euclid\"] = fr2lr_patch_coords_fn[\"lr_dti\"]\n",
    "fr2lr_patch_coords_fn[\"lr_mask\"] = fr2lr_patch_coords_fn[\"lr_dti\"]\n",
    "\n",
    "# Kwargs for the patches dataset (the _VolPatchDataset class) of the HR volumes.\n",
    "patch_kwargs = dict(\n",
    "    patch_shape=tuple(\n",
    "        np.floor(\n",
    "            np.asarray(params.train.in_patch_size) * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "    ),\n",
    "    stride=1,\n",
    "    meta_keys_to_patch_index={\"dti\", \"log_euclid\", \"mask\"},\n",
    "    mask_name=\"mask\",\n",
    ")\n",
    "\n",
    "\n",
    "# Coefficients to the log-euclidean lower triangle/6D vector that properly scales\n",
    "# the Euclidean distance under the log-euclidean metrics.\n",
    "mat_norm_coeffs = torch.ones(6)\n",
    "mat_norm_coeffs[torch.as_tensor([1, 3, 4])] = np.sqrt(2)\n",
    "mat_norm_coeffs = mat_norm_coeffs.reshape(-1, 1, 1, 1)\n",
    "\n",
    "\n",
    "def fix_downsample_shape_errors(\n",
    "    fr_vol: torch.Tensor, fr_affine: torch.Tensor, target_spatial_shape: tuple\n",
    "):\n",
    "    \"\"\"Small utility to fix shape differences between LR and FR data.\"\"\"\n",
    "    target_shape = np.asarray(target_spatial_shape)\n",
    "    if fr_vol.shape[1:] != tuple(target_shape):\n",
    "        # Use torchio objects because they fix the affine matrix, too.\n",
    "        # Flip before transform to pad on the right/top/furthest side of the dimension\n",
    "        # first, before the left/bottom/closest.\n",
    "        flip_vol = fr_vol.flip([1, 2, 3])\n",
    "        im = torchio.ScalarImage(tensor=flip_vol, affine=fr_affine)\n",
    "        transform = torchio.transforms.CropOrPad(target_spatial_shape, 0, copy=False)\n",
    "        im = transform(im)\n",
    "        result_vol = im[\"data\"]\n",
    "        # Unflip.\n",
    "        result_vol = result_vol.flip([1, 2, 3])\n",
    "        result_aff = im[\"affine\"]\n",
    "    else:\n",
    "        result_vol = fr_vol\n",
    "        result_aff = fr_affine\n",
    "\n",
    "    return result_vol, result_aff\n",
    "\n",
    "\n",
    "def orient_to_viz(vol, affine):\n",
    "\n",
    "    if torch.is_tensor(vol):\n",
    "        v = vol.detach().cpu().numpy()\n",
    "    else:\n",
    "        v = vol\n",
    "    v = np.rot90(np.rot90(v, k=1, axes=(1, 3)), k=2, axes=(2, 3))\n",
    "    if torch.is_tensor(vol):\n",
    "        v = torch.from_numpy(np.copy(v)).to(vol)\n",
    "\n",
    "    # Adjust the affine matrix.\n",
    "    full_rot_aff = np.zeros_like(affine)\n",
    "    full_rot_aff[-1, -1] = 1.0\n",
    "    # 90 degree rot around the second axis.\n",
    "    q1 = nib.quaternions.angle_axis2quat(np.pi / 2, [0, 1, 0])\n",
    "    # 180 degree rot around the first axis.\n",
    "    q2 = nib.quaternions.angle_axis2quat(np.pi, [1, 0, 0])\n",
    "    new_q = nib.quaternions.mult(q1, q2)\n",
    "    rot_aff = nib.quaternions.quat2mat(new_q)\n",
    "    full_rot_aff[:-1, :-1] = rot_aff\n",
    "    new_aff = full_rot_aff @ affine\n",
    "\n",
    "    return v, new_aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_gt = Box(default_box=True)\n",
    "\n",
    "meta_keys_to_keep = {\"affine\", \"original_affine\"}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "        data = dict()\n",
    "        data[\"subj_id\"] = subj_id\n",
    "        fr_subj_dir = subj_dirs[subj_id][\"fr\"]\n",
    "        lr_subj_dir = subj_dirs[subj_id][\"lr\"]\n",
    "        data[\"fr_subj_dir\"] = fr_subj_dir\n",
    "        data[\"lr_subj_dir\"] = lr_subj_dir\n",
    "\n",
    "        ####### Low-resolution DTIs/volumes\n",
    "        lr_dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "            lr_subj_dir, params.data.dti_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(lr_dti_f)\n",
    "        lr_dti, meta = nib_reader.get_data(im)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        lr_dti = torch.from_numpy(lr_dti)\n",
    "        lr_dti, meta[\"affine\"] = orient_to_viz(lr_dti, meta[\"affine\"])\n",
    "        data[\"lr_dti\"] = lr_dti\n",
    "        data[\"lr_dti_meta_dict\"] = meta\n",
    "\n",
    "        # May need to handle shape errors when re-upscaling back from LR to HR.\n",
    "        lr_dti_shape = np.asarray(lr_dti.shape[1:])\n",
    "        target_fr_shape = np.floor(\n",
    "            lr_dti_shape * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "\n",
    "        ####### Full-resolution images/volumes.\n",
    "        # DTI.\n",
    "        dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "            fr_subj_dir, params.data.dti_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(dti_f)\n",
    "        dti, meta = nib_reader.get_data(im)\n",
    "        dti = torch.from_numpy(dti)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        dti, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "            dti, meta[\"affine\"], target_fr_shape\n",
    "        )\n",
    "        dti, meta[\"affine\"] = orient_to_viz(dti, meta[\"affine\"])\n",
    "        data[\"dti\"] = dti\n",
    "        data[\"dti_meta_dict\"] = meta\n",
    "\n",
    "        # Diffusion mask.\n",
    "        mask_f = pitn.utils.system.get_file_glob_unique(\n",
    "            fr_subj_dir, params.data.mask_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(mask_f)\n",
    "        mask, meta = nib_reader.get_data(im)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        mask = torch.from_numpy(mask)\n",
    "        # Add channel dim if not available.\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask[None]\n",
    "        mask, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "            mask, meta[\"affine\"], target_fr_shape\n",
    "        )\n",
    "        mask, meta[\"affine\"] = orient_to_viz(mask, meta[\"affine\"])\n",
    "        mask = mask.bool()\n",
    "        data[\"mask\"] = mask\n",
    "        data[\"mask_meta_dict\"] = meta\n",
    "\n",
    "        # Construct a quick and cheap mask for the LR DTI\n",
    "        cheap_lr_mask = F.interpolate(\n",
    "            data[\"mask\"][None].float(),\n",
    "            size=data[\"lr_dti\"][0].shape,\n",
    "            mode=\"nearest\",\n",
    "        )[0]\n",
    "        data[\"lr_mask\"] = cheap_lr_mask.bool()\n",
    "\n",
    "        # Consider this as the \"noise correction\" step to have more informative, consistent\n",
    "        # results with minimal biasing. Otherwise, outliers (which are clearly errors) can\n",
    "        # change loss and performance metrics by orders of magnitude for no good reason!\n",
    "        if \"eigval_clip_cutoff\" in params.data and params.data.eigval_clip_cutoff:\n",
    "            correct_dti = pitn.data.outliers.clip_dti_eigvals(\n",
    "                data[\"dti\"].to(device),\n",
    "                tensor_components_dim=0,\n",
    "                eigval_max=params.data.eigval_clip_cutoff,\n",
    "            ).to(data[\"dti\"])\n",
    "            correct_dti = correct_dti * data[\"mask\"]\n",
    "            ####\n",
    "            # sae_fr = (\n",
    "            #     F.l1_loss(data[\"dti\"], correct_dti, reduction=\"none\") * data[\"mask\"]\n",
    "            # )\n",
    "            # sae_fr = sae_fr.view(6, -1).sum(1)\n",
    "            # mae_fr = sae_fr / torch.count_nonzero(data[\"mask\"])\n",
    "            # print(f\"---Subj {subj_id}---\")\n",
    "            # print(\n",
    "            #     \"MAE of FR DTI after eigenvalue clipping:\\n\",\n",
    "            #     mae_fr.tolist(),\n",
    "            # )\n",
    "            ####\n",
    "            data[\"dti\"] = correct_dti\n",
    "\n",
    "            correct_lr_dti = pitn.data.outliers.clip_dti_eigvals(\n",
    "                data[\"lr_dti\"].to(device),\n",
    "                tensor_components_dim=0,\n",
    "                eigval_max=params.data.eigval_clip_cutoff,\n",
    "            ).to(data[\"lr_dti\"])\n",
    "            lr_mask = data[\"lr_mask\"]\n",
    "            correct_lr_dti = correct_lr_dti * lr_mask\n",
    "            ####\n",
    "            # sae_lr = (\n",
    "            #     F.l1_loss(data[\"lr_dti\"], correct_lr_dti, reduction=\"none\") * lr_mask\n",
    "            # )\n",
    "            # sae_lr = sae_lr.view(6, -1).sum(1)\n",
    "            # mae_lr = sae_lr / torch.count_nonzero(lr_mask)\n",
    "            # print(\n",
    "            #     \"MAE of LR DTI after eigenvalue clipping:\\n\",\n",
    "            #     mae_lr.tolist(),\n",
    "            # )\n",
    "            ####\n",
    "            data[\"lr_dti\"] = correct_lr_dti\n",
    "\n",
    "        ####### Log-euclid pre-computed volumes\n",
    "\n",
    "        # LR log-euclid volume.\n",
    "        lr_log_euclid = pitn.eig.tril_vec2sym_mat(data[\"lr_dti\"], tril_dim=0)\n",
    "        lr_log_euclid = pitn.riemann.log_euclid.log_map(lr_log_euclid)\n",
    "        lr_log_euclid = pitn.eig.sym_mat2tril_vec(lr_log_euclid, tril_dim=0)\n",
    "        lr_log_euclid = lr_log_euclid * mat_norm_coeffs\n",
    "        data[\"lr_log_euclid\"] = lr_log_euclid\n",
    "\n",
    "        log_euclid = pitn.eig.tril_vec2sym_mat(data[\"dti\"], tril_dim=0)\n",
    "        log_euclid = pitn.riemann.log_euclid.log_map(log_euclid)\n",
    "        log_euclid = pitn.eig.sym_mat2tril_vec(log_euclid, tril_dim=0)\n",
    "        log_euclid = log_euclid * mat_norm_coeffs\n",
    "        data[\"log_euclid\"] = log_euclid\n",
    "\n",
    "        # Pre-compute FA maps\n",
    "        fa = pitn.metrics.fast_fa(\n",
    "            data[\"dti\"][None].to(device), foreground_mask=data[\"mask\"][None].to(device)\n",
    "        )\n",
    "        fa = fa.to(data[\"dti\"])[0]\n",
    "        data[\"fa\"] = fa\n",
    "\n",
    "        # Finalize this subject.\n",
    "        subj_gt[subj_id] = data\n",
    "        print(\"Loaded Subject \", subj_id)\n",
    "        print(\"=\" * 20)\n",
    "\n",
    "print(\"===Data Loaded===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Aggregate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only choose subjects in the training and validation datasets.\n",
    "\n",
    "subj_agg_stats = Box(default_box=True)\n",
    "subj_agg_stats.dti.min = torch.zeros(params.n_channels).to(subj_gt[selected_ids[0]].dti)\n",
    "subj_agg_stats.dti.max = torch.zeros(params.n_channels).to(subj_agg_stats.dti.min)\n",
    "\n",
    "subj_agg_stats.log_euclid.min = subj_agg_stats.dti.min\n",
    "subj_agg_stats.log_euclid.max = subj_agg_stats.dti.max\n",
    "\n",
    "for s in subj_gt.values():\n",
    "    fr_mask = s.mask\n",
    "    dti = torch.masked_select(s.dti, fr_mask)\n",
    "    subj_agg_stats.dti.min = torch.minimum(\n",
    "        subj_agg_stats.dti.min, dti.view(params.n_channels, -1).min(-1).values\n",
    "    )\n",
    "    subj_agg_stats.dti.max = torch.maximum(\n",
    "        subj_agg_stats.dti.max, dti.view(params.n_channels, -1).max(-1).values\n",
    "    )\n",
    "\n",
    "    lr_dti = s.lr_dti\n",
    "    lr_mask = s.lr_mask\n",
    "    lr_dti = torch.masked_select(lr_dti, lr_mask)\n",
    "    subj_agg_stats.dti.min = torch.minimum(\n",
    "        subj_agg_stats.dti.min, lr_dti.view(params.n_channels, -1).min(-1).values\n",
    "    )\n",
    "    subj_agg_stats.dti.max = torch.maximum(\n",
    "        subj_agg_stats.dti.max, lr_dti.view(params.n_channels, -1).max(-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "print(subj_agg_stats.dti.min)\n",
    "print(subj_agg_stats.dti.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate global ranges of data for PSNR calculations.\n",
    "\n",
    "expander = functools.partial(einops.rearrange, pattern=\"c -> 1 c 1 1 1\")\n",
    "# Collect DTI global data features.\n",
    "dti_min = expander(subj_agg_stats.dti.min)\n",
    "dti_max = expander(subj_agg_stats.dti.max)\n",
    "\n",
    "feat_min, feat_max = torch.as_tensor(\n",
    "    [\n",
    "        [0] * 6,\n",
    "        [1] * 6,\n",
    "    ]\n",
    ")\n",
    "feat_min = expander(feat_min)\n",
    "feat_max = expander(feat_max)\n",
    "\n",
    "# PSNR is calculated on the final output tensor components, so no log-euclidean or\n",
    "# scaling will occur here.\n",
    "psnr_range_params = pitn.data.norm.GlobalScaleParams(\n",
    "    feature_min=feat_min, feature_max=feat_max, data_min=dti_min, data_max=dti_max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select & Describe Models for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def col_params_from_log(log_file: Path):\n",
    "#     with open(Path(log_file), \"r\") as f:\n",
    "#         p_str = list()\n",
    "#         params = dict(\n",
    "#             use_anat=False, use_half_precision_float=False, use_log_euclid=False\n",
    "#         )\n",
    "#         # 'use_anat': False,\n",
    "#         # 'use_half_precision_float': False,\n",
    "#         # 'use_log_euclid': False,\n",
    "\n",
    "#         search_line = False\n",
    "#         for line in f.readlines():\n",
    "#             if \"hardware\" in line.casefold():\n",
    "#                 break\n",
    "\n",
    "#             if search_line:\n",
    "#                 found_key = None\n",
    "#                 for k in params.keys():\n",
    "#                     if k in line:\n",
    "#                         found_key = k\n",
    "#                         break\n",
    "#                 if found_key is not None:\n",
    "#                     v_str = line[line.index(\":\") + 1 :]\n",
    "#                     v_str = (\n",
    "#                         v_str.strip()\n",
    "#                         .replace(\",\", \"\")\n",
    "#                         .replace(\"[\", \"\")\n",
    "#                         .replace(\"]\", \"\")\n",
    "#                         .replace(\"{\", \"\")\n",
    "#                         .replace(\"}\", \"\")\n",
    "#                     )\n",
    "#                     v = ast.literal_eval(v_str)\n",
    "#                     params[k] = v\n",
    "\n",
    "#             if \"timestamp\" in line.casefold():\n",
    "#                 search_line = True\n",
    "\n",
    "#     return params\n",
    "\n",
    "def run_params_from_config(run_config_file: Path) -> dict:\n",
    "    config_f = Path(run_config_file).resolve()\n",
    "    with open(config_f, \"r\") as f:\n",
    "        config_str = f.read()\n",
    "    config = ast.literal_eval(config_str)\n",
    "    # Clean up any recursive weirdness.\n",
    "    config = Box(config).to_dict()\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_spline_runs = []\n",
    "baseline_espcn_runs = []\n",
    "baseline_revnet_runs = [\n",
    "    \"2022-03-22T11_07_32__uvers_espcn_revnet_split_1\",\n",
    "    \"2022-03-22T11_07_32__uvers_espcn_revnet_split_2\",\n",
    "    \"2022-03-23T04_03_59__uvers_espcn_revnet_split_3\",\n",
    "]\n",
    "diqt_carn_single_stream_runs = []\n",
    "diqt_carn_anat_stream_runs = [\n",
    "    \"2022-03-22T21_33_49__uvers_pitn_anat_stream_dti_split_1\",\n",
    "    \"2022-03-24T03_22_55__uvers_pitn_anat_stream_dti_split_2\",\n",
    "    \"2022-03-23T17_25_43__uvers_pitn_anat_stream_le_split_1\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"run_name\", \"model_name\", \"use_le\", \"use_anat\", \"use_half_precision\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02b6fbf192f5f02a9e4be2e8493e981ac4440e63c59c4307b81de14e51e6a1b0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
