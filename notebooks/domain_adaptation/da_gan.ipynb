{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13edb204-c964-4525-80d8-0fdd2730df3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pain in the Net - Laplacian Pyramid Translation Network (LPTN)\n",
    "Application of Laplacian Pyramid Translation Network (LPTN) to domain adaptation of diffusion MRI.\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "Based on the following work(s):\n",
    "\n",
    "* `J. Liang, H. Zeng, and L. Zhang, “High-Resolution Photorealistic Image Translation in Real-Time: A Laplacian Pyramid Translation Network,” 2021, pp. 9392–9400. Accessed: Aug. 26, 2021. [Online]. Available: https://openaccess.thecvf.com/content/CVPR2021/html/Liang_High-Resolution_Photorealistic_Image_Translation_in_Real-Time_A_Laplacian_Pyramid_Translation_CVPR_2021_paper.html\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03c5c0-aea8-4c1c-98ca-bf001e59dde2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f91f0-eca2-4990-9214-f34aa16b4d05",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bbe9cc-5b3f-4204-870d-4a5bc5f28aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import ants\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dipy.viz\n",
    "import dipy.viz.regtools\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython\n",
    "\n",
    "# Try importing GPUtil for printing GPU specs.\n",
    "# May not be installed if using CPU only.\n",
    "try:\n",
    "    import GPUtil\n",
    "except ImportError:\n",
    "    warnings.warn(\"WARNING: Package GPUtil not found, cannot print GPU specs\")\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, Markdown\n",
    "import ipyplot\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "import addict\n",
    "from addict import Addict\n",
    "import box\n",
    "from box import Box\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8326b-55e1-4195-a85f-7627f591f1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8449ea-9648-4517-8aab-7e85308436de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-specific scripts\n",
    "# It's easier to import it this way rather than make an entirely new package, due to\n",
    "# conflicts with local packages and anaconda installations.\n",
    "# You made me do this, poor python package management!!\n",
    "if \"PROJECT_ROOT\" in os.environ:\n",
    "    lib_location = str(Path(os.environ[\"PROJECT_ROOT\"]).resolve())\n",
    "else:\n",
    "    lib_location = str(Path(\"../../\").resolve())\n",
    "if lib_location not in sys.path:\n",
    "    sys.path.insert(0, lib_location)\n",
    "import lib as pitn\n",
    "\n",
    "# Include the top-level lib module along with its submodules.\n",
    "%aimport lib\n",
    "# Grab all submodules of lib, not including modules outside of the package.\n",
    "includes = list(\n",
    "    filter(\n",
    "        lambda m: m.startswith(\"lib.\"),\n",
    "        map(lambda x: x[1].__name__, inspect.getmembers(pitn, inspect.ismodule)),\n",
    "    )\n",
    ")\n",
    "# Run aimport magic with constructed includes.\n",
    "ipy = IPython.get_ipython()\n",
    "ipy.run_line_magic(\"aimport\", \", \".join(includes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a706635-b544-4f41-886b-d6997dda27e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498af6cf-4263-4415-b6f3-fd32abab4bcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2952b-b4a3-4241-9322-e317c32cb2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # GPU information\n",
    "    # Taken from\n",
    "    # <https://www.thepythoncode.com/article/get-hardware-system-information-python>.\n",
    "    # If GPUtil is not installed, skip this step.\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        print(\"=\" * 50, \"GPU Specs\", \"=\" * 50)\n",
    "        list_gpus = []\n",
    "        for gpu in gpus:\n",
    "            # get the GPU id\n",
    "            gpu_id = gpu.id\n",
    "            # name of GPU\n",
    "            gpu_name = gpu.name\n",
    "            driver_version = gpu.driver\n",
    "            cuda_version = torch.version.cuda\n",
    "            # get total memory\n",
    "            gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "            gpu_uuid = gpu.uuid\n",
    "            list_gpus.append(\n",
    "                (\n",
    "                    gpu_id,\n",
    "                    gpu_name,\n",
    "                    driver_version,\n",
    "                    cuda_version,\n",
    "                    gpu_total_memory,\n",
    "                    gpu_uuid,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            tabulate(\n",
    "                list_gpus,\n",
    "                headers=(\n",
    "                    \"id\",\n",
    "                    \"Name\",\n",
    "                    \"Driver Version\",\n",
    "                    \"CUDA Version\",\n",
    "                    \"Total Memory\",\n",
    "                    \"uuid\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae38f0a-8614-4e0d-a40a-bee5a3585baa",
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2021-09-20T15:11:42.902698+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-84-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 4281c55c802880d2c05bbb8802c05e0b93820076\n",
      "\n",
      "ipywidgets       : 7.6.3\n",
      "nibabel          : 3.2.1\n",
      "pandas           : 1.2.3\n",
      "monai            : 0.5.dev2114\n",
      "dipy             : 1.4.1\n",
      "skimage          : 0.18.1\n",
      "json             : 2.0.9\n",
      "seaborn          : 0.11.1\n",
      "natsort          : 7.1.1\n",
      "GPUtil           : 1.4.0\n",
      "matplotlib       : 3.4.1\n",
      "numpy            : 1.20.2\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "IPython          : 7.23.1\n",
      "addict           : 2.4.0\n",
      "pytorch_lightning: 1.4.5\n",
      "kornia           : 0.5.8\n",
      "torch            : 1.9.0\n",
      "ants             : 0.2.7\n",
      "torchio          : 0.18.37\n",
      "scipy            : 1.5.3\n",
      "\n",
      "================================================== GPU Specs ==================================================\n",
      "  id  Name       Driver Version      CUDA Version  Total Memory    uuid\n",
      "----  ---------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  TITAN RTX  460.91.03                   11.1  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09447c83-298e-444a-91ca-aa46058eb956",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41112b-67dc-4fa3-828e-48a2c88dfb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"]) / \"hcp\"\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"]) / \"hcp\"\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a7233-48c1-439d-af3f-62f628af527c",
   "metadata": {},
   "source": [
    "### Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fdc6f9-42fc-4ce6-905e-c938b89edb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = \"debug_da_gan\"\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "print(experiment_name)\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 3\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6460c-da7e-4391-980a-344508313cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009ab0f-71cd-4692-8722-e6fa947366d1",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c38643-d251-47ed-b263-246514d43c4b",
   "metadata": {},
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e19e98-9483-42ea-a147-fad00be6d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subject_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac5a22-bd1a-41e3-ac99-3d4cdb1ee14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: dict = dict()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "selected_ids = random.sample(selected_ids, num_subject_samples)\n",
    "warnings.warn(\n",
    "    \"WARNING: Sub-selecting participants for dev and debugging. \"\n",
    "    + f\"Subj IDs selected: {selected_ids}\"\n",
    ")\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_ids = natsorted(list(map(lambda s: int(s), selected_ids)))\n",
    "\n",
    "for subj_id in selected_ids:\n",
    "    subj_dirs[subj_id] = data_dir / f\"{subj_id}/T1w/Diffusion\"\n",
    "    assert subj_dirs[subj_id].exists()\n",
    "subj_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5408d-5934-44cc-9aba-01df3461e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to file and experiment.\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ea665-dc8b-45b8-be6f-b9cc3c5f62b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b0e95b7-85fb-4646-a4e6-9c81398f9ba2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438abc8b-9316-4d91-94ab-62db24b012ef",
   "metadata": {},
   "source": [
    "## LPTN Generator Testing & Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e7070-4c8e-44ff-bbe5-9e3779d9cc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hardi_fname, hardi_bval_fname, hardi_bvec_fname = dipy.data.get_fnames(\"stanford_hardi\")\n",
    "label_fname = dipy.data.get_fnames(\"stanford_labels\")\n",
    "\n",
    "data, affine, hardi_img = dipy.io.image.load_nifti(hardi_fname, return_img=True)\n",
    "# Move channels to first dimension.\n",
    "data = data.transpose(3, 0, 1, 2)\n",
    "labels = dipy.io.image.load_nifti_data(label_fname)\n",
    "bvals, bvecs = dipy.io.gradients.read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
    "gtab = dipy.core.gradients.gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f77388-db34-49b0-afb5-e9a528206807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = data[0]\n",
    "x = torch.from_numpy(x).float()\n",
    "print(x.shape)\n",
    "divisible_target = 2 ** 3\n",
    "data_shape = torch.as_tensor(x.shape).float()\n",
    "print(divisible_target - (data_shape % divisible_target))\n",
    "pad_pre = torch.floor((divisible_target - (data_shape % divisible_target)) / 2).int()\n",
    "pad_pre = reversed(pad_pre.tolist())\n",
    "pad_post = torch.ceil((divisible_target - (data_shape % divisible_target)) / 2).int()\n",
    "pad_post = reversed(pad_post.tolist())\n",
    "x = F.pad(x, tuple(itertools.chain.from_iterable(zip(pad_pre, pad_post))))\n",
    "print(torch.as_tensor(x.shape) % divisible_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30614e83-b734-4686-b8ad-4af3805757ca",
   "metadata": {},
   "source": [
    "### Laplacian Pyramid Decomposotion + Reconstruction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8debd2-2aeb-4d98-9062-bd8dbd1011c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyramid = pitn.nn.layers.LaplacePyramid3d(3)\n",
    "hf, residual = pyramid.decompose(x)\n",
    "x_recon = pyramid.reconstruct(hf, residual)\n",
    "print(torch.sqrt(F.mse_loss(x, x_recon[0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac313e-d914-4a55-8215-0d3f156f36c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(x[:, 50].cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_recon[0, 0, :, 50].cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x[:, 50].cpu().numpy() - x_recon[0, 0, :, 50].cpu().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288345b2-4d3e-4354-af4e-1f30b33f6e69",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LPTN Translation Network Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d93e6-0be9-4ed5-ad64-a3429cef6040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = pitn.nn.gan.generative.LPTN(6, 3)\n",
    "y = net(x.repeat(4, 6, 1, 1, 1))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e294b-90b2-4447-a9e8-eb088569f56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    dipy.viz.regtools.overlay_slices(\n",
    "        x.detach().numpy(), y[0, 0].detach().numpy(), slice_type=i\n",
    "    ).set_dpi(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca986b-3805-4d13-989c-2d987d985a9a",
   "metadata": {},
   "source": [
    "## LPTN Discriminator Network Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15a74b-8304-48d6-96f8-8f3fe8a78c59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discrim = pitn.nn.gan.adversarial.MultiDiscriminator(6)\n",
    "y = discrim(x.repeat(4, 6, 1, 1, 1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16849ff8-252a-4754-82fc-05a62fc4246d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49101a65-8de8-4e51-b935-0950ce3c5393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClinicMatchGAN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels: int,\n",
    "        gen_num_high_freq: int = 3,\n",
    "        discriminator_downsample_factors=[1, 2, 4],\n",
    "        lambda_adversary_loss: float = 0.1,\n",
    "        lr=0.001,\n",
    "        betas=(0.9, 0.999),\n",
    "    ):\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.generator = pitn.nn.gan.generative.LPTN(\n",
    "            num_channels, num_high_freq_levels=self.hparams.gen_num_high_freq\n",
    "        )\n",
    "\n",
    "        self.discriminator = pitn.nn.gan.adversarial.MultiDiscriminator(\n",
    "            num_channels, self.hparams.discriminator_downsample_factors\n",
    "        )\n",
    "\n",
    "        self.plain_log = Box(loss_gen = Box(), loss_discrim = Box())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "    def reconstruction_loss(self, y_source, y_pred):\n",
    "        return F.mse_loss(y_source, y_pred, reduction=\"sum\")\n",
    "\n",
    "    def gen_adversarial_loss(self, source_sample):\n",
    "        y_hat = self.generator(source_sample)\n",
    "        return F.mse_loss(self.discriminator(y_hat), 1)\n",
    "\n",
    "    def discriminator_adversarial_loss(self, source_sample, target_sample):\n",
    "        real_sample_loss = F.mse_loss(self.discriminator(target_sample), 1)\n",
    "        fake_sample = self.generator(source_sample)\n",
    "        fake_sample_loss = F.mse_loss(self.discriminator(fake_sample), 0)\n",
    "\n",
    "        return real_sample_loss + fake_sample_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        source_samples, target_samples = batch\n",
    "\n",
    "        # Optimizer index decides whether this step updates the generator or discriminator.\n",
    "        if optimizer_idx == self._GENERATOR_OPTIMIZER_IDX:\n",
    "            translated_samples = self.generator(source_samples)\n",
    "            l_g_reconstruct = self.reconstruction_loss(source_samples, translated_samples)\n",
    "\n",
    "            l_g_adversarial = self.gen_adversarial_loss(source_samples)\n",
    "\n",
    "            loss = l_g_reconstruct + (l_g_adversarial * self.hparams.lambda_adversary_loss)\n",
    "\n",
    "        elif optimizer_idx == self._DISCRIMINATOR_OPTIMIZER_IDX:\n",
    "            # Translated (i.e., fake) images\n",
    "            loss = self.discriminator_adversarial_loss(source_samples, target_samples)\n",
    "            \n",
    "        else:\n",
    "            raise RuntimeError(f\"ERROR: Invalid optimizer index {optimizer_idx}\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        betas = self.hparams.betas\n",
    "\n",
    "        opt_gen = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=betas)\n",
    "        opt_discriminator = torch.optim.Adam(\n",
    "            self.discriminator.paramters(), lr=lr, betas=betas\n",
    "        )\n",
    "\n",
    "        self._GENERATOR_OPTIMIZER_IDX = 0\n",
    "        self._DISCRIMINATOR_OPTIMIZER_IDX = 1\n",
    "        return [opt_gen, opt_discriminator], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf09a7-9301-4489-a28f-8eee21353faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
