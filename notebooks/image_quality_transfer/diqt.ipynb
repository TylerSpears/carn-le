{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pain in the Net\n",
    "Application of Deep Image Quality Transfer (DIQT) with domain adaptation.\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "References:\n",
    "\n",
    "* `R. Tanno et al., “Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion MRI,” NeuroImage, vol. 225, p. 117366, Jan. 2021, doi: 10.1016/j.neuroimage.2020.117366.`\n",
    "* `D. C. Alexander et al., “Image quality transfer and applications in diffusion MRI,” NeuroImage, vol. 152, pp. 283–298, May 2017, doi: 10.1016/j.neuroimage.2017.02.089.`\n",
    "* `S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipyplot\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "from addict import Addict\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "import box\n",
    "from box import Box\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import pitn\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "    # GPU information\n",
    "    try:\n",
    "        gpu_info = pitn.utils.system.get_gpu_specs()\n",
    "        print(gpu_info)\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"])\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = \"debug_diqt_spline_baseline\"\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 3\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = Box(default_box=True)\n",
    "\n",
    "# General experiment-wide params\n",
    "# 6 channels for the 6 DTI components\n",
    "params.n_channels = 6\n",
    "params.n_subjs = 15\n",
    "params.lr_vox_size = 2.5\n",
    "params.fr_vox_size = 1.25\n",
    "params.use_anat = True\n",
    "\n",
    "# Data params\n",
    "params.data.fr_dir = data_dir / f\"scale-{params.fr_vox_size:.2f}mm\"\n",
    "params.data.lr_dir = data_dir / f\"scale-{params.lr_vox_size:.2f}mm\"\n",
    "params.data.dti_fname_pattern = r\"sub-*dti.nii.gz\"\n",
    "params.data.mask_fname_pattern = r\"dti/sub-*mask.nii.gz\"\n",
    "params.data.anat_type = \"t2w\"\n",
    "params.data.anat_fname_pattern = f\"sub-*{params.data.anat_type}.nii.gz\"\n",
    "# The data were downsampled artificially by this factor.\n",
    "params.data.downsampled_by_factor = params.lr_vox_size / params.fr_vox_size\n",
    "params.data.downsampled_by_factor = (\n",
    "    int(params.data.downsampled_by_factor)\n",
    "    if int(params.data.downsampled_by_factor) == params.data.downsampled_by_factor\n",
    "    else params.data.downsampled_by_factor\n",
    ")\n",
    "\n",
    "# This is the number of voxels to remove (read: center crop out) from the network's\n",
    "# prediction. This allows for an \"oversampling\" of the low-res voxels to help inform a\n",
    "# more constrained HR prediction. This value of voxels will be removed from each spatial\n",
    "# dimension (D, H, and W) starting at the center of the output patches.\n",
    "# Ex. A size of 1 will remove the 2 outer-most voxels from each dimension in the output,\n",
    "# while still keeping the corresponding voxels in the LR input.\n",
    "params.hr_center_crop_per_side = 0\n",
    "\n",
    "# Scale input data by the valid values of each channel of the DTI.\n",
    "# I.e., Dx,x in [0, 1], Dx,y in [-1, 1], Dy,y in [0, 1], Dy,z in [-1, 1], etc.\n",
    "params.data.dti_scale_range = ((0, -1, 0, -1, -1, 0), (1, 1, 1, 1, 1, 1))\n",
    "params.data.anat_scale_range = (0, 1)\n",
    "params.data.scale_quantile_clip = (0.01, 0.99)\n",
    "\n",
    "# Network params.\n",
    "# The network's goal is to upsample the input by this factor.\n",
    "params.net.upscale_factor = params.data.downsampled_by_factor\n",
    "params.net.kwargs.n_res_units = 3\n",
    "params.net.kwargs.n_dense_units = 3\n",
    "params.net.kwargs.activate_fn = F.elu\n",
    "params.net.kwargs.upsample_activate_fn = F.elu\n",
    "params.net.kwargs.center_crop_output_side_amt = params.hr_center_crop_per_side\n",
    "\n",
    "# Adam optimizer kwargs\n",
    "params.optim.name = \"AdamW\"\n",
    "params.optim.kwargs.lr = 1e-3\n",
    "params.optim.kwargs.betas = (0.9, 0.999)\n",
    "\n",
    "# Testing params\n",
    "params.test.dataset_subj_percent = 0.5\n",
    "\n",
    "# Validation params\n",
    "params.val.dataset_subj_percent = 0.01\n",
    "\n",
    "# Training params\n",
    "params.train.in_patch_size = (24, 24, 24)\n",
    "params.train.batch_size = 64\n",
    "params.train.samples_per_subj_per_epoch = 4000\n",
    "params.train.max_epochs = 100\n",
    "params.train.loss_name = \"mse\"\n",
    "# Percentage of subjs in dataset that go into the training set.\n",
    "params.train.dataset_subj_percent = 1 - (\n",
    "    params.test.dataset_subj_percent + params.val.dataset_subj_percent\n",
    ")\n",
    "\n",
    "# If a config file exists, override the defaults with those values.\n",
    "try:\n",
    "    config_fname = pitn.utils.system.get_file_glob_unique(Path(\".\"), r\"config.*\")\n",
    "    f_type = config_fname.suffix.casefold()\n",
    "    if f_type in {\"yaml\", \"yml\"}:\n",
    "        f_params = Box.from_yaml(config_fname)\n",
    "    elif f_type == \"json\":\n",
    "        f_params = Box.from_json(config_fname)\n",
    "    elif f_type == \"toml\":\n",
    "        f_params = Box.from_toml(config_fname)\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    params.merge_update(f_params)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Remove the default_box behavior now that params have been fully read in.\n",
    "p = Box(default_box=False)\n",
    "p.merge_update(params)\n",
    "params = p\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(pprint.pformat(params.to_dict()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose a subset of all params as the hyperparams of the model.\n",
    "hyperparams = dict(\n",
    "    batch_size=params.train.batch_size,\n",
    "    samples_per_subj_epoch=params.train.samples_per_subj_per_epoch,\n",
    "    epochs=params.train.max_epochs,\n",
    "    loss_fn=params.train.loss_name,\n",
    "    lr=params.optim.kwargs.lr,\n",
    "    optim=params.optim.name,\n",
    "    anat=params.data.anat_type if params.use_anat else False,\n",
    "    n_subjs=params.n_subjs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: Box = Box()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "sampled_subjs = random.sample(selected_ids, params.n_subjs)\n",
    "if len(sampled_subjs) < len(selected_ids):\n",
    "    warnings.warn(\n",
    "        f\"WARNING: Sub-selecting {len(sampled_subjs)}/{len(selected_ids)} \"\n",
    "        + \"participants for dev and debugging. \"\n",
    "        + f\"Subj IDs selected: {sampled_subjs}\"\n",
    "    )\n",
    "selected_subjs = sampled_subjs\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_subjs = natsorted(selected_subjs)\n",
    "\n",
    "for subj_id in selected_subjs:\n",
    "    subj_dirs[subj_id] = Box()\n",
    "    subj_dirs[subj_id].fr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.fr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    subj_dirs[subj_id].lr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.lr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    assert subj_dirs[subj_id].fr.exists()\n",
    "    assert subj_dirs[subj_id].lr.exists()\n",
    "ppr(subj_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep for Dataset loading.\n",
    "\n",
    "# Data reader object for NIFTI files.\n",
    "nib_reader = monai.data.NibabelReader(as_closest_canonical=True)\n",
    "\n",
    "# HR -> LR patch coordinate conversion function.\n",
    "fr2lr_patch_coords_fn = {\n",
    "    \"lr_dti\": functools.partial(\n",
    "        pitn.coords.transform.int_downscale_patch_idx,\n",
    "        downscale_factor=params.data.downsampled_by_factor,\n",
    "        downscale_patch_shape=params.train.in_patch_size,\n",
    "    )\n",
    "}\n",
    "\n",
    "# Kwargs for the patches dataset (the _VolPatchDataset class) of the HR volumes.\n",
    "patch_kwargs = dict(\n",
    "    patch_shape=tuple(\n",
    "        np.floor(\n",
    "            np.asarray(params.train.in_patch_size) * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "    ),\n",
    "    stride=1,\n",
    "    meta_keys_to_patch_index={\"dti\", \"mask\", params.data.anat_type},\n",
    "    mask_name=\"mask\",\n",
    ")\n",
    "\n",
    "\n",
    "def fix_downsample_shape_errors(\n",
    "    fr_vol: torch.Tensor, fr_affine: torch.Tensor, target_spatial_shape: tuple\n",
    "):\n",
    "    \"\"\"Small utility to fix shape differences between LR and FR data.\"\"\"\n",
    "    target_shape = np.asarray(target_spatial_shape)\n",
    "    if fr_vol.shape[1:] != tuple(target_shape):\n",
    "        # Use torchio objects because they fix the affine matrix, too.\n",
    "        # Flip before transform to pad on the right/top/furthest side of the dimension\n",
    "        # first, before the left/bottom/closest.\n",
    "        flip_vol = fr_vol.flip([1, 2, 3])\n",
    "        im = torchio.ScalarImage(tensor=flip_vol, affine=fr_affine)\n",
    "        transform = torchio.transforms.CropOrPad(target_spatial_shape, 0, copy=False)\n",
    "        im = transform(im)\n",
    "        result_vol = im[\"data\"]\n",
    "        # Unflip.\n",
    "        result_vol = result_vol.flip([1, 2, 3])\n",
    "        result_aff = im[\"affine\"]\n",
    "    else:\n",
    "        result_vol = fr_vol\n",
    "        result_aff = fr_affine\n",
    "\n",
    "    return result_vol, result_aff\n",
    "\n",
    "\n",
    "def orient_to_viz(vol, affine):\n",
    "\n",
    "    if torch.is_tensor(vol):\n",
    "        v = vol.detach().cpu().numpy()\n",
    "    else:\n",
    "        v = vol\n",
    "    v = np.rot90(np.rot90(v, k=1, axes=(1, 3)), k=2, axes=(2, 3))\n",
    "    if torch.is_tensor(vol):\n",
    "        v = torch.from_numpy(np.copy(v)).to(vol)\n",
    "\n",
    "    # Adjust the affine matrix.\n",
    "    full_rot_aff = np.zeros_like(affine)\n",
    "    full_rot_aff[-1, -1] = 1.0\n",
    "    # 90 degree rot around the second axis.\n",
    "    q1 = nib.quaternions.angle_axis2quat(np.pi / 2, [0, 1, 0])\n",
    "    # 180 degree rot around the first axis.\n",
    "    q2 = nib.quaternions.angle_axis2quat(np.pi, [1, 0, 0])\n",
    "    new_q = nib.quaternions.mult(q1, q2)\n",
    "    rot_aff = nib.quaternions.quat2mat(new_q)\n",
    "    full_rot_aff[:-1, :-1] = rot_aff\n",
    "    new_aff = full_rot_aff @ affine\n",
    "\n",
    "    return v, new_aff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and organize all data.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "meta_keys_to_keep = {\"affine\", \"original_affine\"}\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "    data = dict()\n",
    "    data[\"subj_id\"] = subj_id\n",
    "    fr_subj_dir = subj_dirs[subj_id][\"fr\"]\n",
    "    lr_subj_dir = subj_dirs[subj_id][\"lr\"]\n",
    "    data[\"fr_subj_dir\"] = fr_subj_dir\n",
    "    data[\"lr_subj_dir\"] = lr_subj_dir\n",
    "\n",
    "    # Low-resolution DTI.\n",
    "    lr_dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        lr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(lr_dti_f)\n",
    "    lr_dti, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    lr_dti = torch.from_numpy(lr_dti)\n",
    "    lr_dti, meta[\"affine\"] = orient_to_viz(lr_dti, meta[\"affine\"])\n",
    "    data[\"lr_dti\"] = lr_dti\n",
    "    data[\"lr_dti_meta_dict\"] = meta\n",
    "\n",
    "    # May need to handle shape errors when re-upscaling back from LR to HR.\n",
    "    lr_dti_shape = np.asarray(lr_dti.shape[1:])\n",
    "    target_fr_shape = np.floor(lr_dti_shape * params.net.upscale_factor).astype(int)\n",
    "\n",
    "    # Full-resolution images/volumes.\n",
    "    # DTI.\n",
    "    dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(dti_f)\n",
    "    dti, meta = nib_reader.get_data(im)\n",
    "    dti = torch.from_numpy(dti)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    dti, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        dti, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    dti, meta[\"affine\"] = orient_to_viz(dti, meta[\"affine\"])\n",
    "    data[\"dti\"] = dti\n",
    "    data[\"dti_meta_dict\"] = meta\n",
    "\n",
    "    # Perform scaling of input data?\n",
    "    if params.data.dti_scale_range:\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.dti_scale_range[0],\n",
    "            params.data.dti_scale_range[1],\n",
    "            quantile_low=params.data.scale_quantile_clip[0],\n",
    "            quantile_high=params.data.scale_quantile_clip[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=params.n_channels,\n",
    "        )\n",
    "        scaled = scaler.scale(data[\"dti\"], stateful=True)\n",
    "        data[\"dti\"] = scaled\n",
    "        data[\"dti_scaler\"] = scaler\n",
    "\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.dti_scale_range[0],\n",
    "            params.data.dti_scale_range[1],\n",
    "            quantile_low=params.data.scale_quantile_clip[0],\n",
    "            quantile_high=params.data.scale_quantile_clip[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=params.n_channels,\n",
    "        )\n",
    "        scaled = scaler.scale(data[\"lr_dti\"], stateful=True)\n",
    "        data[\"lr_dti\"] = scaled\n",
    "        data[\"lr_dti_scaler\"] = scaler\n",
    "\n",
    "    # Diffusion mask.\n",
    "    mask_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.mask_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(mask_f)\n",
    "    mask, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    mask = torch.from_numpy(mask)\n",
    "    # Add channel dim if not available.\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask[\n",
    "            None,\n",
    "        ]\n",
    "    mask, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        mask, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    mask, meta[\"affine\"] = orient_to_viz(mask, meta[\"affine\"])\n",
    "    mask = mask.bool()\n",
    "    data[\"mask\"] = mask\n",
    "    data[\"mask_meta_dict\"] = meta\n",
    "\n",
    "    # Anatomical/structural volume.\n",
    "    anat_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.anat_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(anat_f)\n",
    "    anat, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    anat = torch.from_numpy(anat)\n",
    "    if anat.ndim == 3:\n",
    "        anat = anat[\n",
    "            None,\n",
    "        ]\n",
    "    anat, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        anat, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    anat, meta[\"affine\"] = orient_to_viz(anat, meta[\"affine\"])\n",
    "    data[params.data.anat_type] = anat\n",
    "    data[params.data.anat_type + \"_meta_dict\"] = meta\n",
    "\n",
    "    # Perform scaling of input data?\n",
    "    if params.data.anat_scale_range:\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.anat_scale_range[0],\n",
    "            params.data.anat_scale_range[1],\n",
    "            quantile_low=params.data.scale_quantile_clip[0],\n",
    "            quantile_high=params.data.scale_quantile_clip[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=1,\n",
    "        )\n",
    "        scaled = scaler.scale(data[params.data.anat_type], stateful=True)\n",
    "        data[params.data.anat_type] = scaled\n",
    "        data[params.data.anat_type + \"_scaler\"] = scaler\n",
    "\n",
    "    vol_names = {\"dti\", \"mask\", \"lr_dti\", params.data.anat_type}\n",
    "    metadata_names = set(data.keys()) - vol_names\n",
    "    vol_d = {k: data[k] for k in vol_names}\n",
    "    meta_d = {k: data[k] for k in metadata_names}\n",
    "\n",
    "    # Create multi-volume dataset for this subj-session.\n",
    "    subj_dataset = pitn.data.SubjSesDataset(\n",
    "        vol_d,\n",
    "        primary_vol_name=\"dti\",\n",
    "        special_secondary2primary_coords_fns=fr2lr_patch_coords_fn,\n",
    "        transform=None,\n",
    "        primary_patch_kwargs=patch_kwargs,\n",
    "        **meta_d\n",
    "    )\n",
    "    print(\"Creating patches\")\n",
    "    # Init the patches dataset.\n",
    "    subj_dataset.patches\n",
    "\n",
    "    # Finalize this subject.\n",
    "    subj_data[subj_id] = subj_dataset\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "print(\"===Data Loaded===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, dpi=120)\n",
    "\n",
    "# sample = subj_data[\"103010\"].patches[20000]\n",
    "# ax1.imshow(sample[\"t2w\"][0, 0, :, 0], cmap=\"gray\", interpolation=None)\n",
    "# ax2.imshow(sample[\"dti\"][0, 0, :, 0], cmap=\"gray\")\n",
    "# ax3.imshow(sample[\"mask\"][0, 0, :, 0], cmap=\"gray\")\n",
    "# ax4.imshow(sample[\"lr_dti\"][0, 0, :, 0], cmap=\"gray\");\n",
    "# print(sample['t2w'].shape, sample['dti'].shape, sample['mask'].shape, sample['lr_dti'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finalize the dataset.\n",
    "# subj_dataset = torchio.SubjectsDataset(list(subj_data.values()), load_getitem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_data)\n",
    "num_test_subjs = int(np.ceil(params.n_subjs * params.test.dataset_subj_percent))\n",
    "num_val_subjs = int(np.ceil(params.n_subjs * params.val.dataset_subj_percent))\n",
    "num_train_subjs = params.n_subjs - (num_test_subjs + num_val_subjs)\n",
    "subj_list = list(subj_data.keys())\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1:\n",
    "    warnings.warn(\n",
    "        \"DEBUG: Only 1 subject selected, mixing training, validation, and testing sets\"\n",
    "    )\n",
    "    num_train_subjs = num_val_subjs = num_test_subjs = 1\n",
    "\n",
    "    test_subjs = subj_list\n",
    "    val_subjs = subj_list\n",
    "    train_subjs = subj_list\n",
    "else:\n",
    "    test_subjs = subj_list[:num_test_subjs]\n",
    "    val_subjs = subj_list[num_test_subjs : (num_test_subjs + num_val_subjs)]\n",
    "    train_subjs = subj_list[(num_test_subjs + num_val_subjs) :]\n",
    "\n",
    "print(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\")\n",
    "print(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\")\n",
    "print(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\")\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\\n\")\n",
    "    f.write(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\\n\")\n",
    "    f.write(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\\n\")\n",
    "\n",
    "logger.add_text(\"train_subjs\", str(train_subjs))\n",
    "logger.add_text(\"val_subjs\", str(val_subjs))\n",
    "logger.add_text(\"test_subjs\", str(test_subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Datasets and DataLoaders for test, validation, and training steps.\n",
    "sample_kws = {\n",
    "    \"subj_id\": \"subj_id\",\n",
    "    \"dti\": \"dti\",\n",
    "    \"dti_scaler\": \"dti_scaler\",\n",
    "    \"lr_dti\": \"lr_dti\",\n",
    "    \"lr_dti_scaler\": \"lr_dti_scaler\",\n",
    "    \"mask\": \"mask\",\n",
    "    params.data.anat_type: params.data.anat_type,\n",
    "    params.data.anat_type + \"_scaler\": params.data.anat_type + \"_scaler\",\n",
    "}\n",
    "\n",
    "# Train\n",
    "train_ds = list()\n",
    "for subj_id in train_subjs:\n",
    "    train_ds.append(subj_data[subj_id].patches)\n",
    "train_dataset = torch.utils.data.ConcatDataset(train_ds)\n",
    "train_sampler = pitn.samplers.ConcatDatasetBalancedRandomSampler(\n",
    "    train_dataset.datasets,\n",
    "    max_samples_per_dataset=params.train.samples_per_subj_per_epoch,\n",
    ")\n",
    "train_collate_fn = functools.partial(pitn.samplers.collate_dicts, **sample_kws)\n",
    "train_loader = monai.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=params.train.batch_size,\n",
    "    collate_fn=train_collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=7,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# Test & Validation\n",
    "test_val_collate_fn = functools.partial(pitn.samplers.collate_dicts, **sample_kws)\n",
    "\n",
    "test_ds = list()\n",
    "for subj_id in test_subjs:\n",
    "    test_ds.append(subj_data[subj_id])\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_ds)\n",
    "test_loader = monai.data.DataLoader(\n",
    "    test_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")\n",
    "\n",
    "val_ds = list()\n",
    "for subj_id in val_subjs:\n",
    "    val_ds.append(subj_data[subj_id])\n",
    "val_dataset = torch.utils.data.ConcatDataset(val_ds)\n",
    "val_loader = monai.data.DataLoader(\n",
    "    val_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "debug_prob = -1 / (\n",
    "    params.train.samples_per_subj_per_epoch * len(train_subjs) / params.train.batch_size\n",
    ")\n",
    "\n",
    "\n",
    "class DIQTCascadeSystem(pl.LightningModule):\n",
    "\n",
    "    # Specify training loss methods with mappings to their names as strings.\n",
    "    loss_methods = {\n",
    "        \"MSE\".casefold(): torch.nn.MSELoss(reduction=\"mean\"),\n",
    "        \"SSE\".casefold(): torch.nn.MSELoss(reduction=\"sum\"),\n",
    "        \"RMSE\".casefold(): lambda y_hat, y: torch.sqrt(\n",
    "            F.mse_loss(y_hat, y, reduction=\"mean\")\n",
    "        ),\n",
    "        \"L1\".casefold(): torch.nn.L1Loss(reduction=\"mean\"),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        batch_size: int,\n",
    "        in_patch_shape: tuple,\n",
    "        upscale_factor: int,\n",
    "        anat_batch_key: str,\n",
    "        train_loss_method: str,\n",
    "        opt_params: dict,\n",
    "        hparams: dict = dict(),\n",
    "        **net_kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self._channels = channels\n",
    "        self._batch_size = batch_size\n",
    "        self._in_patch_shape = in_patch_shape\n",
    "        self._anat_batch_key = anat_batch_key\n",
    "        self._upscale_factor = upscale_factor\n",
    "        # self.hparams.update(hparams)\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = pitn.nn.sr.CascadeUpsampleModeRefine(\n",
    "            self._channels, upscale_factor=self._upscale_factor, **net_kwargs\n",
    "        )\n",
    "\n",
    "        ## Training parameters\n",
    "        self.opt_params = opt_params\n",
    "\n",
    "        # Select loss method as either one of the pre-selected methods, or a custom\n",
    "        # callable.\n",
    "        try:\n",
    "            self._loss_fn = self.loss_methods[train_loss_method.casefold()]\n",
    "        except (AttributeError, KeyError):\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"ERROR: Invalid loss function specification {train_loss_method}, \"\n",
    "                    + f\"expected one of {self.loss_methods.keys()} or a callable.\"\n",
    "                )\n",
    "\n",
    "        self._val_subvol_range = dict()\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = Box(\n",
    "            {\n",
    "                \"train_loss\": list(),\n",
    "                \"val_loss\": {\"rmse\": list()},\n",
    "                \"test_loss\": {\"spline\": {\"rmse\": dict()}, \"rmse\": dict()},\n",
    "                \"viz\": {\n",
    "                    \"spline_preds\": dict(),\n",
    "                    \"test_preds\": dict(),\n",
    "                    \"test_squared_error\": dict(),\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self.logger.log_hyperparams(self.hparams, {\"hp/rmse\": 0})\n",
    "\n",
    "    def forward(self, x, x_mode_refine):\n",
    "        y = self.net(x, x_mode_refine)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = Box(batch)\n",
    "        x = batch.lr_dti\n",
    "        y = batch.dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine)\n",
    "\n",
    "        # Only calculate loss on voxels in the brain mask.\n",
    "        loss = self._loss_fn(\n",
    "            torch.masked_select(y_pred, mask), torch.masked_select(y, mask)\n",
    "        )\n",
    "\n",
    "        self.log(\"train_loss\", loss, batch_size=self._batch_size)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        x = batch.lr_dti\n",
    "        y = batch.dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine)\n",
    "\n",
    "        # Calculate val loss on un-scaled inputs & outputs.\n",
    "        if batch.dti_scaler:\n",
    "            x = batch.lr_dti_scaler[0].descale(x[0])[\n",
    "                None,\n",
    "            ]\n",
    "            y = batch.dti_scaler[0].descale(y[0])[\n",
    "                None,\n",
    "            ]\n",
    "            y_pred = batch.dti_scaler[0].descale(y_pred[0])[\n",
    "                None,\n",
    "            ]\n",
    "            x_mode_refine = batch[self._anat_batch_key + \"_scaler\"][0].descale(\n",
    "                x_mode_refine[0]\n",
    "            )[\n",
    "                None,\n",
    "            ]\n",
    "\n",
    "        rmse_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                torch.masked_select(y_pred, mask),\n",
    "                torch.masked_select(y, mask),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.log(\"val_loss/rmse\", rmse_loss)\n",
    "        self.plain_log.val_loss.rmse.append(float(rmse_loss.cpu()))\n",
    "\n",
    "        # Plot visual of validation volume.\n",
    "        if not self._val_subvol_range:\n",
    "            # Take range between 2/8 to 5/8 the size of each dimension.\n",
    "            fr_space = np.asarray(y.shape[2:])\n",
    "            fr_low = np.floor(fr_space * 2 / 8).astype(int)\n",
    "            fr_high = np.floor(fr_space * 5 / 8).astype(int)\n",
    "            subvol_slice = np.s_[\n",
    "                fr_low[0] : fr_high[0], fr_low[1] : fr_high[1], fr_low[2] : fr_high[2]\n",
    "            ]\n",
    "            self._val_subvol_range[\"fr\"] = (\n",
    "                0,\n",
    "                ...,\n",
    "            ) + subvol_slice\n",
    "\n",
    "            lr_space = np.asarray(x.shape[2:])\n",
    "            lr_low = np.floor(lr_space * 2 / 8).astype(int)\n",
    "            lr_high = np.floor(lr_space * 5 / 8).astype(int)\n",
    "            subvol_slice = np.s_[\n",
    "                lr_low[0] : lr_high[0], lr_low[1] : lr_high[1], lr_low[2] : lr_high[2]\n",
    "            ]\n",
    "            self._val_subvol_range[\"lr\"] = (\n",
    "                0,\n",
    "                ...,\n",
    "            ) + subvol_slice\n",
    "\n",
    "        x_subvol = x.detach()[self._val_subvol_range[\"lr\"]].float()\n",
    "        y_subvol = y.detach()[self._val_subvol_range[\"fr\"]].float()\n",
    "        pred_subvol = y_pred.detach()[self._val_subvol_range[\"fr\"]].float()\n",
    "        # x_mode_refine_subvol = x_mode_refine.detach()[\n",
    "        #     self._val_subvol_range[\"fr\"]\n",
    "        # ].expand_as(y_subvol)\n",
    "        # mask_subvol = mask.detach()[self._val_subvol_range[\"fr\"]]\n",
    "\n",
    "        # Create grid plot\n",
    "        # Plot settings to propogate into the figure.\n",
    "        with mpl.rc_context(\n",
    "            {\n",
    "                \"font.size\": 8.0,\n",
    "                \"axes.labelpad\": 10.0,\n",
    "                \"figure.autolayout\": False,\n",
    "                \"figure.constrained_layout.use\": True,\n",
    "            }\n",
    "        ):\n",
    "            fig = plt.figure(dpi=130, figsize=(6, 8))\n",
    "            channel_names = [\n",
    "                r\"$D_{x,x}$\",\n",
    "                r\"$D_{x,y}$\",\n",
    "                r\"$D_{y,y}$\",\n",
    "                r\"$D_{x,z}$\",\n",
    "                r\"$D_{y,z}$\",\n",
    "                r\"$D_{z,z}$\",\n",
    "            ]\n",
    "            slice_labels = [\"\\nSagg.\", \"\\nHoriz.\", \"\\nCoronal\"]\n",
    "            img_labels = [\"GT\", \"Pred\", \"Input\"]\n",
    "            fig = pitn.viz.plot_vol_slices(\n",
    "                y_subvol,\n",
    "                pred_subvol,\n",
    "                x_subvol,\n",
    "                slice_idx=(None, 0.5, None),\n",
    "                title=f\"Subj {batch.subj_id[0]} Step {self.global_step}\",\n",
    "                vol_labels=img_labels,\n",
    "                channel_labels=channel_names,\n",
    "                slice_labels=slice_labels,\n",
    "                colorbars=\"each\",\n",
    "                fig=fig,\n",
    "                interpolation=\"antialiased\",\n",
    "                cmap=\"gray\",\n",
    "            )\n",
    "\n",
    "        self.logger.experiment.add_figure(\"val_slice\", fig, self.global_step)\n",
    "\n",
    "        return rmse_loss\n",
    "\n",
    "    def test_step(self, batch: dict, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        subj_id = batch.subj_id[0]\n",
    "        x = batch.lr_dti\n",
    "        y = batch.dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine).float()\n",
    "        if batch.dti_scaler:\n",
    "            spline_x = batch.lr_dti_scaler[0].descale(x[0])[None,]\n",
    "            spline_y_pred = self.pred_spline(spline_x).float()\n",
    "        else:\n",
    "            spline_y_pred = self.pred_spline(x).float()\n",
    "\n",
    "        # Calculate test loss on un-scaled inputs & outputs.\n",
    "        if batch.dti_scaler:\n",
    "            y = batch.dti_scaler[0].descale(y[0])[\n",
    "                None,\n",
    "            ]\n",
    "            y_pred = batch.dti_scaler[0].descale(y_pred[0])[\n",
    "                None,\n",
    "            ]\n",
    " \n",
    "\n",
    "        rmse_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                torch.masked_select(y_pred, mask),\n",
    "                torch.masked_select(y, mask),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        spline_rmse = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                torch.masked_select(spline_y_pred, mask),\n",
    "                torch.masked_select(y, mask),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # on_epoch and reduce_fx gather the individual test epoch values and aggregate\n",
    "        # them at the end of the testing epoch.\n",
    "        self.log(\"test_loss/rmse\", rmse_loss, on_epoch=True, reduce_fx=torch.mean)\n",
    "        # Log loss as an hparam metric to be shown alongside the experiment's hparams.\n",
    "        self.log(\"hp/rmse\", rmse_loss, on_epoch=True, reduce_fx=torch.mean)\n",
    "        self.plain_log.test_loss.rmse[subj_id] = rmse_loss.detach().cpu().item()\n",
    "        self.plain_log.viz.test_preds[subj_id] = y_pred[0].detach().cpu()\n",
    "        self.plain_log.test_loss.spline.rmse[subj_id] = (\n",
    "            spline_rmse.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.viz.spline_preds[subj_id] = spline_y_pred[0].detach().cpu()\n",
    "\n",
    "        return rmse_loss\n",
    "\n",
    "    def pred_spline(self, x, order=3):\n",
    "        x_np = x.detach().cpu().numpy()\n",
    "        ys = list()\n",
    "        for b in x_np:\n",
    "            y_b = scipy.ndimage.zoom(\n",
    "                b,\n",
    "                zoom=(\n",
    "                    1,\n",
    "                    self._upscale_factor,\n",
    "                    self._upscale_factor,\n",
    "                    self._upscale_factor,\n",
    "                ),\n",
    "                order=order,\n",
    "            )\n",
    "\n",
    "            ys.append(torch.from_numpy(y_b))\n",
    "\n",
    "        y = torch.stack(ys, dim=0)\n",
    "        y = y.to(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.net.parameters(), **self.opt_params)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "model = DIQTCascadeSystem(\n",
    "    channels=params.n_channels,\n",
    "    batch_size=params.train.batch_size,\n",
    "    in_patch_shape=params.train.in_patch_size,\n",
    "    upscale_factor=params.net.upscale_factor,\n",
    "    anat_batch_key=params.data.anat_type,\n",
    "    train_loss_method=params.train.loss_name,\n",
    "    opt_params=params.optim.kwargs,\n",
    "    hparams=hyperparams,\n",
    "    **params.net.kwargs,\n",
    ")\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Model overview: {model}\\n\")\n",
    "\n",
    "# Create trainer object.\n",
    "trainer = pl.Trainer(\n",
    "    # fast_dev_run=10,\n",
    "    gpus=1,\n",
    "    max_epochs=params.train.max_epochs,\n",
    "    # max_epochs=1,\n",
    "    logger=pl_logger,\n",
    "    log_every_n_steps=50,\n",
    "    # run validation every 0.5 epochs\n",
    "    val_check_interval=0.5,\n",
    "    # Halt if None gradients are detected\n",
    "    # detect_anomaly=True,\n",
    "    # Enable mixed-precision floating point ops.\n",
    "    precision=16,\n",
    "    amp_backend=\"native\",\n",
    "    # max_time={\"minutes\": 5},\n",
    ")\n",
    "\n",
    "# Many warnings are produced here, so it's better for my sanity (i.e., worse in every other\n",
    "# way) to just filter and ignore them...\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out trained model\n",
    "trainer.save_checkpoint(str(experiment_results_dir / \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + params.train.loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss_name = \"RMSE\"\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Test loss function: {test_loss_name}\\n\")\n",
    "\n",
    "row_iter = enumerate(list(model.plain_log[\"test_loss\"].values()))\n",
    "test_loss_tabular = \"\".join([f\"{batch_idx}, {loss}\\n\" for batch_idx, loss in row_iter])\n",
    "\n",
    "with open(test_loss_log_file, \"a+\") as f:\n",
    "    f.write(\"batch_idx, loss\\n\")\n",
    "    f.write(test_loss_tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppr(test_loss_tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.plain_log.test_loss.rmse.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = False\n",
    "\n",
    "hist = sns.histplot(\n",
    "    list(model.plain_log[\"test_loss\"].rmse.values()),\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    "    hatch=\"\\\\\\\\\",\n",
    "    ec=\"blue\",\n",
    ")\n",
    "hist.yaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"-\", \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Our spline mean performance.\n",
    "plt.axvline(\n",
    "    np.asarray(list(model.plain_log.test_loss.spline.rmse.values())).mean(),\n",
    "    label=f\"(Ours) Spline Mean Order 3\",\n",
    "    color=\"black\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "sns.histplot(\n",
    "    np.asarray(list(model.plain_log.test_loss.spline.rmse.values())),\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    "    color=\"black\",\n",
    "    hatch=\"//\",\n",
    ")\n",
    "# Tanno, et. al., 2021 C-spline comparison.\n",
    "# Taken from Table 2, HCP exterior.\n",
    "plt.axvline(\n",
    "    31.738e-4,\n",
    "    label=\"(Tanno etal, 2021)\\nWorst-Case C-Spline\",\n",
    "    color=\"red\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    9.72e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    9.76e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nBest ESPCN\\n[but not really]\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    8.46e-4,\n",
    "    label=\"(Blumberg etal, 2018)\\nBest Overall\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(f\"Test Loss Histogram Over All Subjects with Test Metric {test_loss_name}\")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all subjects.\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "\n",
    "models = (\n",
    "    \"(Ours)\\nCurrent Model\",\n",
    "    \"(Ours)\\nSpline Order 3\",\n",
    "    \"(Tanno etal, 2021)\\nWorst-Case C-Spline\",\n",
    "    \"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    \"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nBest ESPCN\\n[but not really]\",\n",
    "    \"(Blumberg etal, 2018)\\nBest Overall\",\n",
    ")\n",
    "\n",
    "rmse_scores = (\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    np.asarray(list(model.plain_log.test_loss.spline.rmse.values())).mean(),\n",
    "    31.738e-4,\n",
    "    9.72e-4,\n",
    "    9.76e-4,\n",
    "    8.46e-4,\n",
    ")\n",
    "\n",
    "rmse_std_error = np.asarray([0, 0, 0, 0.51e-4, 0.64e-4, 0.67e-4])\n",
    "\n",
    "ax.grid(True, axis=\"y\", zorder=1000)\n",
    "ax.set_axisbelow(True)\n",
    "ax.bar(\n",
    "    models,\n",
    "    rmse_scores,\n",
    "    yerr=rmse_std_error,\n",
    "    color=sns.color_palette(\"deep\", n_colors=len(rmse_scores)),\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    if isinstance(container, mpl.container.BarContainer):\n",
    "        ax.bar_label(container, fmt=\"%.3e\")\n",
    "\n",
    "ax.set_ylim(bottom=0, top=ax.get_ylim()[1] * 1.1)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "ax.set_title(f\"Mean Over Subjects Test Loss {test_loss_name}\")\n",
    "ax.set_xticks(models)\n",
    "ax.set_xticklabels(\n",
    "    models, fontsize=\"x-small\", rotation=25, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_test_idx = np.argsort(np.asarray(list(model.plain_log[\"test_loss\"].values())))\n",
    "sorted_test_results = dict(\n",
    "    list(model.plain_log[\"test_loss\"].items())[i] for i in sorted_test_idx\n",
    ")\n",
    "ppr(sorted_test_results, sort_dicts=False)\n",
    "print(np.mean(list(list(model.plain_log[\"test_loss\"].rmse.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.add_histogram(\n",
    "    \"test/rmse_dist\", np.asarray(list(model.plain_log[\"test_loss\"].rmse.values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debug flag(s)\n",
    "disable_fig_save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volumes of full-res ground truth, low-res downsample, full-res mask,\n",
    "# anatomical image, and full-res predictions.\n",
    "\n",
    "results_viz = Box(default_box=True)\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj in test_dataset:\n",
    "        # Index into the only item in the subject dataset.\n",
    "        s = Box(default_box=True)\n",
    "        subj_id = subj[\"subj_id\"]\n",
    "        print(f\"Starting subject {subj_id}\")\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "        s.mask = model.net.crop_full_output(subj[\"mask\"])\n",
    "        s.dti = model.net.crop_full_output(subj[\"dti\"])\n",
    "        s.affine = subj[\"dti_meta_dict\"][\"affine\"]\n",
    "        s.lr_dti = subj[\"lr_dti\"]\n",
    "        s[params.data.anat_type] = model.net.crop_full_output(\n",
    "            subj[params.data.anat_type]\n",
    "        )\n",
    "\n",
    "        s.pred = model.plain_log.viz.test_preds[subj_id]\n",
    "\n",
    "        if params.data.dti_scale_range:\n",
    "            s.dti = subj[\"dti_scaler\"].descale(s.dti)\n",
    "            s.lr_dti = subj[\"lr_dti_scaler\"].descale(s.lr_dti)\n",
    "            s.pred = subj[\"dti_scaler\"].descale(s.pred)\n",
    "        if params.data.anat_scale_range:\n",
    "            s[params.data.anat_type] = subj[params.data.anat_type + \"_scaler\"].descale(\n",
    "                s[params.data.anat_type]\n",
    "            )\n",
    "\n",
    "        s.dti = s.dti * s.mask\n",
    "        s.pred = s.pred * s.mask\n",
    "\n",
    "        s.metrics.rmse = model.plain_log.test_loss.rmse[subj_id]\n",
    "        s.abs_error = torch.abs(s.pred - s.dti)\n",
    "\n",
    "        for k in {\"mask\", \"dti\", \"lr_dti\", params.data.anat_type, \"pred\", \"abs_error\"}:\n",
    "            v = s[k]\n",
    "            if torch.is_tensor(v):\n",
    "                v = v.detach().cpu().numpy()\n",
    "            if k == \"mask\":\n",
    "                v = v.astype(bool)\n",
    "            else:\n",
    "                v = v.astype(float)\n",
    "            # s[k] = np.rot90(v)\n",
    "            s[k] = v\n",
    "\n",
    "        results_viz[subj_id] = s\n",
    "        print(f\"Finished subject {subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pitn.viz.plot_vol_slices(\n",
    "#     np.rot90(results_viz['303624'].dti[0], k=1)\n",
    "#     , colorbars='each')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out all network predictions to Nifti2 files and compress them into a zip archive.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in results_viz.items():\n",
    "        nib_img = nib.Nifti2Image(viz.dti, viz.affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_dti.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(experiment_results_dir / \"predicted_dti.zip\", \"w\") as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=6,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "    # Make sure we exit the 'with' statement above.\n",
    "    print(\"Done with files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick the worst performing subject from the test set to visualize.\n",
    "rmses = {results_viz[s_id].metrics.rmse: s_id for s_id in results_viz.keys()}\n",
    "bad_rmse = np.sort(np.asarray(list(rmses.keys())))[-1]\n",
    "viz_subj_id = rmses[bad_rmse]\n",
    "print(viz_subj_id, bad_rmse)\n",
    "viz_subj = results_viz[viz_subj_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select indices for visualizing.\n",
    "dti_shape = np.asarray(viz_subj.dti.shape[1:])\n",
    "lr_dti_shape = np.asarray(viz_subj.lr_dti.shape[1:])\n",
    "\n",
    "viz_idx = dti_shape // 2\n",
    "viz_idx[0] = viz_idx[0] + 6\n",
    "viz_lr_idx = lr_dti_shape // 2\n",
    "viz_lr_idx[0] = viz_lr_idx[0] + 6 // params.data.downsampled_by_factor\n",
    "\n",
    "viz_slice_idx = [\n",
    "    np.s_[:, viz_idx[0], :, :],\n",
    "    np.s_[:, :, viz_idx[1], :],\n",
    "    np.s_[:, :, :, viz_idx[2]],\n",
    "]\n",
    "\n",
    "viz_lr_slice_idx = [\n",
    "    np.s_[:, viz_lr_idx[0], :, :],\n",
    "    np.s_[:, :, viz_lr_idx[1], :],\n",
    "    np.s_[:, :, :, viz_lr_idx[2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA-Weighted Direction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ims = list()\n",
    "for im, slices in zip(\n",
    "    [viz_subj.dti, viz_subj.pred, viz_subj.lr_dti],\n",
    "    (viz_slice_idx, viz_slice_idx, viz_lr_slice_idx),\n",
    "):\n",
    "    for sl in slices:\n",
    "        selection = im[sl]\n",
    "        fa_w = pitn.viz.direction_map(selection, channels_first=True)\n",
    "        fa_w = fa_w.transpose(1, 2, 0)\n",
    "        ims.append(np.rot90(fa_w))\n",
    "\n",
    "dim_labels = [\n",
    "    \"Sagg.\",\n",
    "    \"Coronal\",\n",
    "    \"Horiz.\",\n",
    "]\n",
    "vol_labels = [\"Ground Truth\", \"Pred\", \"LR Input\"]\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 12.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=130, figsize=(7, 7))\n",
    "    fig = pitn.viz.plot_im_grid(\n",
    "        ims,\n",
    "        nrows=len(vol_labels),\n",
    "        title=f\"Subj {viz_subj_id} Prediction Results\",\n",
    "        row_headers=vol_labels,\n",
    "        col_headers=dim_labels,\n",
    "        colorbars=None,\n",
    "        fig=fig,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"dir_map_pred.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DTI Channel-Wise Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"$D_{x,x}$\",\n",
    "    \"$D_{x,y}$\",\n",
    "    \"$D_{y,y}$\",\n",
    "    \"$D_{x,z}$\",\n",
    "    \"$D_{y,z}$\",\n",
    "    \"$D_{z,z}$\",\n",
    "]\n",
    "\n",
    "dim_labels = [\n",
    "    \"\\nSagg.\",\n",
    "    \"\\nCor.\",\n",
    "    \"\\nHoriz.\",\n",
    "]\n",
    "\n",
    "dti_names = [\n",
    "    \"FR\",\n",
    "    \"Pred\",\n",
    "    \"LR\",\n",
    "    \"Abs Err\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "cmap = \"gray\"\n",
    "title = f\"DTI Subj {viz_subj_id} Summary\"\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 6.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=150, figsize=(8, 12))\n",
    "    fig = pitn.viz.plot_vol_slices(\n",
    "        viz_subj.dti,\n",
    "        viz_subj.pred,\n",
    "        viz_subj.lr_dti,\n",
    "        viz_subj.abs_error,\n",
    "        slice_idx=(None, None, viz_idx[2] / dti_shape[2]),\n",
    "        title=title,\n",
    "        vol_labels=dti_names,\n",
    "        slice_labels=dim_labels,\n",
    "        channel_labels=channel_names,\n",
    "        colorbars=\"each\",\n",
    "        fig=fig,\n",
    "        cmap=cmap,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "\n",
    "\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / f\"DIQT_DTI_sub-{viz_subj_id}_pred_result.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel-Wise Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Display all 6 DTIs for ground truth, predicted, low-res input, and root squared error\n",
    "# # Normalize by index in the DTI coefficients.\n",
    "# # Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# # different shapes (e.g., the low-res input patch).\n",
    "\n",
    "# cmap = \"coolwarm\"\n",
    "# dtis = [\n",
    "#     test_vol_viz[viz_subj_id].dti.fr[(slice(None), *slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.lr[(slice(None), *low_res_slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.spline[(slice(None), *slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.diqt[(slice(None), *slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.abs_error[(slice(None), *slice_idx)],\n",
    "# ]\n",
    "\n",
    "# nrows = len(dtis)\n",
    "# ncols = len(channel_names)\n",
    "\n",
    "# # Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# # orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# max_dtis = np.quantile(\n",
    "#     np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95, axis=1\n",
    "# )\n",
    "# min_dtis = np.quantile(\n",
    "#     np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05, axis=1\n",
    "# )\n",
    "\n",
    "# max_dtis = np.max(np.abs([max_dtis, min_dtis]), axis=0)\n",
    "# min_dtis = -1 * max_dtis\n",
    "\n",
    "# nrows = len(dtis)\n",
    "# ncols = len(channel_names)\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 7), dpi=160)\n",
    "\n",
    "# grid = mpl.gridspec.GridSpec(\n",
    "#     nrows,\n",
    "#     ncols,\n",
    "#     figure=fig,\n",
    "#     hspace=0.05,\n",
    "#     wspace=0.05,\n",
    "# )\n",
    "\n",
    "# axs = list()\n",
    "# max_subplot_height = 0\n",
    "# for i_row in range(nrows):\n",
    "#     dti = dtis[i_row]\n",
    "#     axs_cols = list()\n",
    "\n",
    "#     for j_col in range(ncols):\n",
    "#         ax = fig.add_subplot(grid[i_row, j_col])\n",
    "#         ax.imshow(\n",
    "#             np.rot90(dti[j_col]),\n",
    "#             cmap=cmap,\n",
    "#             interpolation=None,\n",
    "#             vmin=min_dtis[j_col],\n",
    "#             vmax=max_dtis[j_col],\n",
    "#         )\n",
    "#         if ax.get_subplotspec().is_first_col():\n",
    "#             ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "#         if ax.get_subplotspec().is_last_row():\n",
    "#             ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "#         # Update highest subplot to put the `suptitle` later on.\n",
    "#         max_subplot_height = max(\n",
    "#             max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "#         )\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         ax.set_xticklabels([])\n",
    "#         ax.set_yticklabels([])\n",
    "\n",
    "#         axs_cols.append(ax)\n",
    "\n",
    "#     axs.append(axs_cols)\n",
    "\n",
    "# # Place colorbars on each column.\n",
    "# for j_col in range(ncols):\n",
    "\n",
    "#     full_col_ax = [axs[i][j_col] for i in range(nrows)]\n",
    "\n",
    "#     color_norm = mpl.colors.Normalize(vmin=min_dtis[j_col], vmax=max_dtis[j_col])\n",
    "\n",
    "#     color_mappable = mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap)\n",
    "#     cbar = fig.colorbar(\n",
    "#         color_mappable,\n",
    "#         ax=full_col_ax,\n",
    "#         location=\"top\",\n",
    "#         orientation=\"horizontal\",\n",
    "#         pad=0.01,\n",
    "#         shrink=0.85,\n",
    "#     )\n",
    "#     cbar.ax.tick_params(labelsize=8, rotation=35)\n",
    "#     cbar.ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:g}\"))\n",
    "# #     cbar.ax.ticklabel_format(scilimits=(3, -3), useOffset=False)\n",
    "\n",
    "# plt.suptitle(\n",
    "#     \"DTI Channel Breakdown, Channel-Wise Normalization\",\n",
    "#     y=max_subplot_height + 0.01,\n",
    "#     verticalalignment=\"bottom\",\n",
    "# )\n",
    "# if not disable_fig_save:\n",
    "#     plt.savefig(experiment_results_dir / \"DTI_channel_sample_channel_wise_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl_logger.experiment.flush()\n",
    "# Close tensorboard logger.\n",
    "# Don't finalize if the experiment was for debugging.\n",
    "if \"debug\" not in EXPERIMENT_NAME.casefold():\n",
    "    pl_logger.finalize(\"success\")\n",
    "    # Experiment is complete, move the results directory to its final location.\n",
    "    if experiment_results_dir != final_experiment_results_dir:\n",
    "        print(\"Moving out of tmp location\")\n",
    "        experiment_results_dir = experiment_results_dir.rename(\n",
    "            final_experiment_results_dir\n",
    "        )\n",
    "        log_txt_file = experiment_results_dir / log_txt_file.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
