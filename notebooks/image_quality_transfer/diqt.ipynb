{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pain in the Net\n",
    "Application of Deep Image Quality Transfer (DIQT) with domain adaptation.\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "References:\n",
    "\n",
    "* `R. Tanno et al., “Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion MRI,” NeuroImage, vol. 225, p. 117366, Jan. 2021, doi: 10.1016/j.neuroimage.2020.117366.`\n",
    "* `D. C. Alexander et al., “Image quality transfer and applications in diffusion MRI,” NeuroImage, vol. 152, pp. 283–298, May 2017, doi: 10.1016/j.neuroimage.2017.02.089.`\n",
    "* `S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipyplot\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "from addict import Addict\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "import box\n",
    "from box import Box\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import pitn\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "    # GPU information\n",
    "    try:\n",
    "        gpu_info = pitn.utils.system.get_gpu_specs()\n",
    "        print(gpu_info)\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2022-01-21T23:22:56.529475+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-91-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 3dfe7906e10b0b4c67b0346bf50390675f5c60db\n",
      "\n",
      "pytorch_lightning: 1.5.9\n",
      "json             : 2.0.9\n",
      "nibabel          : 3.2.1\n",
      "pandas           : 1.2.3\n",
      "torch            : 1.10.0\n",
      "matplotlib       : 3.4.1\n",
      "dipy             : 1.4.1\n",
      "scipy            : 1.5.3\n",
      "box              : 5.4.1\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "skimage          : 0.18.1\n",
      "seaborn          : 0.11.1\n",
      "monai            : 0.7.dev2138\n",
      "numpy            : 1.20.2\n",
      "pitn             : 0.0.post1.dev132+g02c0d1a\n",
      "natsort          : 7.1.1\n",
      "torchio          : 0.18.30\n",
      "\n",
      "==================================================GPU Specs==================================================\n",
      "  id  Name                Driver Version    CUDA Version  Total Memory    uuid\n",
      "----  ----------------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  NVIDIA TITAN RTX            470.86            11.3  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"])\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = \"debug_dev_diqt_refactor\"\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 3\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-21T23_22_56__debug_dev_diqt_refactor\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = Box(default_box=True)\n",
    "\n",
    "# General experiment-wide params\n",
    "# 6 channels for the 6 DTI components\n",
    "params.n_channels = 6\n",
    "params.n_subjs = 15\n",
    "params.lr_vox_size = 2.5\n",
    "params.fr_vox_size = 1.25\n",
    "\n",
    "# Data params\n",
    "params.data.fr_dir = data_dir / f\"scale-{params.fr_vox_size:.2f}mm\"\n",
    "params.data.lr_dir = data_dir / f\"scale-{params.lr_vox_size:.2f}mm\"\n",
    "params.data.dti_fname_pattern = r\"sub-*dti.nii.gz\"\n",
    "params.data.mask_fname_pattern = r\"dti/sub-*mask.nii.gz\"\n",
    "params.data.anat_type = \"t2w\"\n",
    "params.data.anat_fname_pattern = f\"sub-*{params.data.anat_type}.nii.gz\"\n",
    "# The data were downsampled artificially by this factor.\n",
    "params.data.downsampled_by_factor = params.lr_vox_size / params.fr_vox_size\n",
    "params.data.downsampled_by_factor = (\n",
    "    int(params.data.downsampled_by_factor)\n",
    "    if int(params.data.downsampled_by_factor) == params.data.downsampled_by_factor\n",
    "    else params.data.downsampled_by_factor\n",
    ")\n",
    "\n",
    "# This is the number of voxels to remove (read: center crop out) from the network's\n",
    "# prediction. This allows for an \"oversampling\" of the low-res voxels to help inform a\n",
    "# more constrained HR prediction. This value of voxels will be removed from each spatial\n",
    "# dimension (D, H, and W) starting at the center of the output patches.\n",
    "# Ex. A size of 1 will remove the 2 outer-most voxels from each dimension in the output,\n",
    "# while still keeping the corresponding voxels in the LR input.\n",
    "params.hr_center_crop_per_side = 5\n",
    "\n",
    "# Scale input data by the valid values of each channel of the DTI.\n",
    "# I.e., Dx,x in [0, 1], Dx,y in [-1, 1], Dy,y in [0, 1], Dy,z in [-1, 1], etc.\n",
    "# params.data_scale_range = ((0, -1, 0, -1, -1, 0), (1, 1, 1, 1, 1, 1))\n",
    "\n",
    "# Network params.\n",
    "# The network's goal is to upsample the input by this factor.\n",
    "params.net.upscale_factor = params.data.downsampled_by_factor\n",
    "params.net.kwargs.n_res_units = 3\n",
    "params.net.kwargs.n_dense_units = 3\n",
    "params.net.kwargs.activate_fn = F.elu\n",
    "params.net.kwargs.upsample_activate_fn = F.elu\n",
    "params.net.kwargs.center_crop_output_side_amt = params.hr_center_crop_per_side\n",
    "\n",
    "# Adam optimizer kwargs\n",
    "params.optim.name = \"Adam\"\n",
    "params.optim.kwargs.lr = 7e-4\n",
    "params.optim.kwargs.betas = (0.9, 0.999)\n",
    "\n",
    "# Testing params\n",
    "params.test.dataset_subj_percent = 0.5\n",
    "\n",
    "# Validation params\n",
    "params.val.dataset_subj_percent = 0.01\n",
    "\n",
    "# Training params\n",
    "params.train.in_patch_size = (24, 24, 24)\n",
    "params.train.batch_size = 16\n",
    "params.train.samples_per_subj_per_epoch = 8000\n",
    "params.train.max_epochs = 50\n",
    "params.train.loss_name = \"mse\"\n",
    "# Percentage of subjs in dataset that go into the training set.\n",
    "params.train.dataset_subj_percent = 1 - (\n",
    "    params.test.dataset_subj_percent + params.val.dataset_subj_percent\n",
    ")\n",
    "\n",
    "# If a config file exists, override the defaults with those values.\n",
    "try:\n",
    "    config_fname = pitn.utils.system.get_file_glob_unique(Path(\".\"), r\"config.*\")\n",
    "    f_type = config_fname.suffix.casefold()\n",
    "    if f_type in {\"yaml\", \"yml\"}:\n",
    "        f_params = Box.from_yaml(config_fname)\n",
    "    elif f_type == \"json\":\n",
    "        f_params = Box.from_json(config_fname)\n",
    "    elif f_type == \"toml\":\n",
    "        f_params = Box.from_toml(config_fname)\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    params.merge_update(f_params)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Remove the default_box behavior now that params have been fully read in.\n",
    "p = Box(default_box=False)\n",
    "p.merge_update(params)\n",
    "params = p\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(pprint.pformat(params.to_dict()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'103010': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-103010'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-103010')},\n",
      " '135528': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-135528'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-135528')},\n",
      " '140117': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-140117'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-140117')},\n",
      " '141422': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-141422'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-141422')},\n",
      " '156637': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-156637'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-156637')},\n",
      " '185947': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-185947'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-185947')},\n",
      " '224022': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-224022'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-224022')},\n",
      " '227432': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-227432'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-227432')},\n",
      " '303624': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-303624'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-303624')},\n",
      " '397154': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-397154'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-397154')},\n",
      " '700634': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-700634'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-700634')},\n",
      " '751348': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-751348'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-751348')},\n",
      " '753251': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-753251'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-753251')},\n",
      " '810439': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-810439'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-810439')},\n",
      " '894774': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-1.25mm/sub-894774'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/mean-downsample/scale-2.50mm/sub-894774')}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Sub-selecting 15/16 participants for dev and debugging. Subj IDs selected: ['303624', '751348', '140117', '224022', '227432', '135528', '103010', '810439', '156637', '700634', '753251', '397154', '185947', '894774', '141422']\n"
     ]
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: Box = Box()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "sampled_subjs = random.sample(selected_ids, params.n_subjs)\n",
    "if len(sampled_subjs) < len(selected_ids):\n",
    "    warnings.warn(\n",
    "        f\"WARNING: Sub-selecting {len(sampled_subjs)}/{len(selected_ids)} \"\n",
    "        + \"participants for dev and debugging. \"\n",
    "        + f\"Subj IDs selected: {sampled_subjs}\"\n",
    "    )\n",
    "selected_subjs = sampled_subjs\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_subjs = natsorted(selected_subjs)\n",
    "\n",
    "for subj_id in selected_subjs:\n",
    "    subj_dirs[subj_id] = Box()\n",
    "    subj_dirs[subj_id].fr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.fr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    subj_dirs[subj_id].lr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.lr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    assert subj_dirs[subj_id].fr.exists()\n",
    "    assert subj_dirs[subj_id].lr.exists()\n",
    "ppr(subj_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep for Dataset loading.\n",
    "\n",
    "# Data reader object for NIFTI files.\n",
    "nib_reader = monai.data.NibabelReader(as_closest_canonical=False)\n",
    "\n",
    "# HR -> LR patch coordinate conversion function.\n",
    "fr2lr_patch_coords_fn = {\n",
    "    \"lr_dti\": functools.partial(\n",
    "        pitn.coords.transform.int_downscale_patch_idx,\n",
    "        downscale_factor=params.data.downsampled_by_factor,\n",
    "        downscale_patch_shape=params.train.in_patch_size,\n",
    "    )\n",
    "}\n",
    "\n",
    "# Kwargs for the patches dataset (the _VolPatchDataset class) of the HR volumes.\n",
    "patch_kwargs = dict(\n",
    "    patch_shape=tuple(\n",
    "        np.floor(\n",
    "            np.asarray(params.train.in_patch_size) * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "    ),\n",
    "    stride=1,\n",
    "    meta_keys_to_patch_index={\"dti\", \"mask\", params.data.anat_type},\n",
    "    mask_name=\"mask\",\n",
    ")\n",
    "\n",
    "\n",
    "def fix_downsample_shape_errors(\n",
    "    fr_vol: torch.Tensor, fr_affine: torch.Tensor, target_spatial_shape: tuple\n",
    "):\n",
    "    \"\"\"Small utility to fix shape differences between LR and FR data.\"\"\"\n",
    "    target_shape = np.asarray(target_spatial_shape)\n",
    "    if fr_vol.shape[1:] != tuple(target_shape):\n",
    "        # Use torchio objects because they fix the affine matrix, too.\n",
    "        # Flip before transform to pad on the right/top/furthest side of the dimension\n",
    "        # first, before the left/bottom/closest.\n",
    "        flip_vol = fr_vol.flip([1, 2, 3])\n",
    "        im = torchio.ScalarImage(tensor=flip_vol, affine=fr_affine)\n",
    "        transform = torchio.transforms.CropOrPad(target_spatial_shape, 0, copy=False)\n",
    "        im = transform(im)\n",
    "        result_vol = im[\"data\"]\n",
    "        # Unflip.\n",
    "        result_vol = result_vol.flip([1, 2, 3])\n",
    "        result_aff = im[\"affine\"]\n",
    "    else:\n",
    "        result_vol = fr_vol\n",
    "        result_aff = fr_affine\n",
    "\n",
    "    return result_vol, result_aff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and organize all data.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "meta_keys_to_keep = {\"affine\", \"original_affine\"}\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "    data = dict()\n",
    "    data[\"subj_id\"] = subj_id\n",
    "    fr_subj_dir = subj_dirs[subj_id][\"fr\"]\n",
    "    lr_subj_dir = subj_dirs[subj_id][\"lr\"]\n",
    "    data[\"fr_subj_dir\"] = fr_subj_dir\n",
    "    data[\"lr_subj_dir\"] = lr_subj_dir\n",
    "\n",
    "    # Low-resolution DTI.\n",
    "    lr_dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        lr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(lr_dti_f)\n",
    "    lr_dti, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    lr_dti = torch.from_numpy(lr_dti)\n",
    "    data[\"lr_dti\"] = lr_dti\n",
    "    data[\"lr_dti_meta_dict\"] = meta\n",
    "\n",
    "    # May need to handle shape errors when re-upscaling back from LR to HR.\n",
    "    lr_dti_shape = np.asarray(lr_dti.shape[1:])\n",
    "    target_fr_shape = np.floor(lr_dti_shape * params.net.upscale_factor).astype(int)\n",
    "\n",
    "    # Full-resolution images/volumes.\n",
    "    # DTI.\n",
    "    dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(dti_f)\n",
    "    dti, meta = nib_reader.get_data(im)\n",
    "    dti = torch.from_numpy(dti)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    dti, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        dti, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    data[\"dti\"] = dti\n",
    "    data[\"dti_meta_dict\"] = meta\n",
    "\n",
    "    # Diffusion mask.\n",
    "    mask_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.mask_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(mask_f)\n",
    "    mask, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    mask = torch.from_numpy(mask)\n",
    "    # Add channel dim if not available.\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask[\n",
    "            None,\n",
    "        ]\n",
    "    mask, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        mask, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    mask = mask.bool()\n",
    "    data[\"mask\"] = mask\n",
    "    data[\"mask_meta_dict\"] = meta\n",
    "\n",
    "    # Anatomical/structural volume.\n",
    "    anat_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.anat_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(anat_f)\n",
    "    anat, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    anat = torch.from_numpy(anat)\n",
    "    if anat.ndim == 3:\n",
    "        anat = anat[\n",
    "            None,\n",
    "        ]\n",
    "    anat, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        anat, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    data[params.data.anat_type] = anat\n",
    "    data[params.data.anat_type + \"_meta_dict\"] = meta\n",
    "\n",
    "    vol_names = {\"dti\", \"mask\", \"lr_dti\", params.data.anat_type}\n",
    "    metadata_names = set(data.keys()) - vol_names\n",
    "    vol_d = {k: data[k] for k in vol_names}\n",
    "    meta_d = {k: data[k] for k in metadata_names}\n",
    "\n",
    "    # Create multi-volume dataset for this subj-session.\n",
    "    subj_dataset = pitn.data.SubjSesDataset(\n",
    "        vol_d,\n",
    "        primary_vol_name=\"dti\",\n",
    "        special_secondary2primary_coords_fns=fr2lr_patch_coords_fn,\n",
    "        transform=None,\n",
    "        primary_patch_kwargs=patch_kwargs,\n",
    "        **meta_d\n",
    "    )\n",
    "    print(\"Creating patches\")\n",
    "    # Init the patches dataset.\n",
    "    subj_dataset.patches\n",
    "\n",
    "    # Finalize this subject.\n",
    "    subj_data[subj_id] = subj_dataset\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "print(\"===Data Loaded===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, dpi=120)\n",
    "\n",
    "# sample = subj_data[\"103010\"].patches[20000]\n",
    "# ax1.imshow(sample[\"t2w\"][0, 0, :, 0], cmap=\"gray\", interpolation=None)\n",
    "# ax2.imshow(sample[\"dti\"][0, 0, :, 0], cmap=\"gray\")\n",
    "# ax3.imshow(sample[\"mask\"][0, 0, :, 0], cmap=\"gray\")\n",
    "# ax4.imshow(sample[\"lr_dti\"][0, 0, :, 0], cmap=\"gray\");\n",
    "# print(sample['t2w'].shape, sample['dti'].shape, sample['mask'].shape, sample['lr_dti'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finalize the dataset.\n",
    "# subj_dataset = torchio.SubjectsDataset(list(subj_data.values()), load_getitem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_data)\n",
    "num_test_subjs = int(np.ceil(params.n_subjs * params.test.dataset_subj_percent))\n",
    "num_val_subjs = int(np.ceil(params.n_subjs * params.val.dataset_subj_percent))\n",
    "num_train_subjs = params.n_subjs - (num_test_subjs + num_val_subjs)\n",
    "subj_list = list(subj_data.keys())\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1:\n",
    "    warnings.warn(\n",
    "        \"DEBUG: Only 1 subject selected, mixing training, validation, and testing sets\"\n",
    "    )\n",
    "    num_train_subjs = num_val_subjs = num_test_subjs = 1\n",
    "\n",
    "    test_subjs = subj_list\n",
    "    val_subjs = subj_list\n",
    "    train_subjs = subj_list\n",
    "else:\n",
    "    test_subjs = subj_list[:num_test_subjs]\n",
    "    val_subjs = subj_list[num_test_subjs : (num_test_subjs + num_val_subjs)]\n",
    "    train_subjs = subj_list[(num_test_subjs + num_val_subjs) :]\n",
    "\n",
    "print(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\")\n",
    "print(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\")\n",
    "print(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\")\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\\n\")\n",
    "    f.write(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\\n\")\n",
    "    f.write(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\\n\")\n",
    "\n",
    "logger.add_text(\"train_subjs\", str(train_subjs))\n",
    "logger.add_text(\"val_subjs\", str(val_subjs))\n",
    "logger.add_text(\"test_subjs\", str(test_subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Datasets and DataLoaders for test, validation, and training steps.\n",
    "sample_kws = {\n",
    "    \"subj_id\": \"subj_id\",\n",
    "    \"dti\": \"dti\",\n",
    "    \"lr_dti\": \"lr_dti\",\n",
    "    \"mask\": \"mask\",\n",
    "    params.data.anat_type: params.data.anat_type,\n",
    "}\n",
    "\n",
    "# Train\n",
    "train_ds = list()\n",
    "for subj_id in train_subjs:\n",
    "    train_ds.append(subj_data[subj_id].patches)\n",
    "train_dataset = torch.utils.data.ConcatDataset(train_ds)\n",
    "train_sampler = pitn.samplers.ConcatDatasetBalancedRandomSampler(\n",
    "    train_dataset.datasets,\n",
    "    max_samples_per_dataset=params.train.samples_per_subj_per_epoch,\n",
    ")\n",
    "train_collate_fn = functools.partial(pitn.samplers.collate_dicts, **sample_kws)\n",
    "train_loader = monai.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=params.train.batch_size,\n",
    "    collate_fn=train_collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=7,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# Test & Validation\n",
    "test_val_collate_fn = functools.partial(pitn.samplers.collate_dicts, **sample_kws)\n",
    "\n",
    "test_ds = list()\n",
    "for subj_id in test_subjs:\n",
    "    test_ds.append(subj_data[subj_id])\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_ds)\n",
    "test_loader = monai.data.DataLoader(\n",
    "    test_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")\n",
    "\n",
    "val_ds = list()\n",
    "for subj_id in val_subjs:\n",
    "    val_ds.append(subj_data[subj_id])\n",
    "val_dataset = torch.utils.data.ConcatDataset(val_ds)\n",
    "val_loader = monai.data.DataLoader(\n",
    "    val_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bounding Box Selection for Visualization During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Choose only one subject for visualization during validation.\n",
    "# val_viz_subj_id = random.choice([s.subj_id for s in val_dataset])\n",
    "# # Store its index in the Dataset object for easier indexing.\n",
    "# val_viz_dataset_idx = [s.subj_id for s in val_dataset].index(val_viz_subj_id)\n",
    "# print(val_viz_subj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create bbox coordinates for visualizing validation aggregate patches.\n",
    "# # NOTE: This presumes that there are no overlap patches in the validation step, and that\n",
    "# # each validation volume is divisible by the patch shape in each spatial dimension.\n",
    "# bbox_coords = list()\n",
    "# region_size = torch.as_tensor(output_spatial_patch_shape) * 3\n",
    "# vol_shape = torch.as_tensor(val_dataset[val_viz_dataset_idx].fr_dti.data.shape[1:])\n",
    "# possible_bbox_ini = [\n",
    "#     torch.arange(0, vol_shape[0], output_spatial_patch_shape[0]),\n",
    "#     torch.arange(0, vol_shape[1], output_spatial_patch_shape[1]),\n",
    "#     torch.arange(0, vol_shape[2], output_spatial_patch_shape[2]),\n",
    "# ]\n",
    "\n",
    "# # Create bbox that spans roughly the center of the volume.\n",
    "# bbox_idx_ini = list()\n",
    "# for possible_bbox_part in possible_bbox_ini:\n",
    "#     num_parts = len(possible_bbox_part)\n",
    "#     bbox_idx_ini.append(possible_bbox_part[round(num_parts * 0.4)])\n",
    "# bbox_idx_ini = torch.as_tensor(bbox_idx_ini)\n",
    "\n",
    "# bbox_coord = torch.cat([bbox_idx_ini, bbox_idx_ini + region_size])\n",
    "# bbox_coords.append(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create bbox that covers an edge.\n",
    "# vol_mask = val_dataset[val_viz_dataset_idx].fr_brain_mask.data[0]\n",
    "# bbox_mask_coverage = list()\n",
    "# possible_bbox_coords_ini = list(itertools.product(*possible_bbox_ini))\n",
    "# for bbox_w, bbox_h, bbox_d in possible_bbox_coords_ini:\n",
    "#     bbox_start = (bbox_w, bbox_h, bbox_d)\n",
    "#     bbox_end = (\n",
    "#         bbox_start[0] + output_spatial_patch_shape[0],\n",
    "#         bbox_start[1] + output_spatial_patch_shape[1],\n",
    "#         bbox_start[2] + output_spatial_patch_shape[2],\n",
    "#     )\n",
    "#     patch = vol_mask[\n",
    "#         bbox_start[0] : bbox_end[0],\n",
    "#         bbox_start[1] : bbox_end[1],\n",
    "#         bbox_start[2] : bbox_end[2],\n",
    "#     ]\n",
    "#     # Validation visuals are shown over the Superior-Anterior axis, so the edge should be\n",
    "#     # located there.\n",
    "#     bbox_mask_coverage.append(\n",
    "#         patch[:, output_spatial_patch_shape[1] // 2, :].sum().item()\n",
    "#     )\n",
    "\n",
    "# # Now search all coordinates' mask coverages for the one closest to a 50% of the total\n",
    "# # patch volume.\n",
    "# patch_vol = output_spatial_patch_shape[0] * output_spatial_patch_shape[2]\n",
    "# target_mask_vol = patch_vol // (2 ** 2)\n",
    "\n",
    "# bbox_coord_idx = np.argmin(np.abs(np.asarray(bbox_mask_coverage) - patch_vol))\n",
    "# bbox_idx_ini = torch.tensor(possible_bbox_coords_ini[bbox_coord_idx])\n",
    "# bbox_coord = torch.cat([bbox_idx_ini, bbox_idx_ini + region_size])\n",
    "# bbox_coords.append(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bbox_coords = torch.stack(bbox_coords)\n",
    "\n",
    "# bbox_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "debug_prob = -1 / (\n",
    "    params.train.samples_per_subj_per_epoch * len(train_subjs) / params.train.batch_size\n",
    ")\n",
    "\n",
    "\n",
    "class DIQTCascadeSystem(pl.LightningModule):\n",
    "\n",
    "    # Specify training loss methods with mappings to their names as strings.\n",
    "    loss_methods = {\n",
    "        \"MSE\".casefold(): torch.nn.MSELoss(reduction=\"mean\"),\n",
    "        \"SSE\".casefold(): torch.nn.MSELoss(reduction=\"sum\"),\n",
    "        \"RMSE\".casefold(): lambda y_hat, y: torch.sqrt(\n",
    "            F.mse_loss(y_hat, y, reduction=\"mean\")\n",
    "        ),\n",
    "        \"L1\".casefold(): torch.nn.L1Loss(reduction=\"mean\"),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        in_patch_shape: tuple,\n",
    "        upscale_factor: int,\n",
    "        anat_batch_key: str,\n",
    "        train_loss_method: str,\n",
    "        opt_params: dict,\n",
    "        val_viz_every_n_epochs=1,\n",
    "        **net_kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = channels\n",
    "        self._in_patch_shape = in_patch_shape\n",
    "        self._anat_batch_key = anat_batch_key\n",
    "        self._upscale_factor = upscale_factor\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = pitn.nn.sr.CascadeUpsampleModeRefine(\n",
    "            self._channels, upscale_factor=self._upscale_factor, **net_kwargs\n",
    "        )\n",
    "\n",
    "        ## Training parameters\n",
    "        self.opt_params = opt_params\n",
    "\n",
    "        # Select loss method as either one of the pre-selected methods, or a custom\n",
    "        # callable.\n",
    "        try:\n",
    "            self._loss_fn = self.loss_methods[train_loss_method.casefold()]\n",
    "        except (AttributeError, KeyError):\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"ERROR: Invalid loss function specification {train_loss_method}, \"\n",
    "                    + f\"expected one of {self.loss_methods.keys()} or a callable.\"\n",
    "                )\n",
    "\n",
    "        self._val_viz_every_n_epochs = val_viz_every_n_epochs\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = Box(\n",
    "            {\n",
    "                \"train_loss\": list(),\n",
    "                \"val_loss\": {\"rmse\": list()},\n",
    "                \"test_loss\": {\"rmse\": dict()},\n",
    "                \"viz\": {\n",
    "                    \"test_preds\": dict(),\n",
    "                    \"test_squared_error\": dict(),\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_mode_refine):\n",
    "        y = self.net(x, x_mode_refine)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = Box(batch)\n",
    "        x = batch.lr_dti\n",
    "        y = batch.dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine)\n",
    "\n",
    "        # Only calculate loss on voxels in the brain mask.\n",
    "        loss = self._loss_fn(\n",
    "            torch.masked_select(y_pred, mask), torch.masked_select(y, mask)\n",
    "        )\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        x = batch.lr_dti\n",
    "        y = batch.dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine)\n",
    "\n",
    "        rmse_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                torch.masked_select(y_pred, mask),\n",
    "                torch.masked_select(y, mask),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.log(\"val_loss/rmse\", rmse_loss)\n",
    "        self.plain_log.val_loss.rmse.append(float(rmse_loss.cpu()))\n",
    "\n",
    "        return rmse_loss\n",
    "\n",
    "    def test_step(self, batch: dict, batch_idx):\n",
    "        batch = Box(batch)\n",
    "        subj_id = batch.subj_id[0]\n",
    "        x = batch.lr_dti\n",
    "        y = batch.dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine)\n",
    "\n",
    "        rmse_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                torch.masked_select(y_pred, mask),\n",
    "                torch.masked_select(y, mask),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.log(\"test_loss/rmse\", rmse_loss)\n",
    "        self.plain_log.test_loss.rmse[subj_id] = rmse_loss.detach().cpu().item()\n",
    "        self.plain_log.viz.test_preds[subj_id] = y_pred[0].detach().cpu()\n",
    "\n",
    "        return rmse_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), **self.opt_params)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = (np.arange(12) ** 2).reshape(4, 3).tolist()\n",
    "nrow = 4\n",
    "ncol = 3\n",
    "print(x)\n",
    "rows = [l[i] for i in range(ncol) for l in itertools.chain(x)]\n",
    "rows = [rows[s:s+ncol] for s in range(0, nrow*ncol, ncol)]\n",
    "rows\n",
    "# row_heights = [sum(map(lambda im: im.shape[0] if im is not None else 0), r)) for r in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "model = DIQTCascadeSystem(\n",
    "    channels=params.n_channels,\n",
    "    in_patch_shape=params.train.in_patch_size,\n",
    "    upscale_factor=params.net.upscale_factor,\n",
    "    anat_batch_key=params.data.anat_type,\n",
    "    train_loss_method=params.train.loss_name,\n",
    "    opt_params=params.optim.kwargs,\n",
    "    val_viz_every_n_epochs=1,\n",
    "    **params.net.kwargs,\n",
    ")\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Model overview: {model}\\n\")\n",
    "\n",
    "# Create trainer object.\n",
    "trainer = pl.Trainer(\n",
    "    #     fast_dev_run=10,\n",
    "    gpus=1,\n",
    "    max_epochs=params.train.max_epochs,\n",
    "    # max_epochs=1,\n",
    "    logger=pl_logger,\n",
    "    log_every_n_steps=50,\n",
    "    check_val_every_n_epoch=2,\n",
    "    detect_anomaly=True,\n",
    ")\n",
    "\n",
    "# Many warnings are produced here, so it's better for my sanity (i.e., worse in every other\n",
    "# way) to just filter and ignore them...\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out trained model\n",
    "trainer.save_checkpoint(str(experiment_results_dir / \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + params.train.loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store test reconstructions along the way for later visualization.\n",
    "test_vol_viz = Addict()\n",
    "\n",
    "# Structure is as follows:\n",
    "# {subj_id_1:\n",
    "#    fr_mask: np.ndarray,\n",
    "#    dti: {\n",
    "#          diqt: np.ndarray,\n",
    "#          spline: np.ndarray,\n",
    "#          fr: np.ndarray,\n",
    "#          lr: np.ndarray\n",
    "#          ...\n",
    "#         }\n",
    "#    fa: {\n",
    "#         diqt: np.ndarray,\n",
    "#         ...\n",
    "#        },\n",
    "# pitn.data.norm.denormalize_batch(y, mean=fr_means, var=fr_vars, eps=self._norm_eps)\n",
    "#  subj_id_2:\n",
    "#     ....\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Debug code for model editing after training has been completed.\n",
    "\n",
    "# # If the model needs to be created, a.k.a. the training loop cell wasn't executed.\n",
    "# model = DIQTSystem(\n",
    "#     channels=channels,\n",
    "#     downsample_factor=exp_params.downsample_factor,\n",
    "#     source_vox_size=exp_params.source_vox_size,\n",
    "#     target_vox_size=exp_params.target_vox_size,\n",
    "#     norm_method=network_norm_method,\n",
    "#     train_loss_method=train_loss_name,\n",
    "#     opt_params=opt_params,\n",
    "#     val_viz_subj_id=val_viz_subj_id,\n",
    "#     val_viz_bboxes=bbox_coords,\n",
    "#     val_viz_every_n_epochs=5,\n",
    "# )\n",
    "\n",
    "# model.load_from_checkpoint(\n",
    "#     experiment_results_dir / \"model.ckpt\",,\n",
    "#     channels=channels,\n",
    "#     downsample_factor=exp_params.downsample_factor,\n",
    "#     source_vox_size=exp_params.source_vox_size,\n",
    "#     target_vox_size=exp_params.target_vox_size,\n",
    "#     norm_method=network_norm_method,\n",
    "#     train_loss_method=train_loss_name,\n",
    "#     opt_params=opt_params,\n",
    "#     val_viz_subj_id=val_viz_subj_id,\n",
    "#     val_viz_bboxes=bbox_coords,\n",
    "#     val_viz_every_n_epochs=5,\n",
    "# )\n",
    "\n",
    "# trainer.test(model, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "plt.imshow(model.plain_log.viz.test_preds[\"103010\"].cpu().numpy()[2, 80])\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store DIQT test reconstructions for visualization.\n",
    "for subj_id in test_subjs:\n",
    "    test_vol_viz[subj_id].dti.diqt = (\n",
    "        model.plain_log.viz.test_preds[subj_id].cpu().numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_vol_viz.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss_name = \"RMSE\"\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Test loss function: {test_loss_name}\\n\")\n",
    "\n",
    "row_iter = enumerate(list(model.plain_log[\"test_loss\"].values()))\n",
    "test_loss_tabular = \"\".join([f\"{batch_idx}, {loss}\\n\" for batch_idx, loss in row_iter])\n",
    "\n",
    "with open(test_loss_log_file, \"a+\") as f:\n",
    "    f.write(\"batch_idx, loss\\n\")\n",
    "    f.write(test_loss_tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.plain_log.test_loss.rmse.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = False\n",
    "\n",
    "hist = sns.histplot(\n",
    "    list(model.plain_log[\"test_loss\"].rmse.values()),\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    "    hatch=\"\\\\\\\\\",\n",
    "    ec=\"blue\",\n",
    ")\n",
    "hist.yaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"-\", \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "# Tanno, et. al., 2021 model comparisons.\n",
    "# Taken from Table 2, HCP exterior.\n",
    "plt.axvline(\n",
    "    31.738e-4,\n",
    "    label=\"(Tanno etal, 2021) C-spline Mean\",\n",
    "    color=\"red\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    23.139e-4,\n",
    "    label=\"(Tanno etal, 2021) RF\",\n",
    "    color=\"orange\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.609e-4,\n",
    "    label=\"(Tanno etal, 2021) ESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.412e-4,\n",
    "    label=\"(Tanno etal, 2021) Best\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    12.78e-4,\n",
    "    label=\"(Blumberg etal, 2018) Best\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(f\"Test Loss Histogram Over All Subjects with Test Metric {test_loss_name}\")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all subjects.\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "\n",
    "models = (\n",
    "    \"(Ours)\\nCurrent Model\",\n",
    "    \"(Tanno etal, 2021)\\nC-spline Mean\",\n",
    "    \"(Tanno etal, 2021)\\nRF\",\n",
    "    \"(Tanno etal, 2021)\\nESPCN Baseline\",\n",
    "    \"(Tanno etal, 2021)\\nBest\",\n",
    "    \"(Blumberg etal, 2018)\\nBest\",\n",
    ")\n",
    "\n",
    "rmse_scores = (\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    31.738e-4,\n",
    "    23.139e-4,\n",
    "    13.609e-4,\n",
    "    13.412e-4,\n",
    "    12.13e-4,\n",
    ")\n",
    "rmse_std_error = np.asarray([0, 0, 0.351e-4, 0.084e-4, 0.041e-4, 1.24e-4])\n",
    "\n",
    "ax.grid(True, axis=\"y\", zorder=1000)\n",
    "ax.set_axisbelow(True)\n",
    "ax.bar(\n",
    "    models,\n",
    "    rmse_scores,\n",
    "    yerr=rmse_std_error,\n",
    "    color=sns.color_palette(\"deep\", n_colors=len(rmse_scores)),\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    if isinstance(container, mpl.container.BarContainer):\n",
    "        ax.bar_label(container, fmt=\"%.3e\")\n",
    "\n",
    "ax.set_ylim(bottom=0, top=ax.get_ylim()[1] * 1.1)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "ax.set_title(f\"Mean Over Subjects Test Loss {test_loss_name}\")\n",
    "ax.set_xticks(models)\n",
    "ax.set_xticklabels(\n",
    "    models, fontsize=\"x-small\", rotation=25, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.plain_log[\"test_loss\"])\n",
    "print(np.mean(list(model.plain_log[\"test_loss\"].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_test_idx = np.argsort(np.asarray(list(model.plain_log[\"test_loss\"].values())))\n",
    "sorted_test_results = dict(\n",
    "    list(model.plain_log[\"test_loss\"].items())[i] for i in sorted_test_idx\n",
    ")\n",
    "ppr(sorted_test_results, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.add_histogram(\n",
    "    \"test/rmse_dist\", np.asarray(list(model.plain_log[\"test_loss\"].values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save out metrics and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_hparams.metric[\"hparam/rmse\"] = np.mean(\n",
    "    list(model.plain_log[\"test_loss\"].values())\n",
    ")\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\n",
    "        f\"Mean RMSE Testing Value: {np.mean(list(model.plain_log['test_loss'].values()))}\\n\"\n",
    "    )\n",
    "    f.write(f\"Mean RMSE Spline Value: {spline_loss_mean}\\n\")\n",
    "\n",
    "logger.add_scalar(\"metric/rmse\", np.mean(list(model.plain_log[\"test_loss\"].values())))\n",
    "logger.add_scalar(\"metric/spline\", spline_loss_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debug flag(s)\n",
    "disable_fig_save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volume of full-res ground truth, low-res downsample, full-res mask, and\n",
    "# full-res predictions.\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj_i in test_dataset:\n",
    "        subj = copy.copy(subj_i)\n",
    "        subj_id = subj[\"subj_id\"]\n",
    "        print(f\"Starting subject {subj_id}\")\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "        fr_vol = subj[\"gt_dti\"][\"data\"].clone()\n",
    "        lr_vol = subj[\"lr_dti\"][\"data\"].clone()\n",
    "\n",
    "        full_res_predicted = torch.from_numpy(test_vol_viz[subj_id].dti.diqt.copy())\n",
    "        full_res_spline = torch.from_numpy(test_vol_viz[subj_id].dti.spline.copy())\n",
    "\n",
    "        #         warnings.warn(\"======== Skipping all de-normalization for visualization.\")\n",
    "        #         if False:\n",
    "        if data_norm_method is not None and \"channel\" in data_norm_method.casefold():\n",
    "            print(\"Normalizing\")\n",
    "\n",
    "            lr_means = torch.as_tensor(subj[\"lr_means\"]).to(lr_vol).clone()\n",
    "            lr_vars = torch.as_tensor(subj[\"lr_vars\"]).to(lr_vol).clone()\n",
    "\n",
    "            lr_vol = pitn.data.norm.denormalize_dti(\n",
    "                lr_vol, mean=lr_means, var=lr_vars\n",
    "            ).clone()\n",
    "\n",
    "        # Zero-out all voxels outside the mask.\n",
    "\n",
    "        fr_mask = subj[\"fr_brain_mask\"][\"data\"].bool().clone()\n",
    "        full_res_spline = full_res_spline * fr_mask.to(full_res_spline).bool()\n",
    "        fr_vol = fr_vol * fr_mask.to(fr_vol).bool()\n",
    "        full_res_predicted = full_res_predicted * fr_mask.to(full_res_predicted).bool()\n",
    "        lr_vol = lr_vol * subj[\"lr_brain_mask\"][\"data\"].to(lr_vol).bool()\n",
    "        abs_error = torch.abs(full_res_predicted - fr_vol)\n",
    "\n",
    "        test_vol_viz[subj.subj_id].dti.update(\n",
    "            fr=fr_vol.cpu().numpy(),\n",
    "            lr=lr_vol.cpu().numpy(),\n",
    "            diqt=full_res_predicted.cpu().numpy(),\n",
    "            spline=full_res_spline.cpu().numpy(),\n",
    "        )\n",
    "\n",
    "        test_vol_viz[subj.subj_id].fa.update(\n",
    "            itertools.starmap(\n",
    "                lambda k, v: (k, pitn.viz.fa_map(test_vol_viz[subj_id].dti[k])),\n",
    "                test_vol_viz[subj_id].dti.items(),\n",
    "            )\n",
    "        )\n",
    "        test_vol_viz[subj_id].fr_mask = fr_mask.cpu().numpy()\n",
    "        test_vol_viz[subj_id].dti.abs_error = abs_error.cpu().numpy()\n",
    "\n",
    "        print(f\"Finished subject {subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out all network predictions to Nifti2 files and compress them into a zip archive.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in test_vol_viz.items():\n",
    "        pred_vol = viz.dti.diqt\n",
    "        affine = subj_data[subj_id][\"gt_dti\"].affine\n",
    "        nib_img = nib.Nifti2Image(pred_vol, affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_dti.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(experiment_results_dir / \"predicted_dti.zip\", \"w\") as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=6,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "    # Make sure we exit the 'with' statement above.\n",
    "    print(\"Done with files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz_subj_idx = random.choice(list(range(len(test_vol_viz.keys()))))\n",
    "# viz_subj_id = list(test_vol_viz.keys())[viz_subj_idx]\n",
    "# Pick the worst performing subject from the test set.\n",
    "viz_subj_id = list(sorted_test_results.keys())[-1]\n",
    "print(list(test_vol_viz.keys()))\n",
    "print(viz_subj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA-Weighted Direction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for prediction.\n",
    "pred_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.diqt)\n",
    "# Set channels last for matplotlib\n",
    "pred_dir_map = pred_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.diqt = pred_dir_map\n",
    "\n",
    "spline_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.spline)\n",
    "# Set channels last for matplotlib\n",
    "spline_dir_map = spline_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.spline = spline_dir_map\n",
    "\n",
    "fr_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.fr)\n",
    "# Set channels last for matplotlib\n",
    "fr_dir_map = fr_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.fr = fr_dir_map\n",
    "\n",
    "lr_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.lr)\n",
    "# Set channels last for matplotlib\n",
    "lr_dir_map = lr_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.lr = lr_dir_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_idx = (slice(None, None, None), slice(None, None, None), 86)\n",
    "low_res_slice_idx = tuple(\n",
    "    int(np.round(s / downsample_factor)) if isinstance(s, int) else s for s in slice_idx\n",
    ")\n",
    "print(slice_idx)\n",
    "print(low_res_slice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(pred_dir_map[slice_idx]), interpolation=\"none\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Predicted with DIQT Net\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"pred_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(fr_dir_map[slice_idx]), interpolation=\"none\")\n",
    "# plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Ground Truth\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"ground_truth_dir_map_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(spline_dir_map[slice_idx]), interpolation=\"none\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Spline Interpolation Order {exp_params.spline.order}\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"cubic_spline_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(lr_dir_map[low_res_slice_idx]), interpolation=\"none\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"LR Input\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"low_res_map_sample.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DTI Channel-Wise Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"$D_{x,x}$\",\n",
    "    \"$D_{x,y}$\",\n",
    "    \"$D_{y,y}$\",\n",
    "    \"$D_{x,z}$\",\n",
    "    \"$D_{y,z}$\",\n",
    "    \"$D_{z,z}$\",\n",
    "]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    f\"Spline Order {exp_params.spline.order}\",\n",
    "    \"Predicted\",\n",
    "    \"Absolute Error\\nFR vs. Predicted\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "cmap = \"jet\"\n",
    "\n",
    "dtis = [\n",
    "    test_vol_viz[viz_subj_id].dti.fr[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.lr[(slice(None), *low_res_slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.spline[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.diqt[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.abs_error[(slice(None), *slice_idx)],\n",
    "]\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95)\n",
    "min_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05)\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dti,\n",
    "            vmax=max_dti,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "color_norm = mpl.colors.Normalize(vmin=min_dti, vmax=max_dti)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap),\n",
    "    ax=axs,\n",
    "    location=\"right\",\n",
    "    fraction=0.1,\n",
    "    pad=0.03,\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Normalized over All Images\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"DTI_channel_sample_global_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel-Wise Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, low-res input, and root squared error\n",
    "# Normalize by index in the DTI coefficients.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "\n",
    "cmap = \"coolwarm\"\n",
    "dtis = [\n",
    "    test_vol_viz[viz_subj_id].dti.fr[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.lr[(slice(None), *low_res_slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.spline[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.diqt[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.abs_error[(slice(None), *slice_idx)],\n",
    "]\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "max_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95, axis=1\n",
    ")\n",
    "min_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05, axis=1\n",
    ")\n",
    "\n",
    "max_dtis = np.max(np.abs([max_dtis, min_dtis]), axis=0)\n",
    "min_dtis = -1 * max_dtis\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "    axs_cols = list()\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dtis[j_col],\n",
    "            vmax=max_dtis[j_col],\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        axs_cols.append(ax)\n",
    "\n",
    "    axs.append(axs_cols)\n",
    "\n",
    "# Place colorbars on each column.\n",
    "for j_col in range(ncols):\n",
    "\n",
    "    full_col_ax = [axs[i][j_col] for i in range(nrows)]\n",
    "\n",
    "    color_norm = mpl.colors.Normalize(vmin=min_dtis[j_col], vmax=max_dtis[j_col])\n",
    "\n",
    "    color_mappable = mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap)\n",
    "    cbar = fig.colorbar(\n",
    "        color_mappable,\n",
    "        ax=full_col_ax,\n",
    "        location=\"top\",\n",
    "        orientation=\"horizontal\",\n",
    "        pad=0.01,\n",
    "        shrink=0.85,\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=8, rotation=35)\n",
    "    cbar.ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:g}\"))\n",
    "#     cbar.ax.ticklabel_format(scilimits=(3, -3), useOffset=False)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Channel-Wise Normalization\",\n",
    "    y=max_subplot_height + 0.01,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"DTI_channel_sample_channel_wise_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FA Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Slice locations for 2D visualization\n",
    "\n",
    "half_fr_space_shape = np.floor(\n",
    "    np.asarray(test_vol_viz[viz_subj_id].fa.fr.shape) // 2\n",
    ").astype(int)\n",
    "half_fr_space_shape = half_fr_space_shape.tolist()\n",
    "\n",
    "slice_indices = [\n",
    "    (half_fr_space_shape[0], slice(None, None, None), slice(None, None, None)),\n",
    "    (slice(None, None, None), half_fr_space_shape[1], slice(None, None, None)),\n",
    "    (slice(None, None, None), slice(None, None, None), half_fr_space_shape[2]),\n",
    "]\n",
    "\n",
    "low_res_slice_indices = list()\n",
    "for slice_idx_i in slice_indices:\n",
    "    slice_coords = tuple()\n",
    "    for s in slice_idx_i:\n",
    "        slice_coords = slice_coords + (\n",
    "            int(np.floor(s / downsample_factor)) if isinstance(s, int) else s,\n",
    "        )\n",
    "    low_res_slice_indices.append(slice_coords)\n",
    "\n",
    "print(slice_indices)\n",
    "print()\n",
    "print(low_res_slice_indices)\n",
    "\n",
    "row_names = [\n",
    "    \"Saggital\",\n",
    "    \"Coronal\",\n",
    "    \"Horizontal\",\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    f\"Spline Order {exp_params.spline.order}\",\n",
    "    \"Predicted\",\n",
    "    #     \"Absolute Error\\nFR vs. Predicted\",\n",
    "]\n",
    "\n",
    "nrows = len(row_names)\n",
    "ncols = len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = dict()\n",
    "for i_row, slice_i in enumerate(slice_indices):\n",
    "    low_res_slice_i = low_res_slice_indices[i_row]\n",
    "    imgs[i_row] = dict()\n",
    "    col_imgs = [\n",
    "        test_vol_viz[viz_subj_id].fa.fr[(*slice_i,)],\n",
    "        test_vol_viz[viz_subj_id].fa.lr[(*low_res_slice_i,)],\n",
    "        test_vol_viz[viz_subj_id].fa.spline[(*slice_i,)],\n",
    "        test_vol_viz[viz_subj_id].fa.diqt[(*slice_i,)],\n",
    "        #         test_vol_viz[viz_subj_id].fa.abs_error[(*slice_i,)],\n",
    "    ]\n",
    "\n",
    "    imgs[i_row].update(tuple(enumerate(col_imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "cmap = \"gist_gray\"\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Concatenate the images in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_intensity = np.quantile(\n",
    "    np.concatenate(\n",
    "        [imgs[i][j] for (i, j) in itertools.product(range(nrows), range(ncols))],\n",
    "        axis=None,\n",
    "    ),\n",
    "    0.95,\n",
    ")\n",
    "min_intensity = np.quantile(\n",
    "    np.concatenate(\n",
    "        [imgs[i][j] for (i, j) in itertools.product(range(nrows), range(ncols))],\n",
    "        axis=None,\n",
    "    ),\n",
    "    0.05,\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(5 * 1.5, 3 * 1.5), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    img_row = imgs[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(img_row[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_intensity,\n",
    "            vmax=max_intensity,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(row_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(model_names[j_col], size=\"small\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "color_norm = mpl.colors.Normalize(vmin=min_intensity, vmax=max_intensity)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap),\n",
    "    ax=axs,\n",
    "    location=\"right\",\n",
    "    fraction=0.1,\n",
    "    pad=0.03,\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"FA Maps, Normalized over All Images\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"fa_sample_global_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl_logger.experiment.flush()\n",
    "# Close tensorboard logger.\n",
    "# Don't finalize if the experiment was for debugging.\n",
    "if \"debug\" not in EXPERIMENT_NAME.casefold():\n",
    "    pl_logger.finalize(\"success\")\n",
    "    # Experiment is complete, move the results directory to its final location.\n",
    "    if experiment_results_dir != final_experiment_results_dir:\n",
    "        print(\"Moving out of tmp location\")\n",
    "        experiment_results_dir = experiment_results_dir.rename(\n",
    "            final_experiment_results_dir\n",
    "        )\n",
    "        log_txt_file = experiment_results_dir / log_txt_file.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
