{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pain in the Net\n",
    "Application of Deep Image Quality Transfer (DIQT) with domain adaptation.\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "References:\n",
    "\n",
    "* `R. Tanno et al., “Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion MRI,” NeuroImage, vol. 225, p. 117366, Jan. 2021, doi: 10.1016/j.neuroimage.2020.117366.`\n",
    "* `D. C. Alexander et al., “Image quality transfer and applications in diffusion MRI,” NeuroImage, vol. 152, pp. 283–298, May 2017, doi: 10.1016/j.neuroimage.2017.02.089.`\n",
    "* `S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipyplot\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "from addict import Addict\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "import box\n",
    "from box import Box\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import pitn\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    # Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(\"CuDNN convolution optimization enabled.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "    # GPU information\n",
    "    try:\n",
    "        gpu_info = pitn.utils.system.get_gpu_specs()\n",
    "        print(gpu_info)\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2022-02-07T20:28:14.236511+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-91-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 61be6a52797624cf59758b441ee67f9ab3096d94\n",
      "\n",
      "torchio          : 0.18.30\n",
      "pytorch_lightning: 1.5.9\n",
      "dipy             : 1.4.1\n",
      "natsort          : 7.1.1\n",
      "pandas           : 1.2.3\n",
      "torch            : 1.10.0\n",
      "seaborn          : 0.11.1\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "scipy            : 1.5.3\n",
      "nibabel          : 3.2.1\n",
      "skimage          : 0.18.1\n",
      "numpy            : 1.20.2\n",
      "box              : 5.4.1\n",
      "matplotlib       : 3.4.1\n",
      "pitn             : 0.0.post1.dev132+g02c0d1a\n",
      "monai            : 0.8.0\n",
      "json             : 2.0.9\n",
      "\n",
      "==================================================GPU Specs==================================================\n",
      "  id  Name                Driver Version    CUDA Version  Total Memory    uuid\n",
      "----  ----------------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  NVIDIA TITAN RTX            470.86            11.3  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"])\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameter Reading & Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Here are all the parameters! This makes it easy to find them! </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = Box(default_box=True)\n",
    "\n",
    "# General experiment-wide params\n",
    "###############################################\n",
    "params.experiment_name = \"debug_rmse_metrics\"\n",
    "###############################################\n",
    "# 6 channels for the 6 DTI components\n",
    "params.n_channels = 6\n",
    "params.n_subjs = 16\n",
    "params.lr_vox_size = 2.5\n",
    "params.fr_vox_size = 1.25\n",
    "params.use_anat = True\n",
    "\n",
    "# Data params\n",
    "params.data.fr_dir = data_dir / f\"scale-{params.fr_vox_size:.2f}mm\"\n",
    "params.data.lr_dir = data_dir / f\"scale-{params.lr_vox_size:.2f}mm\"\n",
    "params.data.dti_fname_pattern = r\"sub-*dti.nii.gz\"\n",
    "params.data.mask_fname_pattern = r\"dti/sub-*mask.nii.gz\"\n",
    "params.data.anat_type = \"t2w\"\n",
    "params.data.anat_fname_pattern = f\"sub-*{params.data.anat_type}.nii.gz\"\n",
    "# The data were downsampled artificially by this factor.\n",
    "params.data.downsampled_by_factor = params.lr_vox_size / params.fr_vox_size\n",
    "params.data.downsampled_by_factor = (\n",
    "    int(params.data.downsampled_by_factor)\n",
    "    if int(params.data.downsampled_by_factor) == params.data.downsampled_by_factor\n",
    "    else params.data.downsampled_by_factor\n",
    ")\n",
    "\n",
    "# This is the number of voxels to remove (read: center crop out) from the network's\n",
    "# prediction. This allows for an \"oversampling\" of the low-res voxels to help inform a\n",
    "# more constrained HR prediction. This value of voxels will be removed from each spatial\n",
    "# dimension (D, H, and W) starting at the center of the output patches.\n",
    "# Ex. A size of 1 will remove the 2 outer-most voxels from each dimension in the output,\n",
    "# while still keeping the corresponding voxels in the LR input.\n",
    "params.hr_center_crop_per_side = 0\n",
    "\n",
    "# Quantile clamping to be done on the outer edge of the mask.\n",
    "# NOTE: This clamping *will* effect the test and validation scores, as those voxels\n",
    "# clamped by this are considered as \"errors\"/\"noise\" and will be discarded in testing.\n",
    "# 80,000 is ~ the average volume of the entire brain mask.\n",
    "params.data.edge_correction_max_vox_to_change = 300\n",
    "# params.data.mask_edge_clamp_max_quantile = False\n",
    "# Second data scaling method, where the training data will be scaled and possibly clipped,\n",
    "# but the testing data will be compared on the originals.\n",
    "# Scale input data by the valid values of each channel of the DTI.\n",
    "# I.e., Dx,x in [0, 1], Dx,y in [-1, 1], Dy,y in [0, 1], Dy,z in [-1, 1], etc.\n",
    "params.data.dti_scale_range = ((0, -1, 0, -1, -1, 0), (1, 1, 1, 1, 1, 1))\n",
    "params.data.anat_scale_range = (0, 1)\n",
    "params.data.scale_to_quantiles = (0.0001, 0.9999)\n",
    "params.data.clip_to_quantiles = True\n",
    "\n",
    "# Network params.\n",
    "# The network's goal is to upsample the input by this factor.\n",
    "params.net.upscale_factor = params.data.downsampled_by_factor\n",
    "params.net.kwargs.n_res_units = 3\n",
    "params.net.kwargs.n_dense_units = 3\n",
    "params.net.kwargs.interior_channels = params.n_channels * 2\n",
    "params.net.kwargs.activate_fn = F.elu\n",
    "params.net.kwargs.upsample_activate_fn = F.elu\n",
    "params.net.kwargs.center_crop_output_side_amt = params.hr_center_crop_per_side\n",
    "\n",
    "# Adam optimizer kwargs\n",
    "params.optim.name = \"AdamW\"\n",
    "params.optim.kwargs.lr = 5e-4\n",
    "params.optim.kwargs.betas = (0.9, 0.999)\n",
    "\n",
    "# Testing params\n",
    "params.test.dataset_subj_percent = 0.4\n",
    "\n",
    "# Validation params\n",
    "params.val.dataset_subj_percent = 0.2\n",
    "\n",
    "# Training params\n",
    "params.train.in_patch_size = (24, 24, 24)\n",
    "params.train.batch_size = 32\n",
    "params.train.samples_per_subj_per_epoch = 8000\n",
    "params.train.max_epochs = 50\n",
    "params.train.loss_name = \"mse\"\n",
    "# Percentage of subjs in dataset that go into the training set.\n",
    "params.train.dataset_subj_percent = 1 - (\n",
    "    params.test.dataset_subj_percent + params.val.dataset_subj_percent\n",
    ")\n",
    "\n",
    "# Learning rate scheduler config.\n",
    "params.train.lr_scheduler.name = \"OneCycleLR\"\n",
    "params.train.lr_scheduler.kwargs.max_lr = 3e-3\n",
    "params.train.lr_scheduler.kwargs.epochs = params.train.max_epochs\n",
    "num_test_subjs = int(np.ceil(params.n_subjs * params.test.dataset_subj_percent))\n",
    "num_val_subjs = int(np.ceil(params.n_subjs * params.val.dataset_subj_percent))\n",
    "num_train_subjs = params.n_subjs - (num_test_subjs + num_val_subjs)\n",
    "params.train.lr_scheduler.kwargs.steps_per_epoch = (\n",
    "    params.train.samples_per_subj_per_epoch * num_train_subjs // params.train.batch_size\n",
    ")\n",
    "\n",
    "# If a config file exists, override the defaults with those values.\n",
    "try:\n",
    "    if \"PITN_CONFIG\" in os.environ.keys():\n",
    "        config_fname = Path(os.environ[\"PITN_CONFIG\"])\n",
    "    else:\n",
    "        config_fname = pitn.utils.system.get_file_glob_unique(Path(\".\"), r\"config.*\")\n",
    "    f_type = config_fname.suffix.casefold()\n",
    "    if f_type in {\"yaml\", \"yml\"}:\n",
    "        f_params = Box.from_yaml(config_fname)\n",
    "    elif f_type == \"json\":\n",
    "        f_params = Box.from_json(config_fname)\n",
    "    elif f_type == \"toml\":\n",
    "        f_params = Box.from_toml(config_fname)\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    params.merge_update(f_params)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Remove the default_box behavior now that params have been fully read in.\n",
    "p = Box(default_box=False)\n",
    "p.merge_update(params)\n",
    "params = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose a subset of all params as the hyperparams of the model.\n",
    "hyperparams = Box(\n",
    "    batch_size=params.train.batch_size,\n",
    "    samples_per_subj_epoch=params.train.samples_per_subj_per_epoch,\n",
    "    epochs=params.train.max_epochs,\n",
    "    loss_fn=params.train.loss_name,\n",
    "    lr_scheduler=params.train.lr_scheduler.name,\n",
    "    optim=params.optim.name,\n",
    "    anat=params.data.anat_type if params.use_anat else False,\n",
    "    n_subjs=params.n_subjs,\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = params.experiment_name\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 5\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07T20_28_14__debug_rmse_metrics\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # Parameters.\n",
    "    f.write(pprint.pformat(params.to_dict()) + \"\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'103010': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-103010'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-103010')},\n",
      " '135528': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-135528'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-135528')},\n",
      " '140117': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-140117'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-140117')},\n",
      " '141422': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-141422'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-141422')},\n",
      " '156637': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-156637'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-156637')},\n",
      " '185947': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-185947'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-185947')},\n",
      " '224022': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-224022'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-224022')},\n",
      " '227432': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-227432'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-227432')},\n",
      " '303624': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-303624'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-303624')},\n",
      " '397154': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-397154'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-397154')},\n",
      " '644246': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-644246'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-644246')},\n",
      " '700634': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-700634'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-700634')},\n",
      " '751348': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-751348'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-751348')},\n",
      " '753251': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-753251'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-753251')},\n",
      " '810439': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-810439'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-810439')},\n",
      " '894774': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-894774'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-894774')}}\n"
     ]
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: Box = Box()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "sampled_subjs = random.sample(selected_ids, params.n_subjs)\n",
    "if len(sampled_subjs) < len(selected_ids):\n",
    "    warnings.warn(\n",
    "        f\"WARNING: Sub-selecting {len(sampled_subjs)}/{len(selected_ids)} \"\n",
    "        + \"participants for dev and debugging. \"\n",
    "        + f\"Subj IDs selected: {sampled_subjs}\"\n",
    "    )\n",
    "selected_subjs = sampled_subjs\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_subjs = natsorted(selected_subjs)\n",
    "\n",
    "for subj_id in selected_subjs:\n",
    "    subj_dirs[subj_id] = Box()\n",
    "    subj_dirs[subj_id].fr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.fr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    subj_dirs[subj_id].lr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.lr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    assert subj_dirs[subj_id].fr.exists()\n",
    "    assert subj_dirs[subj_id].lr.exists()\n",
    "ppr(subj_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep for Dataset loading.\n",
    "\n",
    "# Data reader object for NIFTI files.\n",
    "nib_reader = monai.data.NibabelReader(as_closest_canonical=True)\n",
    "\n",
    "# HR -> LR patch coordinate conversion function.\n",
    "fr2lr_patch_coords_fn = {\n",
    "    \"lr_dti\": functools.partial(\n",
    "        pitn.coords.transform.int_downscale_patch_idx,\n",
    "        downscale_factor=params.data.downsampled_by_factor,\n",
    "        downscale_patch_shape=params.train.in_patch_size,\n",
    "    )\n",
    "}\n",
    "\n",
    "# Kwargs for the patches dataset (the _VolPatchDataset class) of the HR volumes.\n",
    "patch_kwargs = dict(\n",
    "    patch_shape=tuple(\n",
    "        np.floor(\n",
    "            np.asarray(params.train.in_patch_size) * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "    ),\n",
    "    stride=1,\n",
    "    meta_keys_to_patch_index={\"dti\", \"mask\", params.data.anat_type},\n",
    "    mask_name=\"mask\",\n",
    ")\n",
    "\n",
    "\n",
    "def fix_downsample_shape_errors(\n",
    "    fr_vol: torch.Tensor, fr_affine: torch.Tensor, target_spatial_shape: tuple\n",
    "):\n",
    "    \"\"\"Small utility to fix shape differences between LR and FR data.\"\"\"\n",
    "    target_shape = np.asarray(target_spatial_shape)\n",
    "    if fr_vol.shape[1:] != tuple(target_shape):\n",
    "        # Use torchio objects because they fix the affine matrix, too.\n",
    "        # Flip before transform to pad on the right/top/furthest side of the dimension\n",
    "        # first, before the left/bottom/closest.\n",
    "        flip_vol = fr_vol.flip([1, 2, 3])\n",
    "        im = torchio.ScalarImage(tensor=flip_vol, affine=fr_affine)\n",
    "        transform = torchio.transforms.CropOrPad(target_spatial_shape, 0, copy=False)\n",
    "        im = transform(im)\n",
    "        result_vol = im[\"data\"]\n",
    "        # Unflip.\n",
    "        result_vol = result_vol.flip([1, 2, 3])\n",
    "        result_aff = im[\"affine\"]\n",
    "    else:\n",
    "        result_vol = fr_vol\n",
    "        result_aff = fr_affine\n",
    "\n",
    "    return result_vol, result_aff\n",
    "\n",
    "\n",
    "def orient_to_viz(vol, affine):\n",
    "\n",
    "    if torch.is_tensor(vol):\n",
    "        v = vol.detach().cpu().numpy()\n",
    "    else:\n",
    "        v = vol\n",
    "    v = np.rot90(np.rot90(v, k=1, axes=(1, 3)), k=2, axes=(2, 3))\n",
    "    if torch.is_tensor(vol):\n",
    "        v = torch.from_numpy(np.copy(v)).to(vol)\n",
    "\n",
    "    # Adjust the affine matrix.\n",
    "    full_rot_aff = np.zeros_like(affine)\n",
    "    full_rot_aff[-1, -1] = 1.0\n",
    "    # 90 degree rot around the second axis.\n",
    "    q1 = nib.quaternions.angle_axis2quat(np.pi / 2, [0, 1, 0])\n",
    "    # 180 degree rot around the first axis.\n",
    "    q2 = nib.quaternions.angle_axis2quat(np.pi, [1, 0, 0])\n",
    "    new_q = nib.quaternions.mult(q1, q2)\n",
    "    rot_aff = nib.quaternions.quat2mat(new_q)\n",
    "    full_rot_aff[:-1, :-1] = rot_aff\n",
    "    new_aff = full_rot_aff @ affine\n",
    "\n",
    "    return v, new_aff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and organize all data.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "meta_keys_to_keep = {\"affine\", \"original_affine\"}\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "    data = dict()\n",
    "    data[\"subj_id\"] = subj_id\n",
    "    fr_subj_dir = subj_dirs[subj_id][\"fr\"]\n",
    "    lr_subj_dir = subj_dirs[subj_id][\"lr\"]\n",
    "    data[\"fr_subj_dir\"] = fr_subj_dir\n",
    "    data[\"lr_subj_dir\"] = lr_subj_dir\n",
    "\n",
    "    # Low-resolution DTI.\n",
    "    lr_dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        lr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(lr_dti_f)\n",
    "    lr_dti, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    lr_dti = torch.from_numpy(lr_dti)\n",
    "    lr_dti, meta[\"affine\"] = orient_to_viz(lr_dti, meta[\"affine\"])\n",
    "    data[\"lr_dti\"] = lr_dti\n",
    "    # Store raw LR DTI for cubic spline comparisons.\n",
    "    data[\"raw_lr_dti\"] = lr_dti\n",
    "    data[\"lr_dti_meta_dict\"] = meta\n",
    "\n",
    "    # May need to handle shape errors when re-upscaling back from LR to HR.\n",
    "    lr_dti_shape = np.asarray(lr_dti.shape[1:])\n",
    "    target_fr_shape = np.floor(lr_dti_shape * params.net.upscale_factor).astype(int)\n",
    "\n",
    "    # Full-resolution images/volumes.\n",
    "    # DTI.\n",
    "    dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(dti_f)\n",
    "    dti, meta = nib_reader.get_data(im)\n",
    "    dti = torch.from_numpy(dti)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    dti, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        dti, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    dti, meta[\"affine\"] = orient_to_viz(dti, meta[\"affine\"])\n",
    "    data[\"dti\"] = dti\n",
    "    # Store raw DTI for validation and testing.\n",
    "    data[\"raw_dti\"] = dti\n",
    "    data[\"dti_meta_dict\"] = meta\n",
    "\n",
    "    # Diffusion mask.\n",
    "    mask_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.mask_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(mask_f)\n",
    "    mask, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    mask = torch.from_numpy(mask)\n",
    "    # Add channel dim if not available.\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask[\n",
    "            None,\n",
    "        ]\n",
    "    mask, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        mask, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    mask, meta[\"affine\"] = orient_to_viz(mask, meta[\"affine\"])\n",
    "    mask = mask.bool()\n",
    "    data[\"mask\"] = mask\n",
    "    data[\"mask_meta_dict\"] = meta\n",
    "\n",
    "    # Anatomical/structural volume.\n",
    "    anat_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.anat_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(anat_f)\n",
    "    anat, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    anat = torch.from_numpy(anat)\n",
    "    if anat.ndim == 3:\n",
    "        anat = anat[\n",
    "            None,\n",
    "        ]\n",
    "    anat, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        anat, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    anat, meta[\"affine\"] = orient_to_viz(anat, meta[\"affine\"])\n",
    "    data[params.data.anat_type] = anat\n",
    "    data[params.data.anat_type + \"_meta_dict\"] = meta\n",
    "\n",
    "    # plt.clf()\n",
    "    # dti = data['dti']\n",
    "    # fig, axs = plt.subplots(nrows=3, dpi=110)\n",
    "    # plt.title(f\"Subject {subj_id}\")\n",
    "    # axs[0].plot(dti.view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # axs[1].plot(dti.permute(0, 2, 1, 3).contiguous().view(6, 174, -1).max(2).values.numpy().T)\n",
    "    # axs[2].plot(dti.permute(0, 3, 1, 2).contiguous().view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # plt.show(close=True)\n",
    "\n",
    "    # Consider this as the \"noise correction\" step to have more understandable,\n",
    "    # stable, and consistent metric results. Otherwise, metrics can change by orders of\n",
    "    # magnitude for no good reason!\n",
    "    if params.data.edge_correction_max_vox_to_change:\n",
    "\n",
    "        correct_dti = pitn.data.norm.correct_edge_noise_with_median(\n",
    "            data[\"dti\"],\n",
    "            data[\"mask\"],\n",
    "            max_num_vox_to_change=params.data.edge_correction_max_vox_to_change,\n",
    "            erosion_st_elem=skimage.morphology.ball(4),\n",
    "            median_st_elem=skimage.morphology.cube(2),\n",
    "        )\n",
    "        print(\"DTI Correction Mean Abs. Error Per Tensor Component: \")\n",
    "        abs_diff = torch.abs(data[\"dti\"] - correct_dti)\n",
    "        mae = abs_diff.view(6, -1).sum(1)\n",
    "        mae = mae / data[\"mask\"].sum()\n",
    "        mae_str = \"\"\n",
    "\n",
    "        for c in range(params.n_channels):\n",
    "            mae_v = mae.detach().cpu()[c]\n",
    "            # iqr = torch.quantile(data[\"dti\"][c][data['mask'][0]], torch.as_tensor([0.25, 0.75]))\n",
    "            # iqr = torch.abs(iqr[1] - iqr[0]).item()\n",
    "            num_changed = (abs_diff[c] > 1e-13).sum().item()\n",
    "            med = torch.median(data[\"dti\"][c][data[\"mask\"][0]]).item()\n",
    "            s = (\n",
    "                \"\\t\"\n",
    "                + str(mae_v.item())\n",
    "                + f\" with {num_changed} changes vs. median \"\n",
    "                + str(med)\n",
    "                + \"\\n\"\n",
    "            )\n",
    "            mae_str = mae_str + s\n",
    "\n",
    "        print(mae_str)\n",
    "        data[\"dti\"] = correct_dti\n",
    "\n",
    "    elif params.data.mask_edge_quantile_clamp:\n",
    "        data[\"dti\"] = pitn.data.norm.mask_constrain_clamp(\n",
    "            data[\"dti\"],\n",
    "            data[\"mask\"],\n",
    "            quantile_clamp=params.data.mask_edge_quantile_clamp,\n",
    "            selection_st_elem=skimage.morphology.ball(2),\n",
    "        )\n",
    "\n",
    "        # cheap_lr_mask = F.interpolate(\n",
    "        #     data[\"mask\"][\n",
    "        #         None,\n",
    "        #     ].float(),\n",
    "        #     size=tuple(data[\"lr_dti\"].shape[1:]),\n",
    "        #     mode=\"nearest\",\n",
    "        # ).bool()[0]\n",
    "        # data[\"lr_dti\"] = pitn.data.norm.mask_constrain_clamp(\n",
    "        #     data[\"lr_dti\"],\n",
    "        #     cheap_lr_mask,\n",
    "        #     quantile_clamp=params.data.mask_edge_quantile_clamp,\n",
    "        #     selection_st_elem=skimage.morphology.ball(1),\n",
    "        # )\n",
    "    # plt.clf()\n",
    "    # dti = data['dti']\n",
    "    # fig, axs = plt.subplots(nrows=3, dpi=110)\n",
    "    # plt.title(f\"Subject {subj_id}\")\n",
    "    # axs[0].plot(dti.view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # axs[1].plot(dti.permute(0, 2, 1, 3).contiguous().view(6, 174, -1).max(2).values.numpy().T)\n",
    "    # axs[2].plot(dti.permute(0, 3, 1, 2).contiguous().view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # plt.show(close=True)\n",
    "\n",
    "    # Perform scaling of input data?\n",
    "    if params.data.dti_scale_range:\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.dti_scale_range[0],\n",
    "            params.data.dti_scale_range[1],\n",
    "            quantile_low=params.data.scale_to_quantiles[0],\n",
    "            quantile_high=params.data.scale_to_quantiles[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=params.n_channels,\n",
    "            clip=params.data.clip_to_quantiles,\n",
    "        )\n",
    "        scaled = scaler.scale(data[\"dti\"], stateful=True, keep_orig=False)\n",
    "        data[\"dti\"] = scaled\n",
    "        data[\"dti_scaler\"] = scaler\n",
    "\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.dti_scale_range[0],\n",
    "            params.data.dti_scale_range[1],\n",
    "            quantile_low=params.data.scale_to_quantiles[0],\n",
    "            quantile_high=params.data.scale_to_quantiles[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=params.n_channels,\n",
    "            clip=params.data.clip_to_quantiles,\n",
    "        )\n",
    "        scaled = scaler.scale(data[\"lr_dti\"], stateful=True, keep_orig=False)\n",
    "        data[\"lr_dti\"] = scaled\n",
    "        data[\"lr_dti_scaler\"] = scaler\n",
    "\n",
    "    # Perform scaling of input data?\n",
    "    if params.data.anat_scale_range:\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.anat_scale_range[0],\n",
    "            params.data.anat_scale_range[1],\n",
    "            quantile_low=params.data.scale_to_quantiles[0],\n",
    "            quantile_high=params.data.scale_to_quantiles[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=1,\n",
    "            clip=params.data.clip_to_quantiles,\n",
    "        )\n",
    "        scaled = scaler.scale(\n",
    "            data[params.data.anat_type], stateful=True, keep_orig=False\n",
    "        )\n",
    "        # *****Disables anat mode refinement*******\n",
    "        # scaled = (scaled * 0) + 1\n",
    "        data[params.data.anat_type] = scaled\n",
    "        data[params.data.anat_type + \"_scaler\"] = scaler\n",
    "\n",
    "    vol_names = {\"dti\", \"mask\", \"lr_dti\", params.data.anat_type}\n",
    "    metadata_names = set(data.keys()) - vol_names\n",
    "    vol_d = {k: data[k] for k in vol_names}\n",
    "    meta_d = {k: data[k] for k in metadata_names}\n",
    "\n",
    "    # Create multi-volume dataset for this subj-session.\n",
    "    subj_dataset = pitn.data.SubjSesDataset(\n",
    "        vol_d,\n",
    "        primary_vol_name=\"dti\",\n",
    "        special_secondary2primary_coords_fns=fr2lr_patch_coords_fn,\n",
    "        transform=None,\n",
    "        primary_patch_kwargs=patch_kwargs,\n",
    "        **meta_d,\n",
    "    )\n",
    "    print(\"Creating patches\")\n",
    "    # Init the patches dataset.\n",
    "    subj_dataset.patches\n",
    "\n",
    "    # Finalize this subject.\n",
    "    subj_data[subj_id] = subj_dataset\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "print(\"===Data Loaded===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_data)\n",
    "num_test_subjs = int(np.ceil(params.n_subjs * params.test.dataset_subj_percent))\n",
    "num_val_subjs = int(np.ceil(params.n_subjs * params.val.dataset_subj_percent))\n",
    "num_train_subjs = params.n_subjs - (num_test_subjs + num_val_subjs)\n",
    "subj_list = list(subj_data.keys())\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1:\n",
    "    warnings.warn(\n",
    "        \"DEBUG: Only 1 subject selected, mixing training, validation, and testing sets\"\n",
    "    )\n",
    "    num_train_subjs = num_val_subjs = num_test_subjs = 1\n",
    "\n",
    "    test_subjs = subj_list\n",
    "    val_subjs = subj_list\n",
    "    train_subjs = subj_list\n",
    "else:\n",
    "    test_subjs = subj_list[:num_test_subjs]\n",
    "    val_subjs = subj_list[num_test_subjs : (num_test_subjs + num_val_subjs)]\n",
    "    train_subjs = subj_list[(num_test_subjs + num_val_subjs) :]\n",
    "\n",
    "print(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\")\n",
    "print(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\")\n",
    "print(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\")\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\\n\")\n",
    "    f.write(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\\n\")\n",
    "    f.write(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\\n\")\n",
    "\n",
    "logger.add_text(\"train_subjs\", str(train_subjs))\n",
    "logger.add_text(\"val_subjs\", str(val_subjs))\n",
    "logger.add_text(\"test_subjs\", str(test_subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Datasets and DataLoaders for test, validation, and training steps.\n",
    "sample_kws = {\n",
    "    \"subj_id\": \"subj_id\",\n",
    "    \"dti\": \"dti\",\n",
    "    \"dti_scaler\": \"dti_scaler\",\n",
    "    \"lr_dti\": \"lr_dti\",\n",
    "    \"lr_dti_scaler\": \"lr_dti_scaler\",\n",
    "    \"mask\": \"mask\",\n",
    "    params.data.anat_type: params.data.anat_type,\n",
    "    params.data.anat_type + \"_scaler\": params.data.anat_type + \"_scaler\",\n",
    "}\n",
    "\n",
    "# Train\n",
    "train_ds = list()\n",
    "for subj_id in train_subjs:\n",
    "    train_ds.append(subj_data[subj_id].patches)\n",
    "train_dataset = torch.utils.data.ConcatDataset(train_ds)\n",
    "train_sampler = pitn.samplers.ConcatDatasetBalancedRandomSampler(\n",
    "    train_dataset.datasets,\n",
    "    max_samples_per_dataset=params.train.samples_per_subj_per_epoch,\n",
    ")\n",
    "train_collate_fn = functools.partial(pitn.samplers.collate_dicts, **sample_kws)\n",
    "train_loader = monai.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=params.train.batch_size,\n",
    "    collate_fn=train_collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=7,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# Test & Validation\n",
    "# Only need raw DTIs for testing and validation, not training.\n",
    "tv_sample_kws = {**sample_kws, \"raw_dti\": \"raw_dti\", \"raw_lr_dti\": \"raw_lr_dti\"}\n",
    "test_val_collate_fn = functools.partial(pitn.samplers.collate_dicts, **tv_sample_kws)\n",
    "\n",
    "test_ds = list()\n",
    "for subj_id in test_subjs:\n",
    "    test_ds.append(subj_data[subj_id])\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_ds)\n",
    "test_loader = monai.data.DataLoader(\n",
    "    test_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")\n",
    "\n",
    "val_ds = list()\n",
    "for subj_id in val_subjs:\n",
    "    val_ds.append(subj_data[subj_id])\n",
    "val_dataset = torch.utils.data.ConcatDataset(val_ds)\n",
    "val_loader = monai.data.DataLoader(\n",
    "    val_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "debug_prob = -1 / (\n",
    "    params.train.samples_per_subj_per_epoch * len(train_subjs) / params.train.batch_size\n",
    ")\n",
    "\n",
    "\n",
    "class DIQTCascadeSystem(pl.LightningModule):\n",
    "\n",
    "    # Specify training loss methods with mappings to their names as strings.\n",
    "    loss_methods = {\n",
    "        \"MSE\".casefold(): torch.nn.MSELoss(reduction=\"mean\"),\n",
    "        \"SSE\".casefold(): torch.nn.MSELoss(reduction=\"sum\"),\n",
    "        \"RMSE\".casefold(): lambda y_hat, y: torch.sqrt(\n",
    "            F.mse_loss(y_hat, y, reduction=\"mean\")\n",
    "        ),\n",
    "        \"L1\".casefold(): torch.nn.L1Loss(reduction=\"mean\"),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        batch_size: int,\n",
    "        in_patch_shape: tuple,\n",
    "        upscale_factor: int,\n",
    "        anat_batch_key: str,\n",
    "        train_loss_method: str,\n",
    "        val_subj_ids: tuple,\n",
    "        opt_params: dict,\n",
    "        lr_scheduler_kwargs: dict,\n",
    "        net_kwargs: dict = dict(),\n",
    "        **hyper_parameters,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(\n",
    "            \"channels\",\n",
    "            \"batch_size\",\n",
    "            \"train_loss_method\",\n",
    "            *list(hyper_parameters.keys()),\n",
    "        )\n",
    "        self._channels = channels\n",
    "        self._batch_size = batch_size\n",
    "        self._in_patch_shape = in_patch_shape\n",
    "        self._anat_batch_key = anat_batch_key\n",
    "        self._upscale_factor = upscale_factor\n",
    "        self._val_viz_subj_id = random.choice(val_subj_ids)\n",
    "        # self.hparams.update(hparams)\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = pitn.nn.sr.CascadeUpsampleModeRefine(\n",
    "            self._channels, upscale_factor=self._upscale_factor, **net_kwargs\n",
    "        )\n",
    "\n",
    "        ## Training parameters\n",
    "        self.opt_params = opt_params\n",
    "        self.lr_scheduler_kwargs = lr_scheduler_kwargs\n",
    "\n",
    "        # Select loss method as either one of the pre-selected methods, or a custom\n",
    "        # callable.\n",
    "        try:\n",
    "            self._loss_fn = self.loss_methods[train_loss_method.casefold()]\n",
    "        except (AttributeError, KeyError):\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"ERROR: Invalid loss function specification {train_loss_method}, \"\n",
    "                    + f\"expected one of {self.loss_methods.keys()} or a callable.\"\n",
    "                )\n",
    "\n",
    "        self._val_subvol_range = dict()\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = Box(\n",
    "            {\n",
    "                \"train_loss\": list(),\n",
    "                \"val_loss\": {\"rmse\": list(), \"nrmse\": list()},\n",
    "                \"test_loss\": {\n",
    "                    \"spline\": {\n",
    "                        \"rmse\": dict(),\n",
    "                        \"nrmse\": dict(),\n",
    "                        \"scaled_psnr\": dict(),\n",
    "                        \"scaled_ssim\": dict(),\n",
    "                        \"scaled_ms_ssim\": dict(),\n",
    "                    },\n",
    "                    \"rmse\": dict(),\n",
    "                    \"nrmse\": dict(),\n",
    "                    \"scaled_psnr\": dict(),\n",
    "                    \"scaled_ssim\": dict(),\n",
    "                    \"scaled_ms_ssim\": dict(),\n",
    "                },\n",
    "                \"viz\": {\n",
    "                    \"spline_preds\": dict(),\n",
    "                    \"test_preds\": dict(),\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_mode_refine):\n",
    "        y = self.net(x, x_mode_refine)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = Box(batch)\n",
    "        x = batch.lr_dti\n",
    "        y = batch.dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine)\n",
    "\n",
    "        # Only calculate loss on voxels in the brain mask.\n",
    "        loss = self._loss_fn(\n",
    "            torch.masked_select(y_pred, mask), torch.masked_select(y, mask)\n",
    "        )\n",
    "\n",
    "        self.log(\"train_loss\", loss, batch_size=self._batch_size)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        # Assume batch size of 1 for the validation set.\n",
    "        subj_id = batch.subj_id[0]\n",
    "        x = batch.lr_dti\n",
    "        y = batch.raw_dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "\n",
    "        y_pred = self.net(x, x_mode_refine)\n",
    "\n",
    "        # Calculate val loss on un-scaled output.\n",
    "        if batch.lr_dti_scaler:\n",
    "            y_pred = batch.lr_dti_scaler[0].descale(y_pred[0])[\n",
    "                None,\n",
    "            ]\n",
    "\n",
    "        rmse_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                torch.masked_select(y_pred, mask),\n",
    "                torch.masked_select(y, mask),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "        nrmse_loss = pitn.metrics.minmax_normalized_rmse(\n",
    "            torch.masked_select(y_pred, mask).view(y.shape[0], y.shape[1], -1),\n",
    "            torch.masked_select(y, mask).view(y.shape[0], y.shape[1], -1),\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        self.log(\"val_loss/nrmse\", nrmse_loss)\n",
    "        self.log(\"val_loss/rmse\", rmse_loss)\n",
    "        self.plain_log.val_loss.nrmse.append(float(nrmse_loss.detach().cpu()))\n",
    "        self.plain_log.val_loss.rmse.append(float(rmse_loss.detach().cpu()))\n",
    "\n",
    "        # Plot visual of validation volume.\n",
    "        if subj_id == self._val_viz_subj_id and not self._val_subvol_range:\n",
    "            # Take range between 1/4 to 3/4 the size of each dimension.\n",
    "            fr_space = np.asarray(y.shape[2:])\n",
    "            fr_low = np.floor(fr_space * 1 / 4).astype(int)\n",
    "            fr_high = np.floor(fr_space * 3 / 4).astype(int)\n",
    "            subvol_slice = np.s_[\n",
    "                fr_low[0] : fr_high[0], fr_low[1] : fr_high[1], fr_low[2] : fr_high[2]\n",
    "            ]\n",
    "            self._val_subvol_range[\"fr\"] = (\n",
    "                0,\n",
    "                ...,\n",
    "            ) + subvol_slice\n",
    "\n",
    "            lr_space = np.asarray(x.shape[2:])\n",
    "            lr_low = np.floor(lr_space * 1 / 4).astype(int)\n",
    "            lr_high = np.floor(lr_space * 3 / 4).astype(int)\n",
    "            subvol_slice = np.s_[\n",
    "                lr_low[0] : lr_high[0], lr_low[1] : lr_high[1], lr_low[2] : lr_high[2]\n",
    "            ]\n",
    "            self._val_subvol_range[\"lr\"] = (\n",
    "                0,\n",
    "                ...,\n",
    "            ) + subvol_slice\n",
    "\n",
    "        if subj_id == self._val_viz_subj_id:\n",
    "            x_subvol = x.detach()[self._val_subvol_range[\"lr\"]].float()\n",
    "            y_subvol = y.detach()[self._val_subvol_range[\"fr\"]].float()\n",
    "            pred_subvol = y_pred.detach()[self._val_subvol_range[\"fr\"]].float()\n",
    "            # x_mode_refine_subvol = x_mode_refine.detach()[\n",
    "            #     self._val_subvol_range[\"fr\"]\n",
    "            # ].expand_as(y_subvol)\n",
    "            # mask_subvol = mask.detach()[self._val_subvol_range[\"fr\"]]\n",
    "\n",
    "            # Create grid plot\n",
    "            # Plot settings to propogate into the figure.\n",
    "            with mpl.rc_context(\n",
    "                {\n",
    "                    \"font.size\": 8.0,\n",
    "                    \"axes.labelpad\": 10.0,\n",
    "                    \"figure.autolayout\": False,\n",
    "                    \"figure.constrained_layout.use\": True,\n",
    "                }\n",
    "            ):\n",
    "                fig = plt.figure(dpi=130, figsize=(6, 4))\n",
    "                channel_names = [\n",
    "                    r\"$D_{x,x}$\",\n",
    "                    r\"$D_{x,y}$\",\n",
    "                    r\"$D_{y,y}$\",\n",
    "                    r\"$D_{x,z}$\",\n",
    "                    r\"$D_{y,z}$\",\n",
    "                    r\"$D_{z,z}$\",\n",
    "                ]\n",
    "                slice_labels = [\n",
    "                    \"\\nAxial\",\n",
    "                    \"\\nCoronal\",\n",
    "                    \"\\nSagg.\",\n",
    "                ]\n",
    "                img_labels = [\"GT\", \"Pred\", \"Input\"]\n",
    "                fig = pitn.viz.plot_vol_slices(\n",
    "                    y_subvol,\n",
    "                    pred_subvol,\n",
    "                    x_subvol,\n",
    "                    slice_idx=(0.55, None, None),\n",
    "                    title=f\"Subj {subj_id} Step {self.global_step}\",\n",
    "                    vol_labels=img_labels,\n",
    "                    channel_labels=channel_names,\n",
    "                    slice_labels=slice_labels,\n",
    "                    colorbars=\"each\",\n",
    "                    fig=fig,\n",
    "                    interpolation=\"antialiased\",\n",
    "                    cmap=\"gray\",\n",
    "                )\n",
    "                self.logger.experiment.add_figure(\"val_slice\", fig, self.global_step)\n",
    "\n",
    "        return rmse_loss\n",
    "\n",
    "    def on_test_start(self):\n",
    "        # Initialize the metrics as hyperparams so they appear under the tensorboard\n",
    "        # hparams tab. From:\n",
    "        # <https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html#logging-hyperparameters>\n",
    "        self.logger.log_hyperparams(\n",
    "            self.hparams,\n",
    "            {\n",
    "                \"hp/rmse\": 0,\n",
    "                \"hp/nrmse\": 0,\n",
    "                \"hp/scaled_psnr\": 0,\n",
    "                \"hp/scaled_ssim\": 0,\n",
    "                \"hp/scaled_ms_ssim\": 0,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def test_step(self, batch: dict, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        # Assume a batch size of 1.\n",
    "        subj_id = batch.subj_id[0]\n",
    "        x = batch.lr_dti\n",
    "        y = batch.raw_dti\n",
    "        y = self.net.crop_full_output(y)\n",
    "        mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(mask)\n",
    "        x_mode_refine = batch[self._anat_batch_key]\n",
    "\n",
    "        # y_pred = self.net(x, x_mode_refine).float()\n",
    "        #*****disables testing*********\n",
    "        y_pred = torch.randn_like(y)\n",
    "\n",
    "        # Run spline over the raw LR input.\n",
    "        spline_x = batch.raw_lr_dti\n",
    "        spline_y_pred = self.pred_spline(spline_x).float()\n",
    "\n",
    "        # Calculate test loss on un-scaled inputs & outputs.\n",
    "        if batch.lr_dti_scaler:\n",
    "            # Unscale the network prediction *without* using any distribution information\n",
    "            # from the ground truth volumes.\n",
    "            y_pred = batch.lr_dti_scaler[0].descale(y_pred[0])[\n",
    "                None,\n",
    "            ]\n",
    "\n",
    "        # Mask select the target and prediction(s)\n",
    "        y_select = torch.masked_select(y, mask).view(y.shape[0], y.shape[1], -1)\n",
    "        y_pred_select = torch.masked_select(y_pred, mask).view(\n",
    "            y_pred.shape[0], y_pred.shape[1], -1\n",
    "        )\n",
    "        spline_y_pred_select = torch.masked_select(spline_y_pred, mask).view(\n",
    "            spline_y_pred.shape[0], spline_y_pred.shape[1], -1\n",
    "        )\n",
    "\n",
    "        ###### Calculate network performance metrics.\n",
    "        rmse_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                y_pred_select,\n",
    "                y_select,\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "        nrmse_loss = pitn.metrics.minmax_normalized_rmse(\n",
    "            y_pred_select,\n",
    "            y_select,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        scaled_psnr_loss = pitn.metrics.range_scaled_psnr(\n",
    "            y_pred_select,\n",
    "            y_select,\n",
    "            feature_range=(0.0, 1.0),\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        scaled_ssim_loss = pitn.metrics.range_scaled_ssim(\n",
    "            y_pred,\n",
    "            y,\n",
    "            feature_range=(0.0, 1.0),\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        scaled_ms_ssim_loss = pitn.metrics.range_scaled_ms_ssim(\n",
    "            y_pred,\n",
    "            y,\n",
    "            feature_range=(0.0, 1.0),\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        # on_epoch and reduce_fx gather the individual test epoch values and aggregate\n",
    "        # them at the end of the testing epoch.\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"test_loss/rmse\": rmse_loss,\n",
    "                \"test_loss/nrmse\": nrmse_loss,\n",
    "                \"test_loss/scaled_psnr\": scaled_psnr_loss,\n",
    "                \"test_loss/scaled_ssim\": scaled_ssim_loss,\n",
    "                \"test_loss/scaled_ms_ssim\": scaled_ms_ssim_loss,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            reduce_fx=torch.mean,\n",
    "        )\n",
    "        # Log loss as an hparam metric to be shown alongside the experiment's hparams.\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"hp/rmse\": rmse_loss,\n",
    "                \"hp/nrmse\": nrmse_loss,\n",
    "                \"hp/scaled_psnr\": scaled_psnr_loss,\n",
    "                \"hp/scaled_ssim\": scaled_ssim_loss,\n",
    "                \"hp/scaled_ms_ssim\": scaled_ms_ssim_loss,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            reduce_fx=torch.mean,\n",
    "        )\n",
    "        self.plain_log.test_loss.rmse[subj_id] = rmse_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.nrmse[subj_id] = nrmse_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.scaled_psnr[subj_id] = (\n",
    "            scaled_psnr_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.scaled_ssim[subj_id] = (\n",
    "            scaled_ssim_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.scaled_ms_ssim[subj_id] = (\n",
    "            scaled_ms_ssim_loss.detach().cpu().item()\n",
    "        )\n",
    "\n",
    "        ###### Handle spline losses and logging.\n",
    "        spline_rmse = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                spline_y_pred_select,\n",
    "                y_select,\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "        spline_nrmse = pitn.metrics.minmax_normalized_rmse(\n",
    "            spline_y_pred_select,\n",
    "            y_select,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        spline_scaled_psnr = pitn.metrics.range_scaled_psnr(\n",
    "            spline_y_pred_select,\n",
    "            y_select,\n",
    "            feature_range=(0.0, 1.0),\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        spline_scaled_ssim = pitn.metrics.range_scaled_ssim(\n",
    "            spline_y_pred,\n",
    "            y,\n",
    "            feature_range=(0.0, 1.0),\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        spline_scaled_ms_ssim = pitn.metrics.range_scaled_ms_ssim(\n",
    "            spline_y_pred,\n",
    "            y,\n",
    "            feature_range=(0.0, 1.0),\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        self.plain_log.test_loss.spline.rmse[subj_id] = (\n",
    "            spline_rmse.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.spline.nrmse[subj_id] = (\n",
    "            spline_nrmse.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.spline.scaled_psnr[subj_id] = (\n",
    "            spline_scaled_psnr.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.spline.scaled_ssim[subj_id] = (\n",
    "            spline_scaled_ssim.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.spline.scaled_ms_ssim[subj_id] = (\n",
    "            spline_scaled_ms_ssim.detach().cpu().item()\n",
    "        )\n",
    "\n",
    "        # Store results for vizualization later.\n",
    "        self.plain_log.viz.test_preds[subj_id] = y_pred[0].detach().cpu()\n",
    "        self.plain_log.viz.spline_preds[subj_id] = spline_y_pred[0].detach().cpu()\n",
    "\n",
    "        return {\n",
    "            \"rmse\": rmse_loss,\n",
    "            \"nrmse\": nrmse_loss,\n",
    "            \"scaled_psnr\": scaled_psnr_loss,\n",
    "            \"scaled_ssim\": scaled_ssim_loss,\n",
    "            \"scaled_ms_ssim\": scaled_ms_ssim_loss,\n",
    "        }\n",
    "\n",
    "    def pred_spline(self, x, order=3):\n",
    "        x_np = x.detach().cpu().numpy()\n",
    "        ys = list()\n",
    "        for b in x_np:\n",
    "            y_b = scipy.ndimage.zoom(\n",
    "                b,\n",
    "                zoom=(\n",
    "                    1,\n",
    "                    self._upscale_factor,\n",
    "                    self._upscale_factor,\n",
    "                    self._upscale_factor,\n",
    "                ),\n",
    "                order=order,\n",
    "            )\n",
    "\n",
    "            ys.append(torch.from_numpy(y_b))\n",
    "\n",
    "        y = torch.stack(ys, dim=0)\n",
    "        y = y.to(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.net.parameters(), **self.opt_params)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer, **self.lr_scheduler_kwargs\n",
    "        )\n",
    "        opt_system = {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "        return opt_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "model_kwargs = dict(\n",
    "    channels=params.n_channels,\n",
    "    batch_size=params.train.batch_size,\n",
    "    in_patch_shape=params.train.in_patch_size,\n",
    "    upscale_factor=params.net.upscale_factor,\n",
    "    anat_batch_key=params.data.anat_type,\n",
    "    train_loss_method=params.train.loss_name,\n",
    "    val_subj_ids=val_subjs,\n",
    "    opt_params=params.optim.kwargs,\n",
    "    net_kwargs=params.net.kwargs,\n",
    "    lr_scheduler_kwargs=params.train.lr_scheduler.kwargs,\n",
    ")\n",
    "# Update init kwargs with hyperparams, in case there are overlapping names.\n",
    "model_kwargs.update(**hyperparams)\n",
    "\n",
    "# Create model from given kwargs.\n",
    "model = DIQTCascadeSystem(**model_kwargs)\n",
    "\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Model overview: {model}\\n\")\n",
    "\n",
    "# Create trainer object.\n",
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=20,\n",
    "    gpus=1,\n",
    "    max_epochs=params.train.max_epochs,\n",
    "    # max_epochs=7,\n",
    "    logger=pl_logger,\n",
    "    log_every_n_steps=50,\n",
    "    # run validation every 0.5 epochs\n",
    "    val_check_interval=0.5,\n",
    "    # Enable mixed-precision floating point ops.\n",
    "    precision=16,\n",
    "    amp_backend=\"native\",\n",
    "    # max_time={\"minutes\": 20},\n",
    ")\n",
    "\n",
    "# Many warnings are produced here, so it's better for my sanity (i.e., worse in every other\n",
    "# way) to just filter and ignore them...\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out trained model\n",
    "trainer.save_checkpoint(str(experiment_results_dir / \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + params.train.loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mod_state = model.state_dict()\n",
    "\n",
    "# test_mod = DIQTCascadeSystem(\n",
    "#     channels=params.n_channels,\n",
    "#     batch_size=params.train.batch_size,\n",
    "#     in_patch_shape=params.train.in_patch_size,\n",
    "#     upscale_factor=params.net.upscale_factor,\n",
    "#     anat_batch_key=params.data.anat_type,\n",
    "#     train_loss_method=params.train.loss_name,\n",
    "#     opt_params=params.optim.kwargs,\n",
    "#     hparams=hyperparams,\n",
    "#     **params.net.kwargs,\n",
    "# )\n",
    "# test_mod.load_state_dict(mod_state)\n",
    "# trainer.test(test_mod, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_losses = {\"rmse\", \"nrmse\", \"scaled_psnr\", \"scaled_ssim\", \"scaled_ms_ssim\"}\n",
    "loss_comparison_directions = {\n",
    "    \"rmse\": \"↓\",\n",
    "    \"nrmse\": \"↓\",\n",
    "    \"scaled_psnr\": \"↑\",\n",
    "    \"scaled_ssim\": \"↑\",\n",
    "    \"scaled_ms_ssim\": \"↑\",\n",
    "}\n",
    "\n",
    "test_results = Box(subj_id=list(), model=list(), metric=list(), value=list())\n",
    "for subj_id in test_subjs:\n",
    "    for metric in test_losses:\n",
    "        # DIQT model\n",
    "        test_results.subj_id.append(subj_id)\n",
    "        test_results.model.append(\"diqt\")\n",
    "        test_results.metric.append(metric)\n",
    "        test_results.value.append(model.plain_log.test_loss[metric][subj_id])\n",
    "\n",
    "        # Cubic spline\n",
    "        test_results.subj_id.append(subj_id)\n",
    "        test_results.model.append(\"cubic_spline\")\n",
    "        test_results.metric.append(metric)\n",
    "        test_results.value.append(model.plain_log.test_loss.spline[metric][subj_id])\n",
    "# Convert to a pandas dataframe.\n",
    "test_results = pd.DataFrame(test_results.to_dict())\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Test loss functions: {list(test_losses)}\\n\")\n",
    "\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "test_results.to_csv(test_loss_log_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison within experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 8.0,\n",
    "    }\n",
    "):\n",
    "    fig, axs = plt.subplots(\n",
    "        ncols=len(test_losses),\n",
    "        sharex=True,\n",
    "        figsize=(11, 4),\n",
    "        dpi=130,\n",
    "        gridspec_kw={\"wspace\": 1.0, \"hspace\": 0},\n",
    "    )\n",
    "    sns.despine(fig=fig, top=True, right=True)\n",
    "\n",
    "    for i, l in enumerate(test_losses):\n",
    "\n",
    "        ax = axs[i]\n",
    "        df = test_results.loc[test_results.metric == l]\n",
    "        vplot = sns.violinplot(\n",
    "            x=\"model\", y=\"value\", data=df, ax=ax, scale=\"count\", inner=None\n",
    "        )\n",
    "        axs[i].grid(axis=\"y\", alpha=0.5)\n",
    "        points_plot = sns.swarmplot(\n",
    "            x=\"model\",\n",
    "            y=\"value\",\n",
    "            hue=\"subj_id\",\n",
    "            data=df,\n",
    "            ax=ax,\n",
    "            # color=\"white\",\n",
    "            edgecolor=\"black\",\n",
    "            size=4,\n",
    "            linewidth=0.8,\n",
    "        )\n",
    "        points_plot.get_legend().remove()\n",
    "\n",
    "        # Calculate mean performance score.\n",
    "        means = df.groupby(\"model\").mean()\n",
    "        # Make sure the order follows seaborn's x-axis ordering.\n",
    "        model_order = list(map(lambda ax: ax.get_text(), axs[i].get_xticklabels()))\n",
    "        means = means.reindex(model_order)\n",
    "\n",
    "        # Grab colors corresponding to each model.\n",
    "        colors = sns.color_palette(None, n_colors=len(df.model.unique()))\n",
    "\n",
    "        lines = ax.hlines(\n",
    "            y=means.value,\n",
    "            xmin=np.arange(0, len(colors)) - 0.5 + 0.05,\n",
    "            xmax=np.arange(1, len(colors) + 1) - 0.5 - 0.05,\n",
    "            colors=colors,\n",
    "            lw=1.5,\n",
    "        )\n",
    "\n",
    "        outline_path_effects = [\n",
    "            mpl.patheffects.Stroke(linewidth=5, foreground=\"white\", alpha=0.9),\n",
    "            mpl.patheffects.Normal(),\n",
    "        ]\n",
    "        lines.set_path_effects(outline_path_effects)\n",
    "\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=25)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        ax_format = ax.get_yaxis().get_major_formatter()\n",
    "\n",
    "        for m, c in zip(means.value, colors):\n",
    "\n",
    "            ax.annotate(\n",
    "                f\"{m:.4g}\",\n",
    "                xy=(ax.get_xlim()[0] + (ax.get_xlim()[0] * 0.4), m),\n",
    "                xycoords=\"data\",\n",
    "                color=c,\n",
    "                ha=\"right\",\n",
    "                va=\"center\",\n",
    "                annotation_clip=False,\n",
    "                fontweight=\"bold\",\n",
    "                snap=True,\n",
    "                bbox=dict(\n",
    "                    boxstyle=\"square,pad=0.3\", fc=\"white\", lw=0, snap=True, alpha=0.75\n",
    "                ),\n",
    "            )\n",
    "        ax.set_title(f\"{l.replace('_', ' ')} {loss_comparison_directions[l]}\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(\"\")\n",
    "plt.savefig(experiment_results_dir / \"test_result_within_experiment.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with other works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = False\n",
    "\n",
    "hist = sns.histplot(\n",
    "    list(model.plain_log[\"test_loss\"].rmse.values()),\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    "    hatch=\"\\\\\\\\\",\n",
    "    ec=\"blue\",\n",
    ")\n",
    "hist.yaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"-\", \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Our spline mean performance.\n",
    "plt.axvline(\n",
    "    np.asarray(list(model.plain_log.test_loss.spline.rmse.values())).mean(),\n",
    "    label=\"(Ours) Spline Mean Order 3\",\n",
    "    color=\"black\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "sns.histplot(\n",
    "    np.asarray(list(model.plain_log.test_loss.spline.rmse.values())),\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    "    color=\"black\",\n",
    "    hatch=\"//\",\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    9.72e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    9.76e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nBest ESPCN\\n[but not really]\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    8.46e-4,\n",
    "    label=\"(Blumberg etal, 2018)\\nBest Overall\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(\"Test Loss Histogram Over All Subjects with Test Metric RMSE\")\n",
    "plt.savefig(experiment_results_dir / \"test_rmse_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all subjects.\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "\n",
    "models = (\n",
    "    \"(Ours)\\nCurrent Model\",\n",
    "    \"(Ours)\\nSpline Order 3\",\n",
    "    \"(Tanno etal, 2021)\\nC-Spline\\nMean Approx.\",\n",
    "    \"(Tanno etal, 2021)\\nRand. Forest\\nMean Approx.\",\n",
    "    \"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    '(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\n\"Best\" ESPCN',\n",
    "    \"(Blumberg etal, 2018)\\nBest Overall\",\n",
    ")\n",
    "\n",
    "rmse_bounds = np.asarray(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [0, 0],\n",
    "        [31.738e-4, 10.069e-4],\n",
    "        [23.139e-4, 6.974e-4],\n",
    "        [13.609e-4, 6.212e-4],\n",
    "        [13.82e-4, 6.29e-4],\n",
    "        [12.13e-4, 5.58e-4],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rmse_scores = (\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    np.asarray(list(model.plain_log.test_loss.spline.rmse.values())).mean(),\n",
    "    rmse_bounds[2].mean(),\n",
    "    rmse_bounds[3].mean(),\n",
    "    9.72e-4,\n",
    "    9.76e-4,\n",
    "    8.46e-4,\n",
    ")\n",
    "\n",
    "rmse_score_ranges = np.asarray(rmse_scores)[:, None] - rmse_bounds\n",
    "rmse_score_ranges[:2] = rmse_score_ranges[:2] * 0\n",
    "rmse_score_ranges = rmse_score_ranges.T\n",
    "\n",
    "colors = sns.color_palette(\"deep\", n_colors=len(rmse_scores))\n",
    "\n",
    "ax.grid(True, axis=\"y\", zorder=1000)\n",
    "ax.set_axisbelow(True)\n",
    "# Plot our evaluation scores.\n",
    "end_idx = 2\n",
    "ax.bar(\n",
    "    models[:end_idx],\n",
    "    rmse_scores[:end_idx],\n",
    "    color=colors[:end_idx],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    ")\n",
    "for container in ax.containers:\n",
    "    if isinstance(container, mpl.container.BarContainer):\n",
    "        ax.bar_label(container, fmt=\"%.3e\")\n",
    "\n",
    "\n",
    "start_idx = end_idx\n",
    "# Plot the crazy evaluation scores.\n",
    "ax.bar(\n",
    "    models[start_idx:],\n",
    "    height=rmse_bounds[start_idx:, 0] - rmse_bounds[start_idx:, 1],\n",
    "    bottom=rmse_bounds[start_idx:, 1],\n",
    "    color=colors[start_idx:],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    "    alpha=0.8,\n",
    ")\n",
    "end_idx = start_idx + 2\n",
    "bar_width = ax.patches[0].get_width()\n",
    "# Dotted lines for the \"approximate\" actual rmse score.\n",
    "ax.hlines(\n",
    "    rmse_scores[start_idx:end_idx],\n",
    "    xmin=np.arange(start_idx, end_idx) - bar_width / 2,\n",
    "    xmax=np.arange(start_idx, end_idx) + bar_width / 2,\n",
    "    color=\"black\",\n",
    "    ls=\"--\",\n",
    ")\n",
    "for score, x in zip(\n",
    "    rmse_scores[start_idx:end_idx], np.arange(start_idx, end_idx) - bar_width / 2\n",
    "):\n",
    "    ax.annotate(f\"{score:.3e}\", (x, score + 0.03 * np.asarray(rmse_scores).max()))\n",
    "\n",
    "start_idx = end_idx\n",
    "end_idx = len(models)\n",
    "ax.hlines(\n",
    "    rmse_scores[start_idx:],\n",
    "    xmin=np.arange(start_idx, end_idx) - bar_width / 2,\n",
    "    xmax=np.arange(start_idx, end_idx) + bar_width / 2,\n",
    "    color=\"black\",\n",
    "    ls=\"-\",\n",
    ")\n",
    "\n",
    "for score, x in zip(\n",
    "    rmse_scores[start_idx:end_idx], np.arange(start_idx, end_idx) - bar_width / 2\n",
    "):\n",
    "    ax.annotate(f\"{score:.3e}\", (x, score + 0.03 * np.asarray(rmse_scores).max()))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=ax.get_ylim()[1] * 1.1)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "ax.set_title(\"Mean Over Subjects Test Loss RMSE\")\n",
    "ax.set_xticks(models)\n",
    "ax.set_xticklabels(\n",
    "    models, fontsize=\"x-small\", rotation=25, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"test_rmse_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_test_idx = np.argsort(np.asarray(list(model.plain_log.test_loss.rmse.values())))\n",
    "sorted_test_results = dict(\n",
    "    list(model.plain_log.test_loss.rmse.items())[i] for i in sorted_test_idx\n",
    ")\n",
    "ppr(sorted_test_results, sort_dicts=False)\n",
    "print(np.mean(list(list(model.plain_log.test_loss.rmse.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diqt_results = test_results.loc[test_results.model == \"diqt\"]\n",
    "\n",
    "logger.add_histogram(\n",
    "    \"test/rmse_dist\", np.asarray(diqt_results.loc[diqt_results.metric == \"rmse\"].value)\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/nrmse_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"nrmse\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/scaled_psnr_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"scaled_psnr\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/scaled_ssim_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"scaled_ssim\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/scaled_ms_ssim_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"scaled_ms_ssim\"].value),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debug flag(s)\n",
    "disable_fig_save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volumes of full-res ground truth, low-res downsample, full-res mask,\n",
    "# anatomical image, and full-res predictions.\n",
    "\n",
    "results_viz = Box(default_box=True)\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj in test_dataset:\n",
    "        # Index into the only item in the subject dataset.\n",
    "        s = Box(default_box=True)\n",
    "        subj_id = subj[\"subj_id\"]\n",
    "        print(f\"Starting subject {subj_id}\")\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "        s.mask = model.net.crop_full_output(subj[\"mask\"])\n",
    "        s.dti = model.net.crop_full_output(subj[\"raw_dti\"])\n",
    "        s.affine = subj[\"dti_meta_dict\"][\"affine\"]\n",
    "        s.lr_dti = subj[\"lr_dti\"]\n",
    "        s[params.data.anat_type] = model.net.crop_full_output(\n",
    "            subj[params.data.anat_type]\n",
    "        )\n",
    "\n",
    "        s.pred = model.plain_log.viz.test_preds[subj_id]\n",
    "        s.spline_pred = model.plain_log.viz.spline_preds[subj_id]\n",
    "\n",
    "        if params.data.dti_scale_range:\n",
    "            # s.dti = subj[\"dti_scaler\"].descale(s.dti)\n",
    "            s.lr_dti = subj[\"lr_dti_scaler\"].descale(s.lr_dti)\n",
    "            # Already descaled prediction in the test_step().\n",
    "            # s.pred = subj[\"dti_scaler\"].descale(s.pred)\n",
    "        if params.data.anat_scale_range:\n",
    "            s[params.data.anat_type] = subj[params.data.anat_type + \"_scaler\"].descale(\n",
    "                s[params.data.anat_type]\n",
    "            )\n",
    "\n",
    "        s.dti = s.dti * s.mask\n",
    "        s.pred = s.pred * s.mask\n",
    "        s.spline_pred = s.spline_pred * s.mask\n",
    "        s.metrics.rmse = model.plain_log.test_loss.rmse[subj_id]\n",
    "        s.abs_error = torch.abs(s.pred - s.dti)\n",
    "\n",
    "        for k in {\n",
    "            \"mask\",\n",
    "            \"dti\",\n",
    "            \"lr_dti\",\n",
    "            params.data.anat_type,\n",
    "            \"pred\",\n",
    "            \"spline_pred\",\n",
    "            \"abs_error\",\n",
    "        }:\n",
    "            v = s[k]\n",
    "            if torch.is_tensor(v):\n",
    "                v = v.detach().cpu().numpy()\n",
    "            if k == \"mask\":\n",
    "                v = v.astype(bool)\n",
    "            else:\n",
    "                v = v.astype(float)\n",
    "            # s[k] = np.rot90(v)\n",
    "            s[k] = v\n",
    "\n",
    "        results_viz[subj_id] = s\n",
    "        print(f\"Finished subject {subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pitn.viz.plot_vol_slices(\n",
    "#     np.rot90(results_viz['303624'].dti[0], k=1)\n",
    "#     , colorbars='each')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out all network predictions to Nifti2 files and compress them into a zip archive.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in results_viz.items():\n",
    "        nib_img = nib.Nifti2Image(viz.dti, viz.affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_dti.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(experiment_results_dir / \"predicted_dti.zip\", \"w\") as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=6,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "    # Make sure we exit the 'with' statement above.\n",
    "    print(\"Done with files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick the worst performing subject from the test set to visualize.\n",
    "sel_rmse = test_results.loc[\n",
    "    (test_results.model == \"diqt\") & (test_results.metric == \"rmse\")\n",
    "][[\"subj_id\", \"value\"]]\n",
    "sel_rmse = sel_rmse.sort_values(\"value\")\n",
    "# Or 2nd worst performing...\n",
    "bad_rmse = sel_rmse.iloc[-2]\n",
    "viz_subj_id = bad_rmse.subj_id\n",
    "print(viz_subj_id, bad_rmse.value)\n",
    "viz_subj = results_viz[viz_subj_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select indices for visualizing.\n",
    "dti_shape = np.asarray(viz_subj.dti.shape[1:])\n",
    "lr_dti_shape = np.asarray(viz_subj.lr_dti.shape[1:])\n",
    "\n",
    "viz_idx = dti_shape // 2\n",
    "# Last dimension (saggital) shouldn't be exactly centered, as the longitudinal fissure\n",
    "# doesn't have many fibers beyond the corpus collosum.\n",
    "viz_idx[2] = viz_idx[2] + 6\n",
    "viz_lr_idx = lr_dti_shape // 2\n",
    "viz_lr_idx[2] = viz_lr_idx[2] + 6 // params.data.downsampled_by_factor\n",
    "\n",
    "viz_slice_idx = [\n",
    "    np.s_[:, viz_idx[0], :, :],\n",
    "    np.s_[:, :, viz_idx[1], :],\n",
    "    np.s_[:, :, :, viz_idx[2]],\n",
    "]\n",
    "\n",
    "viz_lr_slice_idx = [\n",
    "    np.s_[:, viz_lr_idx[0], :, :],\n",
    "    np.s_[:, :, viz_lr_idx[1], :],\n",
    "    np.s_[:, :, :, viz_lr_idx[2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA-Weighted Direction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ims = list()\n",
    "for im, slices in zip(\n",
    "    [viz_subj.dti, viz_subj.pred, viz_subj.spline_pred, viz_subj.lr_dti],\n",
    "    (viz_slice_idx, viz_slice_idx, viz_slice_idx, viz_lr_slice_idx),\n",
    "):\n",
    "    for sl in slices:\n",
    "        selection = im[sl]\n",
    "        fa_w = pitn.viz.direction_map(selection, channels_first=True)\n",
    "        fa_w = fa_w.transpose(1, 2, 0)\n",
    "        ims.append(fa_w)\n",
    "\n",
    "dim_labels = [\n",
    "    \"Axial\",\n",
    "    \"Coronal\",\n",
    "    \"Saggital\",\n",
    "]\n",
    "vol_labels = [\"Ground Truth\", \"Pred\", \"Spline Interp.\", \"LR Input\"]\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 12.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=130, figsize=(7, 7))\n",
    "    fig = pitn.viz.plot_im_grid(\n",
    "        ims,\n",
    "        nrows=len(vol_labels),\n",
    "        title=f\"Subj {viz_subj_id} Prediction Results\",\n",
    "        row_headers=vol_labels,\n",
    "        col_headers=dim_labels,\n",
    "        colorbars=None,\n",
    "        fig=fig,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"dir_map_pred.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DTI Channel-Wise Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"$D_{x,x}$\",\n",
    "    \"$D_{x,y}$\",\n",
    "    \"$D_{y,y}$\",\n",
    "    \"$D_{x,z}$\",\n",
    "    \"$D_{y,z}$\",\n",
    "    \"$D_{z,z}$\",\n",
    "]\n",
    "\n",
    "dim_labels = [\n",
    "    \"\\nAxial\",\n",
    "    \"\\nCor.\",\n",
    "    \"\\nSagg.\",\n",
    "]\n",
    "\n",
    "dti_names = [\n",
    "    \"FR\",\n",
    "    \"Pred\",\n",
    "    \"Spline\",\n",
    "    \"LR\",\n",
    "    \"Abs Err\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "cmap = \"gray\"\n",
    "title = f\"DTI Subj {viz_subj_id} Summary\"\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 6.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=150, figsize=(8, 12))\n",
    "    fig = pitn.viz.plot_vol_slices(\n",
    "        viz_subj.dti,\n",
    "        viz_subj.pred,\n",
    "        viz_subj.spline_pred,\n",
    "        viz_subj.lr_dti,\n",
    "        viz_subj.abs_error,\n",
    "        slice_idx=(None, None, viz_idx[2] / dti_shape[2]),\n",
    "        title=title,\n",
    "        vol_labels=dti_names,\n",
    "        slice_labels=dim_labels,\n",
    "        channel_labels=channel_names,\n",
    "        colorbars=\"col\",\n",
    "        fig=fig,\n",
    "        cmap=cmap,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "\n",
    "\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / f\"DIQT_DTI_sub-{viz_subj_id}_pred_result.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel-Wise Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Display all 6 DTIs for ground truth, predicted, low-res input, and root squared error\n",
    "# # Normalize by index in the DTI coefficients.\n",
    "# # Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# # different shapes (e.g., the low-res input patch).\n",
    "\n",
    "# cmap = \"coolwarm\"\n",
    "# dtis = [\n",
    "#     test_vol_viz[viz_subj_id].dti.fr[(slice(None), *slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.lr[(slice(None), *low_res_slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.spline[(slice(None), *slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.diqt[(slice(None), *slice_idx)],\n",
    "#     test_vol_viz[viz_subj_id].dti.abs_error[(slice(None), *slice_idx)],\n",
    "# ]\n",
    "\n",
    "# nrows = len(dtis)\n",
    "# ncols = len(channel_names)\n",
    "\n",
    "# # Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# # orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# max_dtis = np.quantile(\n",
    "#     np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95, axis=1\n",
    "# )\n",
    "# min_dtis = np.quantile(\n",
    "#     np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05, axis=1\n",
    "# )\n",
    "\n",
    "# max_dtis = np.max(np.abs([max_dtis, min_dtis]), axis=0)\n",
    "# min_dtis = -1 * max_dtis\n",
    "\n",
    "# nrows = len(dtis)\n",
    "# ncols = len(channel_names)\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 7), dpi=160)\n",
    "\n",
    "# grid = mpl.gridspec.GridSpec(\n",
    "#     nrows,\n",
    "#     ncols,\n",
    "#     figure=fig,\n",
    "#     hspace=0.05,\n",
    "#     wspace=0.05,\n",
    "# )\n",
    "\n",
    "# axs = list()\n",
    "# max_subplot_height = 0\n",
    "# for i_row in range(nrows):\n",
    "#     dti = dtis[i_row]\n",
    "#     axs_cols = list()\n",
    "\n",
    "#     for j_col in range(ncols):\n",
    "#         ax = fig.add_subplot(grid[i_row, j_col])\n",
    "#         ax.imshow(\n",
    "#             np.rot90(dti[j_col]),\n",
    "#             cmap=cmap,\n",
    "#             interpolation=None,\n",
    "#             vmin=min_dtis[j_col],\n",
    "#             vmax=max_dtis[j_col],\n",
    "#         )\n",
    "#         if ax.get_subplotspec().is_first_col():\n",
    "#             ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "#         if ax.get_subplotspec().is_last_row():\n",
    "#             ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "#         # Update highest subplot to put the `suptitle` later on.\n",
    "#         max_subplot_height = max(\n",
    "#             max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "#         )\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         ax.set_xticklabels([])\n",
    "#         ax.set_yticklabels([])\n",
    "\n",
    "#         axs_cols.append(ax)\n",
    "\n",
    "#     axs.append(axs_cols)\n",
    "\n",
    "# # Place colorbars on each column.\n",
    "# for j_col in range(ncols):\n",
    "\n",
    "#     full_col_ax = [axs[i][j_col] for i in range(nrows)]\n",
    "\n",
    "#     color_norm = mpl.colors.Normalize(vmin=min_dtis[j_col], vmax=max_dtis[j_col])\n",
    "\n",
    "#     color_mappable = mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap)\n",
    "#     cbar = fig.colorbar(\n",
    "#         color_mappable,\n",
    "#         ax=full_col_ax,\n",
    "#         location=\"top\",\n",
    "#         orientation=\"horizontal\",\n",
    "#         pad=0.01,\n",
    "#         shrink=0.85,\n",
    "#     )\n",
    "#     cbar.ax.tick_params(labelsize=8, rotation=35)\n",
    "#     cbar.ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:g}\"))\n",
    "# #     cbar.ax.ticklabel_format(scilimits=(3, -3), useOffset=False)\n",
    "\n",
    "# plt.suptitle(\n",
    "#     \"DTI Channel Breakdown, Channel-Wise Normalization\",\n",
    "#     y=max_subplot_height + 0.01,\n",
    "#     verticalalignment=\"bottom\",\n",
    "# )\n",
    "# if not disable_fig_save:\n",
    "#     plt.savefig(experiment_results_dir / \"DTI_channel_sample_channel_wise_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl_logger.experiment.flush()\n",
    "# Close tensorboard logger.\n",
    "# Don't finalize if the experiment was for debugging.\n",
    "if \"debug\" not in EXPERIMENT_NAME.casefold():\n",
    "    pl_logger.finalize(\"success\")\n",
    "    # Experiment is complete, move the results directory to its final location.\n",
    "    if experiment_results_dir != final_experiment_results_dir:\n",
    "        print(\"Moving out of tmp location\")\n",
    "        experiment_results_dir = experiment_results_dir.rename(\n",
    "            final_experiment_results_dir\n",
    "        )\n",
    "        log_txt_file = experiment_results_dir / log_txt_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
