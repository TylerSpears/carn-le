{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain in the Net\n",
    "Replication of *Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images*\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "Source work:\n",
    "`S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:40.888176Z",
     "iopub.status.busy": "2021-05-17T18:48:40.887797Z",
     "iopub.status.idle": "2021-05-17T18:48:44.278559Z",
     "shell.execute_reply": "2021-05-17T18:48:44.277854Z",
     "shell.execute_reply.started": "2021-05-17T18:48:40.888133Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/pitn/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning:\n",
      "\n",
      "Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import IPython\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "from typing import Generator\n",
    "\n",
    "import ants\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Try importing GPUtil for printing GPU specs.\n",
    "# May not be installed if using CPU only.\n",
    "try:\n",
    "    import GPUtil\n",
    "except ImportError:\n",
    "    warnings.warn(\"WARNING: Package GPUtil not found, cannot print GPU specs\")\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import nilearn.plotting\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "import einops\n",
    "import einops.layers\n",
    "import einops.layers.torch\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:44.279795Z",
     "iopub.status.busy": "2021-05-17T18:48:44.279634Z",
     "iopub.status.idle": "2021-05-17T18:48:45.736487Z",
     "shell.execute_reply": "2021-05-17T18:48:45.735655Z",
     "shell.execute_reply.started": "2021-05-17T18:48:44.279776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:45.739875Z",
     "iopub.status.busy": "2021-05-17T18:48:45.739495Z",
     "iopub.status.idle": "2021-05-17T18:48:45.758084Z",
     "shell.execute_reply": "2021-05-17T18:48:45.757515Z",
     "shell.execute_reply.started": "2021-05-17T18:48:45.739828Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-specific scripts\n",
    "# It's easier to import it this way rather than make an entirely new package, due to\n",
    "# conflicts with local packages and anaconda installations.\n",
    "# You made me do this, poor python package management!!\n",
    "if \"PROJECT_ROOT\" in os.environ:\n",
    "    lib_location = str(Path(os.environ[\"PROJECT_ROOT\"]).resolve())\n",
    "else:\n",
    "    lib_location = str(Path(\"../../\").resolve())\n",
    "if lib_location not in sys.path:\n",
    "    sys.path.insert(0, lib_location)\n",
    "import lib as pitn\n",
    "\n",
    "# Include the top-level lib module along with its submodules.\n",
    "%aimport lib\n",
    "# Grab all submodules of lib, not including modules outside of the package.\n",
    "includes = list(\n",
    "    filter(\n",
    "        lambda m: m.startswith(\"lib.\"),\n",
    "        map(lambda x: x[1].__name__, inspect.getmembers(pitn, inspect.ismodule)),\n",
    "    )\n",
    ")\n",
    "# Run aimport magic with constructed includes.\n",
    "ipy = IPython.get_ipython()\n",
    "ipy.run_line_magic(\"aimport\", \", \".join(includes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:45.759358Z",
     "iopub.status.busy": "2021-05-17T18:48:45.759206Z",
     "iopub.status.idle": "2021-05-17T18:48:45.810680Z",
     "shell.execute_reply": "2021-05-17T18:48:45.809984Z",
     "shell.execute_reply.started": "2021-05-17T18:48:45.759340Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch setup\n",
    "\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:45.811728Z",
     "iopub.status.busy": "2021-05-17T18:48:45.811560Z",
     "iopub.status.idle": "2021-05-17T18:48:46.050230Z",
     "shell.execute_reply": "2021-05-17T18:48:46.049215Z",
     "shell.execute_reply.started": "2021-05-17T18:48:45.811708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # GPU information\n",
    "    # Taken from\n",
    "    # <https://www.thepythoncode.com/article/get-hardware-system-information-python>.\n",
    "    # If GPUtil is not installed, skip this step.\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        print(\"=\" * 50, \"GPU Specs\", \"=\" * 50)\n",
    "        list_gpus = []\n",
    "        for gpu in gpus:\n",
    "            # get the GPU id\n",
    "            gpu_id = gpu.id\n",
    "            # name of GPU\n",
    "            gpu_name = gpu.name\n",
    "            driver_version = gpu.driver\n",
    "            cuda_version = torch.version.cuda\n",
    "            # get total memory\n",
    "            gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "            gpu_uuid = gpu.uuid\n",
    "            list_gpus.append(\n",
    "                (\n",
    "                    gpu_id,\n",
    "                    gpu_name,\n",
    "                    driver_version,\n",
    "                    cuda_version,\n",
    "                    gpu_total_memory,\n",
    "                    gpu_uuid,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            tabulate(\n",
    "                list_gpus,\n",
    "                headers=(\n",
    "                    \"id\",\n",
    "                    \"Name\",\n",
    "                    \"Driver Version\",\n",
    "                    \"CUDA Version\",\n",
    "                    \"Total Memory\",\n",
    "                    \"uuid\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.051360Z",
     "iopub.status.busy": "2021-05-17T18:48:46.051194Z",
     "iopub.status.idle": "2021-05-17T18:48:46.055219Z",
     "shell.execute_reply": "2021-05-17T18:48:46.054742Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.051340Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2021-05-17T18:48:45.834996+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-72-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 73342213b8e010f0efb1a39ad9a40017b16be23f\n",
      "\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "GPUtil           : 1.4.0\n",
      "scipy            : 1.5.3\n",
      "ants             : 0.2.7\n",
      "nibabel          : 3.2.1\n",
      "einops           : 0.3.0\n",
      "matplotlib       : 3.4.1\n",
      "torchio          : 0.18.37\n",
      "pytorch_lightning: 1.2.6\n",
      "natsort          : 7.1.1\n",
      "pandas           : 1.2.3\n",
      "dipy             : 1.4.0\n",
      "numpy            : 1.20.2\n",
      "torch            : 1.8.1\n",
      "nilearn          : 0.7.1\n",
      "skimage          : 0.18.1\n",
      "IPython          : 7.22.0\n",
      "seaborn          : 0.11.1\n",
      "json             : 2.0.9\n",
      "torchvision      : 0.9.1\n",
      "\n",
      "================================================== GPU Specs ==================================================\n",
      "  id  Name       Driver Version      CUDA Version  Total Memory    uuid\n",
      "----  ---------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  TITAN RTX  460.73.01                   11.1  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.056213Z",
     "iopub.status.busy": "2021-05-17T18:48:46.056064Z",
     "iopub.status.idle": "2021-05-17T18:48:46.061202Z",
     "shell.execute_reply": "2021-05-17T18:48:46.060661Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.056194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"]) / \"hcp\"\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"]) / \"hcp\"\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.062417Z",
     "iopub.status.busy": "2021-05-17T18:48:46.062238Z",
     "iopub.status.idle": "2021-05-17T18:48:46.072688Z",
     "shell.execute_reply": "2021-05-17T18:48:46.072107Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.062396Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 3 temporary results, culling to the most recent\n",
      "Deleted temporary results directory  /home/jovyan/work/pitn/results/tmp/2021-05-17T15_25_08__debug\n",
      "Experiment results directory:  /home/jovyan/work/pitn/results/tmp/2021-05-17T18_48_46__debug\n"
     ]
    }
   ],
   "source": [
    "# Experiment logging setup\n",
    "experiment_name = \"debug\"\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_results_dir = results_dir / \"tmp\"\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 3\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "(experiment_results_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(\n",
    "    \"Experiment results directory: \",\n",
    "    experiment_results_dir,\n",
    ")\n",
    "assert experiment_results_dir.exists()\n",
    "\n",
    "experiment_results_log = experiment_results_dir / \"log.txt\"\n",
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Global Function & Class Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.074727Z",
     "iopub.status.busy": "2021-05-17T18:48:46.074569Z",
     "iopub.status.idle": "2021-05-17T18:48:46.077825Z",
     "shell.execute_reply": "2021-05-17T18:48:46.077343Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.074708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsample_factor = 2\n",
    "# Include b=0 shells and b=1000 shells for DTI fitting.\n",
    "bval_range = (0, 1500)\n",
    "dti_fit_method = \"WLS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.079963Z",
     "iopub.status.busy": "2021-05-17T18:48:46.079691Z",
     "iopub.status.idle": "2021-05-17T18:48:46.086874Z",
     "shell.execute_reply": "2021-05-17T18:48:46.086163Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.079934Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patch parameters\n",
    "batch_size = 64\n",
    "# 6 channels for the 6 DTI components\n",
    "channels = 6\n",
    "\n",
    "# Output patch shapes\n",
    "h_out = 14\n",
    "w_out = 14\n",
    "d_out = 14\n",
    "# Output shape after shuffling.\n",
    "output_patch_shape = (channels, h_out, w_out, d_out)\n",
    "output_spatial_patch_shape = output_patch_shape[1:]\n",
    "# This is the factor that determines how over-extended the input patch should be\n",
    "# relative to the size of the full-res patch.\n",
    "# $low_res_patch_dim = \\frac{full_res_patch_dim}{downsample_factor} \\times low_res_sample_extension$\n",
    "# A value of 1 indicates that the input patch dims will be exactly divided by the\n",
    "# downsample factor. A dilation > 1 increases the \"spatial extent\" of the input\n",
    "# patch, providing information outside of the target HR patch.\n",
    "low_res_sample_extension = 1.57\n",
    "# Input patch parameters\n",
    "h_in = round(h_out / (downsample_factor) * low_res_sample_extension)\n",
    "w_in = round(w_out / (downsample_factor) * low_res_sample_extension)\n",
    "d_in = round(d_out / (downsample_factor) * low_res_sample_extension)\n",
    "input_patch_shape = (channels, h_in, w_in, d_in)\n",
    "input_spatial_patch_shape = input_patch_shape[1:]\n",
    "\n",
    "# Pre-shuffle output patch sizes.\n",
    "unshuffled_channels_out = channels * downsample_factor ** 3\n",
    "# Output before shuffling\n",
    "unshuffled_output_patch_shape = (unshuffled_channels_out, h_in, w_in, d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.088213Z",
     "iopub.status.busy": "2021-05-17T18:48:46.087999Z",
     "iopub.status.idle": "2021-05-17T18:48:46.093475Z",
     "shell.execute_reply": "2021-05-17T18:48:46.092755Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.088186Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Downsample Factor: {downsample_factor}\\n\")\n",
    "    f.write(f\"DTI Fit Method: {dti_fit_method}\\n\")\n",
    "    f.write(f\"Input Patch Size: {input_patch_shape}\\n\")\n",
    "    f.write(f\"Output Patch Size: {output_patch_shape}\\n\")\n",
    "    f.write(f\"Batch Size: {batch_size}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.094756Z",
     "iopub.status.busy": "2021-05-17T18:48:46.094544Z",
     "iopub.status.idle": "2021-05-17T18:48:46.105178Z",
     "shell.execute_reply": "2021-05-17T18:48:46.104306Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.094729Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-fdcf9eb32dbf>:25: UserWarning:\n",
      "\n",
      "WARNING: Sub-selecting participants for dev and debugging. Subj IDs selected: ['303624', '135528']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{135528: PosixPath('/mnt/storage/data/pitn/hcp/135528/T1w/Diffusion'),\n",
       " 303624: PosixPath('/mnt/storage/data/pitn/hcp/303624/T1w/Diffusion')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: dict = dict()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "selected_ids = random.sample(selected_ids, 2)\n",
    "warnings.warn(\n",
    "    \"WARNING: Sub-selecting participants for dev and debugging. \"\n",
    "    + f\"Subj IDs selected: {selected_ids}\"\n",
    ")\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_ids = natsorted(list(map(lambda s: int(s), selected_ids)))\n",
    "\n",
    "for subj_id in selected_ids:\n",
    "    subj_dirs[subj_id] = data_dir / f\"{subj_id}/T1w/Diffusion\"\n",
    "    assert subj_dirs[subj_id].exists()\n",
    "subj_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 90 scans are taken from the $b=1000 \\ s/mm^2$. However, the $b=0$ shells are still required for fitting the diffusion tensors (DTI's), so those will need to be kept, too.\n",
    "\n",
    "To find those, sub-select with the $0 < bvals < 1500$, or roughly thereabout. A b-val of $995$ or $1005$ still counts as a b=1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.106630Z",
     "iopub.status.busy": "2021-05-17T18:48:46.106402Z",
     "iopub.status.idle": "2021-05-17T18:48:46.110894Z",
     "shell.execute_reply": "2021-05-17T18:48:46.110182Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.106602Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.112361Z",
     "iopub.status.busy": "2021-05-17T18:48:46.112055Z",
     "iopub.status.idle": "2021-05-17T18:48:46.122398Z",
     "shell.execute_reply": "2021-05-17T18:48:46.121595Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.112330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the transformation pipeline.\n",
    "# Pad the original image & maks to ensure that lr patches cannot have invalid indices.\n",
    "fr_spatial_padding = tuple(\n",
    "    (np.ceil(np.asarray(input_spatial_patch_shape) * downsample_factor / 2) + 1).astype(\n",
    "        int\n",
    "    )\n",
    ")\n",
    "\n",
    "preproc_transforms = torchio.Compose(\n",
    "    [\n",
    "        torchio.transforms.ToCanonical(include=(\"dwi\", \"brain_mask\"), copy=False),\n",
    "        pitn.transforms.BValSelectionTransform(\n",
    "            bval_range=bval_range,\n",
    "            bval_key=\"bvals\",\n",
    "            bvec_key=\"bvecs\",\n",
    "            include=\"dwi\",\n",
    "            copy=False,\n",
    "        ),\n",
    "        torchio.transforms.Pad(\n",
    "            fr_spatial_padding,\n",
    "            padding_mode=0,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.MeanDownsampleTransform(\n",
    "            downsample_factor,\n",
    "            #                 spatial_padding=lr_spatial_padding,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            keep={\"dwi\": \"fr_dwi\", \"brain_mask\": \"fr_brain_mask\"},\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"dwi\": \"lr_dwi\", \"brain_mask\": \"lr_brain_mask\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"fr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"fr_dwi\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"lr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"lr_dwi\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"fr_dwi\": \"fr_dti\", \"lr_dwi\": \"lr_dti\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.ImageToDictTransform(\n",
    "            include=(\"lr_dti\", \"lr_brain_mask\"), copy=False\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.124150Z",
     "iopub.status.busy": "2021-05-17T18:48:46.123797Z",
     "iopub.status.idle": "2021-05-17T18:48:46.130175Z",
     "shell.execute_reply": "2021-05-17T18:48:46.129064Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.124106Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Preprocessing transformation pipeline: {str(preproc_transforms)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:48:46.132114Z",
     "iopub.status.busy": "2021-05-17T18:48:46.131769Z",
     "iopub.status.idle": "2021-05-17T18:54:21.227901Z",
     "shell.execute_reply": "2021-05-17T18:54:21.227332Z",
     "shell.execute_reply.started": "2021-05-17T18:48:46.132072Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/135528/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 135528\n",
      "\tSelected\n",
      "Downsampling: Subject 135528\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 135528\n",
      "\tDWI shape: torch.Size([108, 169, 198, 169])\n",
      "\tDTI shape: (6, 169, 198, 169)\n",
      "\tFitted DTI model: torch.Size([6, 169, 198, 169])\n",
      "Fitting to DTI: Subject 135528\n",
      "\tDWI shape: torch.Size([108, 85, 99, 85])\n",
      "\tDTI shape: (6, 85, 99, 85)\n",
      "\tFitted DTI model: torch.Size([6, 85, 99, 85])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/303624/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 303624\n",
      "\tSelected\n",
      "Downsampling: Subject 303624\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 303624\n",
      "\tDWI shape: torch.Size([108, 169, 198, 169])\n",
      "\tDTI shape: (6, 169, 198, 169)\n",
      "\tFitted DTI model: torch.Size([6, 169, 198, 169])\n",
      "Fitting to DTI: Subject 303624\n",
      "\tDWI shape: torch.Size([108, 85, 99, 85])\n",
      "\tDTI shape: (6, 85, 99, 85)\n",
      "\tFitted DTI model: torch.Size([6, 85, 99, 85])\n",
      "===Data Loaded & Transformed===\n"
     ]
    }
   ],
   "source": [
    "# Import all image data into a sequence of `torchio.Subject` objects.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "    # Sub-select volumes with only bvals in a certain range. E.x. bvals <= 1100 mm/s^2,\n",
    "    # a.k.a. only the b=0 and b=1000 shells.\n",
    "    bvals = torch.as_tensor(np.loadtxt(subj_dir / \"bvals\").astype(int))\n",
    "    bvecs = torch.as_tensor(np.loadtxt(subj_dir / \"bvecs\"))\n",
    "    # Reshape to be N x 3\n",
    "    if bvecs.shape[0] == 3:\n",
    "        bvecs = bvecs.T\n",
    "\n",
    "    brain_mask = torchio.LabelMap(\n",
    "        subj_dir / \"nodif_brain_mask.nii.gz\",\n",
    "        type=torchio.LABEL,\n",
    "        channels_last=False,\n",
    "    )\n",
    "    mask_data = brain_mask.data.bool().cpu().numpy()\n",
    "    # Dilate the brain mask to give some empty samples to train on.\n",
    "    # Dilate by 2/3 the input patch size, because doing 1/2 would give a very low\n",
    "    # probability of even sampling an empty sample. And 1.0 seems like too much...\n",
    "    st_elem = skimage.morphology.ball(radius=max(fr_spatial_padding))\n",
    "    mask_data = scipy.ndimage.binary_dilation(mask_data[0], st_elem)[None, ...]\n",
    "    # The brain mask is binary.\n",
    "    brain_mask.set_data(torch.from_numpy(mask_data).to(brain_mask.data.bool()))\n",
    "\n",
    "    dwi = torchio.ScalarImage(\n",
    "        subj_dir / \"data.nii.gz\",\n",
    "        type=torchio.INTENSITY,\n",
    "        bvals=bvals,\n",
    "        bvecs=bvecs,\n",
    "        reader=pitn.io.nifti_reader,\n",
    "        channels_last=True,\n",
    "    )\n",
    "\n",
    "    subject_dict = torchio.Subject(subj_id=subj_id, dwi=dwi, brain_mask=brain_mask)\n",
    "    preproced_subj = preproc_transforms(subject_dict)\n",
    "\n",
    "    fr_mask = preproced_subj.fr_brain_mask.tensor\n",
    "\n",
    "    # Store subject-and-channel-wise means and vars in order to reverse the normalization\n",
    "    # for the final visualization/output.\n",
    "    preproced_subj[\"channel_means\"] = (\n",
    "        (preproced_subj.fr_dti.tensor * fr_mask)\n",
    "        .mean(dim=(1, 2, 3), keepdim=True)\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    preproced_subj[\"channel_var\"] = (\n",
    "        (preproced_subj.fr_dti.tensor * fr_mask)\n",
    "        .var(dim=(1, 2, 3), keepdim=True)\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    subj_data[subj_id] = preproced_subj\n",
    "\n",
    "print(\"===Data Loaded & Transformed===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:54:21.228980Z",
     "iopub.status.busy": "2021-05-17T18:54:21.228796Z",
     "iopub.status.idle": "2021-05-17T18:54:21.232432Z",
     "shell.execute_reply": "2021-05-17T18:54:21.231952Z",
     "shell.execute_reply.started": "2021-05-17T18:54:21.228957Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj_dataset = torchio.SubjectsDataset(list(subj_data.values()), load_getitem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:56:44.924071Z",
     "iopub.status.busy": "2021-05-17T18:56:44.923510Z",
     "iopub.status.idle": "2021-05-17T18:56:48.274150Z",
     "shell.execute_reply": "2021-05-17T18:56:48.273480Z",
     "shell.execute_reply.started": "2021-05-17T18:56:44.924009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject(s) IDs:  [135528]\n",
      "Training subject(s) IDs:  [303624]\n"
     ]
    }
   ],
   "source": [
    "# Data train/validation/test split\n",
    "test_percent = 0.2\n",
    "# test_percent = 0.5\n",
    "train_percent = 1 - test_percent\n",
    "# val_percent = 0.1\n",
    "\n",
    "num_subjs = len(subj_dataset)\n",
    "num_test_subjs = int(np.ceil(num_subjs * test_percent))\n",
    "num_train_subjs = num_subjs - num_test_subjs\n",
    "subj_list = subj_dataset.dry_iter()\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Create partial function to collect list of samples and form a tuple of tensors.\n",
    "collate_fn = functools.partial(\n",
    "    pitn.samplers.collate_subj, full_res_key=\"fr_dti\", low_res_key=\"lr_dti\"\n",
    ")\n",
    "\n",
    "test_dataset = torchio.SubjectsDataset(subj_list[:num_test_subjs], load_getitem=False)\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1 and num_train_subjs == 0:\n",
    "    print(\"DEBUG: Only 1 subject with no training subjects, mixing train and test set\")\n",
    "    subj_list = subj_list[:]\n",
    "    num_train_subjs = num_test_subjs\n",
    "else:\n",
    "    subj_list = subj_list[num_test_subjs:]\n",
    "\n",
    "train_dataset = torchio.SubjectsDataset(subj_list, load_getitem=False)\n",
    "\n",
    "# Training patch sampler, random across all patches of all volumes.\n",
    "train_sampler = pitn.samplers.MultiresSampler(\n",
    "    source_img_key=\"fr_dti\",\n",
    "    low_res_key=\"lr_dti\",\n",
    "    downsample_factor_key=\"downsample_factor\",\n",
    "    label_name=\"fr_brain_mask\",\n",
    "    source_spatial_patch_size=output_spatial_patch_shape,\n",
    "    low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "    label_probabilities={0: 0, 1: 1},\n",
    ")\n",
    "\n",
    "patches_per_subj = 8000\n",
    "# Hold enough for 2 epochs at a time.\n",
    "queue_max_length = patches_per_subj * num_train_subjs * 2\n",
    "\n",
    "# Set up a torchio.Queue to act as a sampler proxy for the torch DataLoader\n",
    "train_queue = torchio.Queue(\n",
    "    train_dataset,\n",
    "    max_length=queue_max_length,\n",
    "    samples_per_volume=patches_per_subj,\n",
    "    sampler=train_sampler,\n",
    "    shuffle_patches=True,\n",
    "    shuffle_subjects=True,\n",
    "    num_workers=6,\n",
    "    #     verbose=True,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_queue,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Set up testing objects.\n",
    "# Calculate the patch overlap needed for ~50% of the patch volume overlapping (which is\n",
    "# not the same as dividing each dimension by 2).\n",
    "input_vol_half_overlap = int(\n",
    "    np.floor(np.power(np.prod(input_spatial_patch_shape) / 2, 1 / 3))\n",
    ")\n",
    "# torchio requires an even-numbered overlap.\n",
    "if input_vol_half_overlap % 2 == 1:\n",
    "    input_vol_half_overlap += 1\n",
    "input_vol_half_overlap = np.repeat(input_vol_half_overlap, 3)\n",
    "\n",
    "# Repeat for the output.\n",
    "output_vol_half_overlap = np.floor(\n",
    "    np.power(np.prod(output_spatial_patch_shape) / 2, 1 / 3)\n",
    ").astype(int)\n",
    "# torchio requires an even-numbered overlap.\n",
    "if output_vol_half_overlap % 2 == 1:\n",
    "    output_vol_half_overlap += 1\n",
    "output_vol_half_overlap = np.repeat(output_vol_half_overlap, 3)\n",
    "\n",
    "# Test samplers\n",
    "test_samplers = list()\n",
    "for subj in test_dataset.dry_iter():\n",
    "    test_samplers.append(\n",
    "        pitn.samplers.MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor=downsample_factor,\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            patch_overlap=output_vol_half_overlap,\n",
    "            padding_mode=\"constant\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "concat_test_dataset = torch.utils.data.ConcatDataset(test_samplers)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    concat_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Test subject(s) IDs: \", [s.subj_id for s in test_dataset.dry_iter()])\n",
    "print(\"Training subject(s) IDs: \", [s.subj_id for s in train_dataset.dry_iter()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:56:49.210503Z",
     "iopub.status.busy": "2021-05-17T18:56:49.209913Z",
     "iopub.status.idle": "2021-05-17T18:56:49.217621Z",
     "shell.execute_reply": "2021-05-17T18:56:49.216234Z",
     "shell.execute_reply.started": "2021-05-17T18:56:49.210439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# o = np.floor(np.power(np.prod(input_spatial_patch_shape) / 2, 1 / 3))\n",
    "# o = np.asarray([o, o, o]).repeat(2)\n",
    "# o = np.concatenate(([0, 0], o))\n",
    "# np.split(o, 4)\n",
    "# 11 / 1.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:56:49.542579Z",
     "iopub.status.busy": "2021-05-17T18:56:49.542075Z",
     "iopub.status.idle": "2021-05-17T18:56:49.551617Z",
     "shell.execute_reply": "2021-05-17T18:56:49.550246Z",
     "shell.execute_reply.started": "2021-05-17T18:56:49.542521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Training Set Subjects: {[s.subj_id for s in test_dataset.dry_iter()]}\\n\")\n",
    "    f.write(f\"Test Set Subjects: {[s.subj_id for s in train_dataset.dry_iter()]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:56:50.662151Z",
     "iopub.status.busy": "2021-05-17T18:56:50.661584Z",
     "iopub.status.idle": "2021-05-17T18:56:50.694519Z",
     "shell.execute_reply": "2021-05-17T18:56:50.693782Z",
     "shell.execute_reply.started": "2021-05-17T18:56:50.662088Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "class DIQTSystem(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        downsample_factor,\n",
    "        train_loss_method: str,\n",
    "        norm_method=None,\n",
    "        train_loss_log_file=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = channels\n",
    "        self._downsample_factor = downsample_factor\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = pitn.nn.models.ThreeConv(\n",
    "            self._channels, self._downsample_factor, norm_method=norm_method\n",
    "        )\n",
    "\n",
    "        ## Training parameters\n",
    "        self._lr = 10e-3\n",
    "        self._betas = (0.9, 0.999)\n",
    "        loss_methods = {\n",
    "            \"MSE\".casefold(): torch.nn.MSELoss(reduction=\"mean\"),\n",
    "            \"SSE\".casefold(): torch.nn.MSELoss(reduction=\"sum\"),\n",
    "            \"RMSE\".casefold(): lambda y_hat, y: torch.sqrt(\n",
    "                F.mse_loss(y_hat, y, reduction=\"mean\")\n",
    "            ),\n",
    "            \"L1\".casefold(): torch.nn.L1Loss(reduction=\"mean\"),\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            self._loss_fn = loss_methods[train_loss_method.casefold()]\n",
    "        except (AttributeError, KeyError) as e:\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = {\"train_loss\": list(), \"val_loss\": list(), \"test_loss\": list()}\n",
    "        self.train_loss_log_file = train_loss_log_file\n",
    "        if self.train_loss_log_file is not None:\n",
    "            with open(self.train_loss_log_file, \"a+\") as f:\n",
    "                f.write(\"epoch, batch_idx, loss\\n\")\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_with_layer(norm_layer, y):\n",
    "\n",
    "        if norm_layer is not None:\n",
    "            if not norm_layer.track_running_stats:\n",
    "                y = norm_layer(y)\n",
    "            else:\n",
    "                if isinstance(norm_layer, torch.nn.InstanceNorm3d):\n",
    "                    y = F.instance_norm(\n",
    "                        y,\n",
    "                        eps=norm_layer.eps,\n",
    "                    )\n",
    "                elif isinstance(norm_layer, torch.nn.BatchNorm3d):\n",
    "                    y = F.batch_norm(\n",
    "                        y,\n",
    "                        eps=norm_layer.eps,\n",
    "                    )\n",
    "\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        # We need both prediction and ground truth to be a standard normal distribution\n",
    "        # for a fair calculation of the loss.\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "        if self.net.norm is not None:\n",
    "            y = self.normalize_with_layer(self.net.norm, y)\n",
    "\n",
    "        loss = self._loss_fn(y_pred, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, logger=False)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        # Only log each epoch if a log filename was given.\n",
    "        if self.train_loss_log_file:\n",
    "\n",
    "            row_iter = itertools.product(\n",
    "                (self.current_epoch,),\n",
    "                range(len(training_step_outputs)),\n",
    "                [str(float(l[\"loss\"].detach().cpu())) for l in training_step_outputs],\n",
    "            )\n",
    "\n",
    "            loss_rows = \"\".join(\n",
    "                [\n",
    "                    f\"{epoch}, {batch_idx}, {loss}\\n\"\n",
    "                    for epoch, batch_idx, loss in row_iter\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            with open(self.train_loss_log_file, \"a+\") as f:\n",
    "                f.write(loss_rows)\n",
    "\n",
    "    #     def validation_step(self, batch, batch_idx):\n",
    "    #         pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        # We can't normalize the outputs or ground truth because it would change\n",
    "        # our units out of $mm^2/s$.\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "        #         if self.net.norm is not None:\n",
    "        #             y = self.normalize_with_layer(self.net.norm, y)\n",
    "\n",
    "        test_loss = torch.sqrt(F.mse_loss(y_pred, y, reduction=\"mean\"))\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        self.plain_log[\"test_loss\"].append(float(test_loss.cpu()))\n",
    "\n",
    "        return test_loss\n",
    "\n",
    "    def viz_step(self, x):\n",
    "        \"\"\"Step for running inference for the purpose of a visualization.\n",
    "\n",
    "        Mainly deals with normalization.\"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.net.training:\n",
    "                was_training = True\n",
    "            else:\n",
    "                was_training = False\n",
    "\n",
    "            self.net.eval()\n",
    "\n",
    "            y_pred = self.net(x, norm_output=True)\n",
    "\n",
    "            if isinstance(self.net.norm, torch.nn.InstanceNorm3d):\n",
    "                target_mean = torch.mean(x, dim=(2, 3, 4), keepdim=True)\n",
    "                target_var = torch.var(x, dim=(2, 3, 4), keepdim=True)\n",
    "                eps = self.net.norm.eps\n",
    "\n",
    "            elif isinstance(self.net.norm, torch.nn.BatchNorm3d):\n",
    "                target_mean = torch.mean(x, dim=(0, 2, 3, 4), keepdim=True)\n",
    "                target_var = torch.var(x, dim=(0, 2, 3, 4), keepdim=True)\n",
    "                eps = self.net.norm.eps\n",
    "            else:\n",
    "                target_mean = torch.zeros(1, 1, 1, 1, 1).to(x)\n",
    "                target_var = torch.ones(1, 1, 1, 1, 1).to(x)\n",
    "                eps = 1e-10\n",
    "\n",
    "            y_pred = pitn.data.norm.denormalize_batch(\n",
    "                y_pred, target_mean, target_var, eps=eps\n",
    "            )\n",
    "\n",
    "            if was_training:\n",
    "                self.net.train()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.net.parameters(), lr=self._lr, betas=self._betas\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:56:51.636340Z",
     "iopub.status.busy": "2021-05-17T18:56:51.635774Z",
     "iopub.status.idle": "2021-05-17T18:56:51.643950Z",
     "shell.execute_reply": "2021-05-17T18:56:51.642544Z",
     "shell.execute_reply.started": "2021-05-17T18:56:51.636279Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_epochs = 20\n",
    "norm_method = \"instance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:56:51.847550Z",
     "iopub.status.busy": "2021-05-17T18:56:51.847029Z",
     "iopub.status.idle": "2021-05-17T18:56:51.855001Z",
     "shell.execute_reply": "2021-05-17T18:56:51.853480Z",
     "shell.execute_reply.started": "2021-05-17T18:56:51.847490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_name = \"MSE\"\n",
    "train_loss_log_file = experiment_results_dir / \"train_loss.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T18:56:52.976643Z",
     "iopub.status.busy": "2021-05-17T18:56:52.976138Z",
     "iopub.status.idle": "2021-05-17T18:56:53.619768Z",
     "shell.execute_reply": "2021-05-17T18:56:53.618517Z",
     "shell.execute_reply.started": "2021-05-17T18:56:52.976585Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type      | Params\n",
      "---------------------------------------\n",
      "0 | net      | ThreeConv | 142 K \n",
      "1 | _loss_fn | MSELoss   | 0     \n",
      "---------------------------------------\n",
      "142 K     Trainable params\n",
      "0         Non-trainable params\n",
      "142 K     Total params\n",
      "0.572     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665216c1e513440bb8a38915cf456a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "ERROR: Invalid low-res patch: tensor([], size=(6, 11, 0, 11)), torch.Size([6, 11, 0, 11]) |Index: [46 89 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5ddfea711070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtrain_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmicrosecond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_start_timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train duration: {train_duration}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mval_loop_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/profiler/profilers.py\u001b[0m in \u001b[0;36mprofile_iterable\u001b[0;34m(self, iterable, action_name)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\u001b[0m in \u001b[0;36m_with_is_last\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     45\u001b[0m         See `https://stackoverflow.com/a/1630350 <https://stackoverflow.com/a/1630350>`_\"\"\"\n\u001b[1;32m     46\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# yield last and has next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \"\"\"\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mrequest_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \"\"\"\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Recursively apply to collection items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/torchio/data/queue.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Patches list is empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0msample_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sampled_patches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/pitn/lib/python3.8/site-packages/torchio/data/queue.py\u001b[0m in \u001b[0;36m_fill\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0msubject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_subject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_per_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_patches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pitn/lib/samplers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, subject, num_patches)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlr_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0;34mf\"ERROR: Invalid low-res patch: {lr_patch}, {lr_patch.shape} |\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0;34mf\"Index: {lr_index_ini}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ERROR: Invalid low-res patch: tensor([], size=(6, 11, 0, 11)), torch.Size([6, 11, 0, 11]) |Index: [46 89 24]"
     ]
    }
   ],
   "source": [
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "model = DIQTSystem(\n",
    "    channels=channels,\n",
    "    downsample_factor=downsample_factor,\n",
    "    train_loss_log_file=train_loss_log_file,\n",
    "    norm_method=norm_method,\n",
    "    train_loss_method=train_loss_name,\n",
    ")\n",
    "\n",
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Max epochs: {max_epochs}\\n\")\n",
    "    f.write(f\"Model overview: {model}\\n\")\n",
    "    f.write(f\"Training loss function: {train_loss_name}\\n\")\n",
    "\n",
    "# Create trainer object. Note: `automatic_optimization` needs to be set to `False` when\n",
    "# manually performing backprop. See\n",
    "# <https://colab.research.google.com/drive/1nGtvBFirIvtNQdppe2xBes6aJnZMjvl8?usp=sharing>\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=max_epochs, progress_bar_refresh_rate=10)\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.214231Z",
     "iopub.status.idle": "2021-05-17T18:54:27.214474Z",
     "shell.execute_reply": "2021-05-17T18:54:27.214356Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.215236Z",
     "iopub.status.idle": "2021-05-17T18:54:27.215464Z",
     "shell.execute_reply": "2021-05-17T18:54:27.215354Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + train_loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.216202Z",
     "iopub.status.idle": "2021-05-17T18:54:27.216429Z",
     "shell.execute_reply": "2021-05-17T18:54:27.216320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(model.plain_log[\"train_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.217113Z",
     "iopub.status.idle": "2021-05-17T18:54:27.217388Z",
     "shell.execute_reply": "2021-05-17T18:54:27.217275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.218123Z",
     "iopub.status.idle": "2021-05-17T18:54:27.218357Z",
     "shell.execute_reply": "2021-05-17T18:54:27.218248Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.219096Z",
     "iopub.status.idle": "2021-05-17T18:54:27.219324Z",
     "shell.execute_reply": "2021-05-17T18:54:27.219214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss_name = \"RMSE\"\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "\n",
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Test loss function: {test_loss_name}\\n\")\n",
    "\n",
    "row_iter = enumerate(model.plain_log[\"test_loss\"])\n",
    "test_loss_tabular = \"\".join([f\"{batch_idx}, {loss}\\n\" for batch_idx, loss in row_iter])\n",
    "\n",
    "with open(test_loss_log_file, \"a+\") as f:\n",
    "    f.write(\"batch_idx, loss\\n\")\n",
    "    f.write(test_loss_tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cubic Spline Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.220060Z",
     "iopub.status.idle": "2021-05-17T18:54:27.220286Z",
     "shell.execute_reply": "2021-05-17T18:54:27.220178Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cubic_spline_test_log = list()\n",
    "\n",
    "for subj in test_dataset.dry_iter():\n",
    "    print(\"---\")\n",
    "    target_shape = subj[\"fr_dti\"][\"data\"].cpu().numpy().shape\n",
    "    interp_cubic_spline = scipy.ndimage.zoom(\n",
    "        subj[\"lr_dti\"][\"data\"].cpu().numpy(),\n",
    "        zoom=(1, downsample_factor, downsample_factor, downsample_factor),\n",
    "        order=3,\n",
    "    )\n",
    "    # Crop off the end few voxels to account for the lack of padding used in full-\n",
    "    # volume inference.\n",
    "    interp_cubic_spline = interp_cubic_spline[\n",
    "        :, : target_shape[1], : target_shape[2], : target_shape[3]\n",
    "    ]\n",
    "    print(f\"Subj {subj['subj_id']} done\")\n",
    "\n",
    "    cubic_spline_test_log.append(interp_cubic_spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.221017Z",
     "iopub.status.idle": "2021-05-17T18:54:27.221244Z",
     "shell.execute_reply": "2021-05-17T18:54:27.221134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.asarray(subj[\"fr_dti\"][\"data\"].cpu().numpy().shape) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.221981Z",
     "iopub.status.idle": "2021-05-17T18:54:27.222209Z",
     "shell.execute_reply": "2021-05-17T18:54:27.222100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(test_vol_results[0].full_res[0].cpu().numpy().shape)\n",
    "print(test_vol_results[0].low_res[0].cpu().numpy().shape)\n",
    "cubic_spline_test_log[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.222937Z",
     "iopub.status.idle": "2021-05-17T18:54:27.223164Z",
     "shell.execute_reply": "2021-05-17T18:54:27.223055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    test_vol_results[0].full_res[0][slice_idx].cpu().numpy(), alpha=0.25, cmap=\"gray\"\n",
    ")\n",
    "plt.imshow(\n",
    "    cubic_spline_test_log[0][0][slice_idx],\n",
    "    alpha=0.5,\n",
    "    cmap=\"Reds\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.223921Z",
     "iopub.status.idle": "2021-05-17T18:54:27.224149Z",
     "shell.execute_reply": "2021-05-17T18:54:27.224039Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "\n",
    "sns.histplot(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]),\n",
    "    kde=True,\n",
    "    stat=\"probability\",\n",
    "    #     log_scale=True,\n",
    "    ax=ax_prob,\n",
    "    label=\"Current Model\",\n",
    "    legend=False,\n",
    ")\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw an entire other plot, invisibly, to have another y-axis.\n",
    "ax_count = ax_prob.twinx()\n",
    "sns.histplot(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]), alpha=0, ax=ax_count, stat=\"count\"\n",
    ")\n",
    "\n",
    "comparison_kwargs = {\"ls\": \"--\", \"alpha\": 0.8, \"lw\": 2.5}\n",
    "\n",
    "plt.axvline(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    31.738 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) C-spline Mean\",\n",
    "    color=\"red\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    23.139 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) RF\",\n",
    "    color=\"orange\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.609 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) ESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.412 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) Best\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    12.78 * (10.0 ** (-4)),\n",
    "    label=\"(Blumberg etal, 2018) Best\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(f\"Test Loss Histogram with Test Metric {test_loss_name}\")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.224877Z",
     "iopub.status.idle": "2021-05-17T18:54:27.225103Z",
     "shell.execute_reply": "2021-05-17T18:54:27.224994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.asarray(model.plain_log[\"test_loss\"]).max())\n",
    "print(np.asarray(model.plain_log[\"test_loss\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.225858Z",
     "iopub.status.idle": "2021-05-17T18:54:27.226091Z",
     "shell.execute_reply": "2021-05-17T18:54:27.225982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volume of full-res ground truth, low-res downsample, and high-res\n",
    "# inferences.\n",
    "@dataclass\n",
    "class SubjResult:\n",
    "    subj_id: int\n",
    "    full_res: torch.Tensor\n",
    "    low_res: torch.Tensor\n",
    "    full_res_predicted: torch.Tensor\n",
    "    full_res_cubic_spline: np.ndarray\n",
    "\n",
    "\n",
    "test_vol_results = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj in test_dataset.dry_iter():\n",
    "\n",
    "        # Create a grid sampler for this subject.\n",
    "        subj_sampler = pitn.samplers.MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor_key=\"downsample_factor\",\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            #             patch_overlap=output_vol_half_overlap,\n",
    "            patch_overlap=0,\n",
    "        )\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            subj_sampler, batch_size=256, pin_memory=True\n",
    "        )\n",
    "        aggregator = torchio.GridAggregator(subj_sampler)\n",
    "\n",
    "        # Iterate over all batches of patches.\n",
    "        for batch in loader:\n",
    "\n",
    "            x = batch[\"lr_dti\"][\"data\"]\n",
    "            # Locations are in reference to the full-res groud truth.\n",
    "            locations = batch[\"location\"]\n",
    "            predictions = model.viz_step(x.to(model.device)).detach().cpu()\n",
    "\n",
    "            aggregator.add_batch(predictions, locations)\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "\n",
    "        # Calculate cubic spline as a baseline.\n",
    "        cubic_splines = scipy.ndimage.zoom(\n",
    "            subj[\"lr_dti\"][\"data\"].cpu().numpy(),\n",
    "            zoom=((1,) + (downsample_factor,) * 3),\n",
    "            order=3,\n",
    "        )\n",
    "\n",
    "        subj_means = torch.as_tensor(subj[\"channel_means\"])\n",
    "        subj_vars = torch.as_tensor(subj[\"channel_var\"])\n",
    "        subj_result = SubjResult(\n",
    "            subj_id=subj[\"subj_id\"],\n",
    "            full_res=subj[\"fr_dti\"].tensor,\n",
    "            low_res=subj[\"lr_dti\"][\"data\"],\n",
    "            full_res_predicted=aggregator.get_output_tensor(),\n",
    "            full_res_cubic_spline=torch.from_numpy(cubic_splines),\n",
    "        )\n",
    "\n",
    "        test_vol_results.append(subj_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.226816Z",
     "iopub.status.idle": "2021-05-17T18:54:27.227042Z",
     "shell.execute_reply": "2021-05-17T18:54:27.226933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis_subj_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.227773Z",
     "iopub.status.idle": "2021-05-17T18:54:27.227998Z",
     "shell.execute_reply": "2021-05-17T18:54:27.227890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for prediction.\n",
    "tensor_key = \"full_res_predicted\"\n",
    "pred_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "pred_dir_map = pred_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.228731Z",
     "iopub.status.idle": "2021-05-17T18:54:27.228959Z",
     "shell.execute_reply": "2021-05-17T18:54:27.228848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for cubic spline interpolation.\n",
    "tensor_key = \"full_res_cubic_spline\"\n",
    "cspline_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "cspline_dir_map = cspline_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.229679Z",
     "iopub.status.idle": "2021-05-17T18:54:27.229905Z",
     "shell.execute_reply": "2021-05-17T18:54:27.229796Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map.\n",
    "tensor_key = \"full_res\"\n",
    "fr_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "fr_dir_map = fr_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.230650Z",
     "iopub.status.idle": "2021-05-17T18:54:27.230877Z",
     "shell.execute_reply": "2021-05-17T18:54:27.230767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for low-res input.\n",
    "tensor_key = \"low_res\"\n",
    "lr_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "lr_dir_map = lr_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.232388Z",
     "iopub.status.idle": "2021-05-17T18:54:27.232707Z",
     "shell.execute_reply": "2021-05-17T18:54:27.232547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_idx = (slice(None, None, None), 78, slice(None, None, None))\n",
    "low_res_slice_idx = tuple(s // 2 if isinstance(s, int) else s for s in slice_idx)\n",
    "print(slice_idx)\n",
    "print(low_res_slice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.233772Z",
     "iopub.status.idle": "2021-05-17T18:54:27.234116Z",
     "shell.execute_reply": "2021-05-17T18:54:27.233948Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cspline_dir_map.shape\n",
    "fr_dir_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.235183Z",
     "iopub.status.idle": "2021-05-17T18:54:27.235429Z",
     "shell.execute_reply": "2021-05-17T18:54:27.235315Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(pred_dir_map[slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"pred_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.236101Z",
     "iopub.status.idle": "2021-05-17T18:54:27.236326Z",
     "shell.execute_reply": "2021-05-17T18:54:27.236217Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(cspline_dir_map[slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"cubic_spline_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.236878Z",
     "iopub.status.idle": "2021-05-17T18:54:27.237098Z",
     "shell.execute_reply": "2021-05-17T18:54:27.236986Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(fr_dir_map[slice_idx]))\n",
    "# plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"ground_truth_dir_map_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.237642Z",
     "iopub.status.idle": "2021-05-17T18:54:27.237856Z",
     "shell.execute_reply": "2021-05-17T18:54:27.237750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(lr_dir_map[low_res_slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"low_res_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.238756Z",
     "iopub.status.idle": "2021-05-17T18:54:27.239032Z",
     "shell.execute_reply": "2021-05-17T18:54:27.238921Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"jet\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error between FR and prediction.\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(np.rot90(dti[j_col]), cmap=cmap, interpolation=None)\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Per-Image Normalization\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_per_img_norm.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.239607Z",
     "iopub.status.idle": "2021-05-17T18:54:27.239827Z",
     "shell.execute_reply": "2021-05-17T18:54:27.239719Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"jet\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95)\n",
    "min_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05)\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dti,\n",
    "            vmax=max_dti,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "color_norm = mpl.colors.Normalize(vmin=min_dti, vmax=max_dti)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap),\n",
    "    ax=axs,\n",
    "    location=\"right\",\n",
    "    fraction=0.1,\n",
    "    pad=0.03,\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Normalized over All Images\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_global_norm.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.240544Z",
     "iopub.status.idle": "2021-05-17T18:54:27.240766Z",
     "shell.execute_reply": "2021-05-17T18:54:27.240658Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, low-res input, and root squared error\n",
    "# Normalize by index in the DTI coefficients.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "\n",
    "channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"coolwarm\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "max_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95, axis=1\n",
    ")\n",
    "min_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05, axis=1\n",
    ")\n",
    "\n",
    "max_dtis = np.max(np.abs([max_dtis, min_dtis]), axis=0)\n",
    "min_dtis = -1 * max_dtis\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "    axs_cols = list()\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dtis[j_col],\n",
    "            vmax=max_dtis[j_col],\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        axs_cols.append(ax)\n",
    "\n",
    "    axs.append(axs_cols)\n",
    "\n",
    "# Place colorbars on each column.\n",
    "for j_col in range(ncols):\n",
    "\n",
    "    full_col_ax = [axs[i][j_col] for i in range(nrows)]\n",
    "\n",
    "    color_norm = mpl.colors.Normalize(vmin=min_dtis[j_col], vmax=max_dtis[j_col])\n",
    "\n",
    "    color_mappable = mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap)\n",
    "    cbar = fig.colorbar(\n",
    "        color_mappable,\n",
    "        ax=full_col_ax,\n",
    "        location=\"top\",\n",
    "        orientation=\"horizontal\",\n",
    "        pad=0.01,\n",
    "        shrink=0.85,\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=8, rotation=35)\n",
    "    cbar.ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:g}\"))\n",
    "#     cbar.ax.ticklabel_format(scilimits=(3, -3), useOffset=False)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Channel-Wise Normalization\",\n",
    "    y=max_subplot_height + 0.01,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_channel_wise_norm.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-17T18:54:27.241451Z",
     "iopub.status.idle": "2021-05-17T18:54:27.241682Z",
     "shell.execute_reply": "2021-05-17T18:54:27.241573Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment is complete, move the results directory to its final location.\n",
    "experiment_results_dir = experiment_results_dir.rename(final_experiment_results_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c0df22fa1c7481e833da43c2f14758f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "112267c2356f4e678f746579ae75a5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bbe1f397a8204b41bef440c416836bb9",
       "style": "IPY_MODEL_3f93657f6e154f39a207a896ef79ce6c",
       "value": " 0/125 [00:00&lt;?, ?it/s]"
      }
     },
     "16b8e6d2cb864fceb95c25eae19698c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "17758d0e4f874861ad184a8102c70a38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f9c1bb38bd034e0da23e612a328ddc92",
       "style": "IPY_MODEL_58761fe00ba84c9fa738a09cb26e6fb2",
       "value": "Epoch 0:   0%"
      }
     },
     "1b096b31144e4b598e86f0ac58e2a514": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2b55a66e12624a01a3fe8fc33ad6e97d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3f93657f6e154f39a207a896ef79ce6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4db1cebe51de41cfb188e6ea4dbc12c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0c0df22fa1c7481e833da43c2f14758f",
       "style": "IPY_MODEL_1b096b31144e4b598e86f0ac58e2a514",
       "value": " 0/125 [00:00&lt;?, ?it/s]"
      }
     },
     "5412c3ce0699409fa7155ea54163cc2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fbff2de1db5e4ab58e6249955124f15f",
        "IPY_MODEL_b36011153b164d4984dee6683e519e7b",
        "IPY_MODEL_112267c2356f4e678f746579ae75a5f6"
       ],
       "layout": "IPY_MODEL_16b8e6d2cb864fceb95c25eae19698c1"
      }
     },
     "58761fe00ba84c9fa738a09cb26e6fb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "665216c1e513440bb8a38915cf456a43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_17758d0e4f874861ad184a8102c70a38",
        "IPY_MODEL_feb71c6f814b418ca45eb6e9ae802b25",
        "IPY_MODEL_4db1cebe51de41cfb188e6ea4dbc12c1"
       ],
       "layout": "IPY_MODEL_f122b3aeac024dcb8495098b5aa3a7b1"
      }
     },
     "7b9a12baa16f4333b2c069e4ebc603d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8fdb471a18b64c08b4512cb1735bbe0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "b36011153b164d4984dee6683e519e7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_8fdb471a18b64c08b4512cb1735bbe0c",
       "max": 125,
       "style": "IPY_MODEL_2b55a66e12624a01a3fe8fc33ad6e97d"
      }
     },
     "bbe1f397a8204b41bef440c416836bb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf5bb117f5a740e1935efd6d01a189d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cdded582bcfd4e38b8f0c3b9bff1f091": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dfae8d3a50f9412db6c68fd5d94ebf7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f122b3aeac024dcb8495098b5aa3a7b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "f9c1bb38bd034e0da23e612a328ddc92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fbff2de1db5e4ab58e6249955124f15f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7b9a12baa16f4333b2c069e4ebc603d1",
       "style": "IPY_MODEL_bf5bb117f5a740e1935efd6d01a189d4",
       "value": "Epoch 0:   0%"
      }
     },
     "feb71c6f814b418ca45eb6e9ae802b25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_dfae8d3a50f9412db6c68fd5d94ebf7e",
       "max": 125,
       "style": "IPY_MODEL_cdded582bcfd4e38b8f0c3b9bff1f091"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
