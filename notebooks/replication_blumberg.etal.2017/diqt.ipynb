{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Pain in the Net\n",
    "Replication of *Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images*\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "Source work:\n",
    "`S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "from typing import Generator\n",
    "import zipfile\n",
    "\n",
    "import ants\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython\n",
    "\n",
    "# Try importing GPUtil for printing GPU specs.\n",
    "# May not be installed if using CPU only.\n",
    "try:\n",
    "    import GPUtil\n",
    "except ImportError:\n",
    "    warnings.warn(\"WARNING: Package GPUtil not found, cannot print GPU specs\")\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, Markdown\n",
    "import ipyplot\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import nilearn.plotting\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "import addict\n",
    "from addict import Addict\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "import einops\n",
    "import einops.layers\n",
    "import einops.layers.torch\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-specific scripts\n",
    "# It's easier to import it this way rather than make an entirely new package, due to\n",
    "# conflicts with local packages and anaconda installations.\n",
    "# You made me do this, poor python package management!!\n",
    "if \"PROJECT_ROOT\" in os.environ:\n",
    "    lib_location = str(Path(os.environ[\"PROJECT_ROOT\"]).resolve())\n",
    "else:\n",
    "    lib_location = str(Path(\"../../\").resolve())\n",
    "if lib_location not in sys.path:\n",
    "    sys.path.insert(0, lib_location)\n",
    "import lib as pitn\n",
    "\n",
    "# Include the top-level lib module along with its submodules.\n",
    "%aimport lib\n",
    "# Grab all submodules of lib, not including modules outside of the package.\n",
    "includes = list(\n",
    "    filter(\n",
    "        lambda m: m.startswith(\"lib.\"),\n",
    "        map(lambda x: x[1].__name__, inspect.getmembers(pitn, inspect.ismodule)),\n",
    "    )\n",
    ")\n",
    "# Run aimport magic with constructed includes.\n",
    "ipy = IPython.get_ipython()\n",
    "ipy.run_line_magic(\"aimport\", \", \".join(includes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # GPU information\n",
    "    # Taken from\n",
    "    # <https://www.thepythoncode.com/article/get-hardware-system-information-python>.\n",
    "    # If GPUtil is not installed, skip this step.\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        print(\"=\" * 50, \"GPU Specs\", \"=\" * 50)\n",
    "        list_gpus = []\n",
    "        for gpu in gpus:\n",
    "            # get the GPU id\n",
    "            gpu_id = gpu.id\n",
    "            # name of GPU\n",
    "            gpu_name = gpu.name\n",
    "            driver_version = gpu.driver\n",
    "            cuda_version = torch.version.cuda\n",
    "            # get total memory\n",
    "            gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "            gpu_uuid = gpu.uuid\n",
    "            list_gpus.append(\n",
    "                (\n",
    "                    gpu_id,\n",
    "                    gpu_name,\n",
    "                    driver_version,\n",
    "                    cuda_version,\n",
    "                    gpu_total_memory,\n",
    "                    gpu_uuid,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            tabulate(\n",
    "                list_gpus,\n",
    "                headers=(\n",
    "                    \"id\",\n",
    "                    \"Name\",\n",
    "                    \"Driver Version\",\n",
    "                    \"CUDA Version\",\n",
    "                    \"Total Memory\",\n",
    "                    \"uuid\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"]) / \"hcp\"\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"]) / \"hcp\"\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = \"debug_dev_boxplots\"\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_results_dir = results_dir / \"tmp\"\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 3\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dict to keep track of experiment configuration parameters. Will not be logged to\n",
    "# tensorboard.\n",
    "exp_params = Addict()\n",
    "# Dict to keep track of tensorboard hparams that we *specifically* want to compare\n",
    "# between runs.\n",
    "compare_hparams = Addict(hparam=Addict(), metric=Addict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsample_factor = 2\n",
    "# Include b=0 shells and b=1000 shells for DTI fitting.\n",
    "bval_range = (0, 1500)\n",
    "dti_fit_method = \"WLS\"\n",
    "exp_params.update(\n",
    "    {\n",
    "        \"downsample_factor\": downsample_factor,\n",
    "        \"bval_range\": bval_range,\n",
    "        \"dti_fit_method\": dti_fit_method,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patch parameters\n",
    "batch_size = 12\n",
    "# 6 channels for the 6 DTI components\n",
    "channels = 6\n",
    "\n",
    "# Output patch shapes\n",
    "h_out = 14\n",
    "w_out = 14\n",
    "d_out = 14\n",
    "\n",
    "# This is the factor that determines how over-extended the input patch should be\n",
    "# relative to the size of the full-res patch.\n",
    "# $low_res_patch_dim = \\frac{full_res_patch_dim}{downsample_factor} \\times low_res_sample_extension$\n",
    "# A value of 1 indicates that the input patch dims will be exactly divided by the\n",
    "# downsample factor. A dilation > 1 increases the \"spatial extent\" of the input\n",
    "# patch, providing information outside of the target HR patch.\n",
    "low_res_sample_extension = 1.57\n",
    "\n",
    "# Output shape after shuffling.\n",
    "output_patch_shape = (channels, h_out, w_out, d_out)\n",
    "output_spatial_patch_shape = output_patch_shape[1:]\n",
    "\n",
    "# Input patch parameters\n",
    "h_in = round(h_out / (downsample_factor) * low_res_sample_extension)\n",
    "w_in = round(w_out / (downsample_factor) * low_res_sample_extension)\n",
    "d_in = round(d_out / (downsample_factor) * low_res_sample_extension)\n",
    "input_patch_shape = (channels, h_in, w_in, d_in)\n",
    "input_spatial_patch_shape = input_patch_shape[1:]\n",
    "\n",
    "# Pre-shuffle output patch sizes.\n",
    "unshuffled_channels_out = channels * downsample_factor ** 3\n",
    "# Output before shuffling\n",
    "unshuffled_output_patch_shape = (unshuffled_channels_out, h_in, w_in, d_in)\n",
    "\n",
    "# Patch size in FR-space when accounting for the low-res over-extension/over-sampling\n",
    "# factor.\n",
    "fr_extension_patch_size = tuple(\n",
    "    np.asarray(input_spatial_patch_shape) * downsample_factor\n",
    ")\n",
    "fr_extension_amount = tuple(\n",
    "    np.asarray(fr_extension_patch_size) - np.asarray(output_spatial_patch_shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_params.patch.update(\n",
    "    batch_size=batch_size,\n",
    "    channels=channels,\n",
    "    low_res_sample_extension=low_res_sample_extension,\n",
    "    input_shape=input_patch_shape,\n",
    "    output_shape=output_patch_shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data parameters.\n",
    "num_subject_samples = 13\n",
    "# Should the data be normalized as a pre-processing step?\n",
    "# Can be:\n",
    "# { None, \"channels\" }\n",
    "data_norm_method = \"channels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_params.data.update(\n",
    "    num_subject=num_subject_samples, data_norm_method=data_norm_method\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training and Testing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training/testing parameters.\n",
    "# Percentages will be rounded off to the nearest subject, with the test and validation\n",
    "# sizes rounded *up*, ensuring at least 1 subject in each.\n",
    "test_percent = 0.5\n",
    "val_percent = 0.01\n",
    "train_percent = 1 - (test_percent + val_percent)\n",
    "\n",
    "# NN parameters.\n",
    "max_epochs = 25\n",
    "network_norm_method = None\n",
    "train_loss_name = \"sse\"\n",
    "\n",
    "# Optimization parameters.\n",
    "opt_name = \"Adam\"\n",
    "opt_params = {\"lr\": 1e-3, \"betas\": (0.9, 0.999)}\n",
    "\n",
    "# Spline interpolation baseline parameters.\n",
    "spline_interp_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of voxels to dilate the mask in FR space.\n",
    "# Just make it 0...\n",
    "dilation_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_params.update(test_percent=test_percent)\n",
    "exp_params.train.update(\n",
    "    train_percent=train_percent, max_epochs=max_epochs, train_loss_name=train_loss_name\n",
    ")\n",
    "exp_params.nn.update(network_norm_method=network_norm_method)\n",
    "exp_params.opt.update(opt_params)\n",
    "exp_params.opt.name = opt_name\n",
    "exp_params.spline.update(order=spline_interp_order)\n",
    "exp_params.preproc.update(dilation_size=dilation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(pprint.pformat(exp_params) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def patch_center(\n",
    "    patch: torch.Tensor, sub_sample_strategy=\"lower\", keepdim=False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Extract 3D multi-channel patch center.\n",
    "\n",
    "    Expects patch of shape '[B x C x] W x H x D'\n",
    "\n",
    "    sub_sample_strategy: str\n",
    "        Strategy for handling center coordinates of even-sized dimensions.\n",
    "        Options:\n",
    "            Strategies over indices:\n",
    "                'lower': Take the voxel to the left of the center.\n",
    "                'upper': Take the voxel to the right of the center.\n",
    "\n",
    "            Strategies over multi-dimensional voxels:\n",
    "                'max': Take the max of all center voxels.\n",
    "                'min': Take the minimum of all center voxels.\n",
    "                'mean': Take the average of all center voxels.\n",
    "                'agg': Don't reduce at all, and return the center voxels.\n",
    "    \"\"\"\n",
    "    strategy_fn = {\n",
    "        \"idx_fns\": {\n",
    "            \"lower\".casefold(): lambda i: int(i),\n",
    "            \"upper\".casefold(): lambda i: int(i) + 1,\n",
    "        },\n",
    "        \"vox_fns\": {\n",
    "            \"max\".casefold(): lambda p: torch.amax(p, dim=(-3, -2, -1), keepdim=True),\n",
    "            \"min\".casefold(): lambda p: torch.amin(p, dim=(-3, -2, -1), keepdim=True),\n",
    "            \"mean\".casefold(): lambda p: p.mean(dim=(-3, -2, -1), keepdim=True),\n",
    "            \"agg\".casefold(): lambda p: p,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    strat = sub_sample_strategy.casefold()\n",
    "    if (strat not in strategy_fn[\"idx_fns\"].keys()) and (\n",
    "        strat not in strategy_fn[\"vox_fns\"].keys()\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\"ERROR: Invalid strategy; got {sub_sample_strategy}, expected one of\"\n",
    "            + f\"{list(strategy_fn['idx_fns'].keys()) + list(strategy_fn['vox_fns'].keys())}\"\n",
    "        )\n",
    "    patch_spatial_shape = patch.shape[-3:]\n",
    "    centers = torch.as_tensor(patch_spatial_shape) / 2\n",
    "    center = list()\n",
    "    for dim in centers:\n",
    "        if int(dim) != dim:\n",
    "            dim = slice(int(math.floor(dim)), int(math.ceil(dim)))\n",
    "        elif strat in strategy_fn[\"idx_fns\"].keys():\n",
    "            dim = int(strategy_fn[\"idx_fns\"][strat](dim))\n",
    "            dim = slice(dim, dim + 1)\n",
    "        elif strat in strategy_fn[\"vox_fns\"].keys():\n",
    "            dim = slice(int(dim), int(dim) + 2)\n",
    "        else:\n",
    "            raise ValueError(\"ERROR: Invalid strategy\")\n",
    "        center.append(dim)\n",
    "\n",
    "    center_patches = patch[..., center[0], center[1], center[2]]\n",
    "\n",
    "    if (\n",
    "        center_patches.shape[-3:] != (1, 1, 1)\n",
    "        and strat in strategy_fn[\"vox_fns\"].keys()\n",
    "    ):\n",
    "        center_patches = strategy_fn[\"vox_fns\"][strat](center_patches)\n",
    "\n",
    "    if not keepdim:\n",
    "        center_patches = center_patches.squeeze()\n",
    "\n",
    "    return center_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BoxplotStats = collections.namedtuple(\n",
    "    \"BoxplotStats\",\n",
    "    [\"low_outliers\", \"low\", \"q1\", \"median\", \"q3\", \"high\", \"high_outliers\"],\n",
    ")\n",
    "\n",
    "\n",
    "def batch_boxplot_stats(batch):\n",
    "    \"\"\"Quick calculation of a batch of 1D values for showing boxplot stats.\"\"\"\n",
    "    q1, median, q3 = np.quantile(batch, q=[0.25, 0.5, 0.75], axis=1)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - (1.5 * iqr)\n",
    "    high = q3 + (1.5 * iqr)\n",
    "    low_outliers = list()\n",
    "    high_outliers = list()\n",
    "    # Number of outliers may be different for each batch, so it needs to be a list of\n",
    "    # arrays.\n",
    "    for i_batch in range(len(batch)):\n",
    "        batch_i = batch[i_batch]\n",
    "        low_i = low[i_batch]\n",
    "        low_outliers.append(batch_i[np.where(batch_i < low_i)])\n",
    "        high_i = high[i_batch]\n",
    "        high_outliers.append(batch_i[np.where(batch_i > high_i)])\n",
    "\n",
    "    return BoxplotStats(low_outliers, low, q1, median, q3, high, high_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick check on full volume/batch distributions.\n",
    "\n",
    "\n",
    "def desc_channel_dists(vols, mask=None):\n",
    "    t_vols = torch.as_tensor(vols)\n",
    "\n",
    "    if t_vols.ndim == 4:\n",
    "        t_vols = t_vols[None, ...]\n",
    "\n",
    "    if mask is not None:\n",
    "        t_mask = torch.as_tensor(mask)\n",
    "        if mask.ndim == 4:\n",
    "            mask = mask[0]\n",
    "    else:\n",
    "        t_mask = torch.ones_like(t_vols[0, 0]).bool()\n",
    "\n",
    "    results = \"means | vars\\n\"\n",
    "    for t_vol_i in t_vols:\n",
    "        masked_vol = torch.masked_select(t_vol_i, t_mask).reshape(t_vol_i.shape[0], -1)\n",
    "        mean_i = torch.mean(masked_vol, dim=1)\n",
    "        var_i = torch.var(masked_vol, dim=1)\n",
    "        mvs = [\n",
    "            (f\"{mv[0]} | {mv[1]}\\n\")\n",
    "            for mv in torch.stack([mean_i, var_i], dim=-1).tolist()\n",
    "        ]\n",
    "        results = results + \"\".join(mvs)\n",
    "        results = results + (\"=\" * (len(mvs[-1]) - 1)) + \"\\n\"\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dti_box_row(\n",
    "    fig,\n",
    "    grid,\n",
    "    row_idx: int,\n",
    "    subj_id: int,\n",
    "    shared_axs_rows: list,\n",
    "    shared_axs_cols: list,\n",
    "    fr_vol: np.ndarray,\n",
    "    lr_vol: np.ndarray,\n",
    "    colors: list = list(sns.color_palette(\"Set2\", n_colors=2)),\n",
    "):\n",
    "\n",
    "    dti_channel_names = [\n",
    "        \"$D_{xx}$\",\n",
    "        \"$D_{xy}$\",\n",
    "        \"$D_{yy}$\",\n",
    "        \"$D_{xz}$\",\n",
    "        \"$D_{yz}$\",\n",
    "        \"$D_{zz}$\",\n",
    "    ]\n",
    "\n",
    "    for i_channel, channel_name in enumerate(dti_channel_names):\n",
    "        cell = grid[row_idx, i_channel]\n",
    "\n",
    "        ax = fig.add_subplot(\n",
    "            cell,\n",
    "            sharex=shared_axs_cols[channel_name],\n",
    "            sharey=shared_axs_rows[subj_id],\n",
    "        )\n",
    "        if shared_axs_cols[channel_name] is None:\n",
    "            shared_axs_cols[channel_name] = ax\n",
    "        if shared_axs_rows[subj_id] is None:\n",
    "            shared_axs_rows[subj_id] = ax\n",
    "\n",
    "        #         quantile_outlier_cutoff = (0.1, 0.9)\n",
    "        fr_channel = fr_vol[i_channel]\n",
    "        #         fr_nn = fr_nn[\n",
    "        #             (np.quantile(fr_nn, quantile_outlier_cutoff[0]) <= fr_nn)\n",
    "        #             & (fr_nn <= np.quantile(fr_nn, quantile_outlier_cutoff[1]))\n",
    "        #         ]\n",
    "        lr_channel = lr_vol[i_channel]\n",
    "        #         lr_nn = lr_nn[\n",
    "        #             (np.quantile(lr_nn, quantile_outlier_cutoff[0]) <= lr_nn)\n",
    "        #             & (lr_nn <= np.quantile(lr_nn, quantile_outlier_cutoff[1]))\n",
    "        #         ]\n",
    "        #         fr_norm = normed_fr_vol[i_channel].detach().cpu().numpy()\n",
    "        #         lr_norm = normed_lr_vol[i_channel].detach().cpu().numpy()\n",
    "\n",
    "        num_fr_vox = len(fr_channel)\n",
    "        num_lr_vox = len(lr_channel)\n",
    "\n",
    "        resolution_labels = ([\"FR\",] * num_fr_vox) + (\n",
    "            [\n",
    "                \"LR\",\n",
    "            ]\n",
    "            * num_lr_vox\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"data\": np.concatenate([fr_channel, lr_channel]),\n",
    "                \"resolution\": resolution_labels,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        sns.boxenplot(\n",
    "            data=df,\n",
    "            y=\"resolution\",\n",
    "            x=\"data\",\n",
    "            orient=\"h\",\n",
    "            ax=ax,\n",
    "            palette=colors,\n",
    "            k_depth=\"proportion\",\n",
    "            outlier_prop=0.11,\n",
    "            showfliers=False,\n",
    "        )\n",
    "\n",
    "        if not cell.is_last_row():\n",
    "            plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        else:\n",
    "            plt.setp(ax.get_xticklabels(), fontsize=\"x-small\", rotation=25)\n",
    "\n",
    "        if not cell.is_first_col():\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "            ax.set_ylabel(\"\")\n",
    "        else:\n",
    "            ax.set_ylabel(subj_id)\n",
    "\n",
    "        ax.set_xlabel(\"\")\n",
    "        if cell.is_first_row():\n",
    "            ax.set_title(channel_name)\n",
    "\n",
    "    return fig, shared_axs_rows, shared_axs_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: dict = dict()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "selected_ids = random.sample(selected_ids, num_subject_samples)\n",
    "warnings.warn(\n",
    "    \"WARNING: Sub-selecting participants for dev and debugging. \"\n",
    "    + f\"Subj IDs selected: {selected_ids}\"\n",
    ")\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_ids = natsorted(list(map(lambda s: int(s), selected_ids)))\n",
    "\n",
    "for subj_id in selected_ids:\n",
    "    subj_dirs[subj_id] = data_dir / f\"{subj_id}/T1w/Diffusion\"\n",
    "    assert subj_dirs[subj_id].exists()\n",
    "subj_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 90 scans are taken from the $b=1000 \\ s/mm^2$. However, the $b=0$ shells are still required for fitting the diffusion tensors (DTI's), so those will need to be kept, too.\n",
    "\n",
    "To find those, sub-select with the $0 < bvals < 1500$, or roughly thereabout. A b-val of $995$ or $1005$ still counts as a b=1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the transformation pipeline.\n",
    "\n",
    "preproc_transforms = torchio.Compose(\n",
    "    [\n",
    "        torchio.transforms.ToCanonical(include=(\"dwi\", \"brain_mask\"), copy=False),\n",
    "        pitn.transforms.BValSelectionTransform(\n",
    "            bval_range=bval_range,\n",
    "            bval_key=\"bvals\",\n",
    "            bvec_key=\"bvecs\",\n",
    "            include=\"dwi\",\n",
    "            copy=False,\n",
    "        ),\n",
    "        # Pad by the dilation factor, then dilate the mask.\n",
    "        torchio.transforms.Pad(\n",
    "            dilation_size,\n",
    "            padding_mode=0,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.DilateMaskTransform(\n",
    "            dilation_size=dilation_size, include=(\"brain_mask\",), copy=False\n",
    "        ),\n",
    "        # Pad by the amount of extension voxels in FR space, so LR indices cannot\n",
    "        # go out of bounds.\n",
    "        torchio.transforms.Pad(\n",
    "            fr_extension_amount,\n",
    "            padding_mode=0,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        # Ensure FR dims are divisible by the downsample factor, to more reliably\n",
    "        # convert between FR indices and LR indices.\n",
    "        torchio.transforms.EnsureShapeMultiple(\n",
    "            downsample_factor, method=\"pad\", include=(\"dwi\", \"brain_mask\"), copy=False\n",
    "        ),\n",
    "        pitn.transforms.MeanDownsampleTransform(\n",
    "            downsample_factor,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            keep={\"dwi\": \"fr_dwi\", \"brain_mask\": \"fr_brain_mask\"},\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"dwi\": \"lr_dwi\", \"brain_mask\": \"lr_brain_mask\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"fr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"fr_dwi\"),\n",
    "            #             cache_dir=\"./.cache\",\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"lr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"lr_dwi\"),\n",
    "            #             cache_dir=\"./.cache\",\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"fr_dwi\": \"fr_dti\", \"lr_dwi\": \"lr_dti\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.ImageToDictTransform(\n",
    "            include=(\"lr_dti\", \"lr_brain_mask\"), copy=False\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "\n",
    "# n_subj = len(subj_dirs.keys())\n",
    "# fig_non_norm = plt.figure(dpi=120, figsize=(6 * 2.5, 1.5 * n_subj))\n",
    "# fig_non_norm.suptitle(\"Non-Normalized Subject DTI Distributions\")\n",
    "# grid_non_norm = mpl.gridspec.GridSpec(\n",
    "#     nrows=len(subj_dirs.keys()), ncols=len(dti_channel_names), figure=fig_non_norm\n",
    "# )\n",
    "\n",
    "# fig_norm = plt.figure(dpi=120, figsize=(6 * 2.5, 1.5 * n_subj))\n",
    "# fig_norm.suptitle(\"Normalized Subject DTI Distributions\")\n",
    "# grid_norm = mpl.gridspec.GridSpec(\n",
    "#     nrows=len(subj_dirs.keys()), ncols=len(dti_channel_names), figure=fig_norm\n",
    "# )\n",
    "\n",
    "# colors = list(sns.color_palette(\"Set2\", n_colors=2))\n",
    "# share_axs_non_norm = collections.defaultdict(\n",
    "#     lambda: None,\n",
    "#     row=collections.defaultdict(lambda: None),\n",
    "#     col=collections.defaultdict(lambda: None),\n",
    "# )\n",
    "# share_axs_norm = collections.defaultdict(\n",
    "#     lambda: None,\n",
    "#     row=collections.defaultdict(lambda: None),\n",
    "#     col=collections.defaultdict(lambda: None),\n",
    "# )\n",
    "\n",
    "# for subj_id in subj_dirs.keys():\n",
    "\n",
    "#     masked_fr_vol = torch.from_numpy(subj_box_stats[subj_id].non_norm_fr)\n",
    "#     masked_lr_vol = torch.from_numpy(subj_box_stats[subj_id].non_norm_lr)\n",
    "\n",
    "#     normed_fr_vol = torch.from_numpy(subj_box_stats[subj_id].norm_fr)\n",
    "#     normed_lr_vol = torch.from_numpy(subj_box_stats[subj_id].norm_lr)\n",
    "\n",
    "#     # Create boxplots for non-normed data.\n",
    "#     # Set up sub-grid for this subject.\n",
    "#     subj_idx = list(subj_dirs.keys()).index(subj_id)\n",
    "#     for i_channel, channel_name in enumerate(dti_channel_names):\n",
    "#         cell = grid_non_norm[subj_idx, i_channel]\n",
    "\n",
    "#         ax = fig_non_norm.add_subplot(\n",
    "#             cell,\n",
    "#             sharex=share_axs_non_norm[\"col\"][channel_name],\n",
    "#             sharey=share_axs_non_norm[\"row\"][subj_id],\n",
    "#         )\n",
    "#         if share_axs_non_norm[\"col\"][channel_name] is None:\n",
    "#             share_axs_non_norm[\"col\"][channel_name] = ax\n",
    "#         if share_axs_non_norm[\"row\"][subj_id] is None:\n",
    "#             share_axs_non_norm[\"row\"][subj_id] = ax\n",
    "\n",
    "#         quantile_outlier_cutoff = (0.1, 0.9)\n",
    "#         fr_nn = masked_fr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         fr_nn = fr_nn[\n",
    "#         #             (np.quantile(fr_nn, quantile_outlier_cutoff[0]) <= fr_nn)\n",
    "#         #             & (fr_nn <= np.quantile(fr_nn, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         lr_nn = masked_lr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         lr_nn = lr_nn[\n",
    "#         #             (np.quantile(lr_nn, quantile_outlier_cutoff[0]) <= lr_nn)\n",
    "#         #             & (lr_nn <= np.quantile(lr_nn, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         #         fr_norm = normed_fr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         lr_norm = normed_lr_vol[i_channel].detach().cpu().numpy()\n",
    "\n",
    "#         num_fr_vox = len(fr_nn)\n",
    "#         num_lr_vox = len(lr_nn)\n",
    "\n",
    "#         resolution_labels = ([\"FR\",] * num_fr_vox) + (\n",
    "#             [\n",
    "#                 \"LR\",\n",
    "#             ]\n",
    "#             * num_lr_vox\n",
    "#         )\n",
    "\n",
    "#         df = pd.DataFrame(\n",
    "#             {\n",
    "#                 \"data\": np.concatenate([fr_nn, lr_nn]),\n",
    "#                 \"resolution\": resolution_labels,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         sns.boxenplot(\n",
    "#             data=df,\n",
    "#             y=\"resolution\",\n",
    "#             x=\"data\",\n",
    "#             orient=\"h\",\n",
    "#             ax=ax,\n",
    "#             palette=colors,\n",
    "#             k_depth=\"proportion\",\n",
    "#             outlier_prop=0.11,\n",
    "#             showfliers=False,\n",
    "#         )\n",
    "\n",
    "#         if not cell.is_last_row():\n",
    "#             plt.setp(ax.get_xticklabels(), visible=False)\n",
    "#         else:\n",
    "#             plt.setp(ax.get_xticklabels(), fontsize=\"x-small\", rotation=25)\n",
    "\n",
    "#         if not cell.is_first_col():\n",
    "#             plt.setp(ax.get_yticklabels(), visible=False)\n",
    "#             ax.set_ylabel(\"\")\n",
    "#         else:\n",
    "#             ax.set_ylabel(subj_id)\n",
    "\n",
    "#         ax.set_xlabel(\"\")\n",
    "#         if cell.is_first_row():\n",
    "#             ax.set_title(channel_name)\n",
    "\n",
    "#         # ============================================\n",
    "\n",
    "#         # Create boxplots for normed data.\n",
    "#         cell = grid_norm[subj_idx, i_channel]\n",
    "\n",
    "#         ax = fig_norm.add_subplot(\n",
    "#             cell,\n",
    "#             sharex=share_axs_norm[\"col\"][channel_name],\n",
    "#             sharey=share_axs_norm[\"row\"][subj_id],\n",
    "#         )\n",
    "#         if share_axs_norm[\"col\"][channel_name] is None:\n",
    "#             share_axs_norm[\"col\"][channel_name] = ax\n",
    "#         if share_axs_norm[\"row\"][subj_id] is None:\n",
    "#             share_axs_norm[\"row\"][subj_id] = ax\n",
    "\n",
    "#         fr_norm = normed_fr_vol[i_channel].detach().cpu().numpy()\n",
    "#         lr_norm = normed_lr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         fr_norm = fr_norm[\n",
    "#         #             (np.quantile(fr_norm, quantile_outlier_cutoff[0]) <= fr_norm)\n",
    "#         #             & (fr_norm <= np.quantile(fr_norm, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         #         lr_norm = lr_norm[\n",
    "#         #             (np.quantile(lr_norm, quantile_outlier_cutoff[0]) <= lr_norm)\n",
    "#         #             & (lr_norm <= np.quantile(lr_norm, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         num_fr_vox = len(fr_norm)\n",
    "#         num_lr_vox = len(lr_norm)\n",
    "\n",
    "#         resolution_labels = ([\"FR\",] * num_fr_vox) + (\n",
    "#             [\n",
    "#                 \"LR\",\n",
    "#             ]\n",
    "#             * num_lr_vox\n",
    "#         )\n",
    "\n",
    "#         df = pd.DataFrame(\n",
    "#             {\n",
    "#                 \"data\": np.concatenate([fr_norm, lr_norm]),\n",
    "#                 \"resolution\": resolution_labels,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         sns.boxenplot(\n",
    "#             data=df,\n",
    "#             y=\"resolution\",\n",
    "#             x=\"data\",\n",
    "#             orient=\"h\",\n",
    "#             k_depth=\"proportion\",\n",
    "#             outlier_prop=0.11,\n",
    "#             ax=ax,\n",
    "#             palette=colors,\n",
    "#             showfliers=False,\n",
    "#         )\n",
    "\n",
    "#         if not cell.is_last_row():\n",
    "#             plt.setp(ax.get_xticklabels(), visible=False)\n",
    "#         else:\n",
    "#             plt.setp(ax.get_xticklabels(), fontsize=\"x-small\", rotation=25)\n",
    "\n",
    "#         if not cell.is_first_col():\n",
    "#             plt.setp(ax.get_yticklabels(), visible=False)\n",
    "#             ax.set_ylabel(\"\")\n",
    "#         else:\n",
    "#             ax.set_ylabel(subj_id)\n",
    "\n",
    "#         ax.set_xlabel(\"\")\n",
    "#         if cell.is_first_row():\n",
    "#             ax.set_title(channel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import all image data into a sequence of `torchio.Subject` objects.\n",
    "subj_data: dict = dict()\n",
    "summary_stats_fmt = \"github\"\n",
    "summary_stats_header = [\n",
    "    \"Subj ID\",\n",
    "    \"Resolution\",\n",
    "    \"Channel Index\",\n",
    "    \"Mean\",\n",
    "    \"Var\",\n",
    "    \"Num Outliers (Lower)\",\n",
    "    \"Low\",\n",
    "    \"25th Percentile\",\n",
    "    \"Median\",\n",
    "    \"75th Percentile\",\n",
    "    \"High\",\n",
    "    \"Num Outliers (Upper)\",\n",
    "]\n",
    "dti_channel_names = [\"D xx\", \"D xy\", \"D yy\", \"D xz\", \"D yz\", \"D zz\"]\n",
    "subj_stats = dict()\n",
    "# Dictionary to hold the subject's summary statistics if image-level or global\n",
    "# normalization is used.\n",
    "norm_subj_stats = dict()\n",
    "# Grid plot for displaying enhanced boxplots of subject DTI image intensities.\n",
    "plt.clf()\n",
    "n_subj = len(subj_dirs.keys())\n",
    "\n",
    "fig_non_norm = plt.figure(dpi=120, figsize=(6 * 2.5, 1.5 * n_subj))\n",
    "fig_non_norm.suptitle(\"Non-Normalized Subject DTI Distributions\")\n",
    "grid_non_norm = mpl.gridspec.GridSpec(\n",
    "    nrows=len(subj_dirs.keys()), ncols=len(dti_channel_names), figure=fig_non_norm\n",
    ")\n",
    "\n",
    "fig_norm = plt.figure(dpi=120, figsize=(6 * 2.5, 1.5 * n_subj))\n",
    "fig_norm.suptitle(\"Normalized Subject DTI Distributions\")\n",
    "grid_norm = mpl.gridspec.GridSpec(\n",
    "    nrows=len(subj_dirs.keys()), ncols=len(dti_channel_names), figure=fig_norm\n",
    ")\n",
    "\n",
    "colors = list(sns.color_palette(\"Set2\", n_colors=2))\n",
    "share_axs_non_norm = collections.defaultdict(\n",
    "    lambda: None,\n",
    "    row=collections.defaultdict(lambda: None),\n",
    "    col=collections.defaultdict(lambda: None),\n",
    ")\n",
    "share_axs_norm = collections.defaultdict(\n",
    "    lambda: None,\n",
    "    row=collections.defaultdict(lambda: None),\n",
    "    col=collections.defaultdict(lambda: None),\n",
    ")\n",
    "\n",
    "for k in summary_stats_header:\n",
    "    subj_stats[k] = list()\n",
    "    norm_subj_stats[k] = list()\n",
    "\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "    # Sub-select volumes with only bvals in a certain range. E.x. bvals <= 1100 mm/s^2,\n",
    "    # a.k.a. only the b=0 and b=1000 shells.\n",
    "    bvals = torch.as_tensor(np.loadtxt(subj_dir / \"bvals\").astype(int))\n",
    "    bvecs = torch.as_tensor(np.loadtxt(subj_dir / \"bvecs\"))\n",
    "    # Reshape to be N x 3\n",
    "    if bvecs.shape[0] == 3:\n",
    "        bvecs = bvecs.T\n",
    "\n",
    "    brain_mask = torchio.LabelMap(\n",
    "        subj_dir / \"nodif_brain_mask.nii.gz\",\n",
    "        type=torchio.LABEL,\n",
    "        channels_last=False,\n",
    "    )\n",
    "    brain_mask.set_data(brain_mask.data.bool())\n",
    "    mask_volume = brain_mask[\"data\"].sum()\n",
    "\n",
    "    dwi = torchio.ScalarImage(\n",
    "        subj_dir / \"data.nii.gz\",\n",
    "        type=torchio.INTENSITY,\n",
    "        bvals=bvals,\n",
    "        bvecs=bvecs,\n",
    "        reader=pitn.io.nifti_reader,\n",
    "        channels_last=True,\n",
    "    )\n",
    "\n",
    "    subject_dict = torchio.Subject(subj_id=subj_id, dwi=dwi, brain_mask=brain_mask)\n",
    "    preproced_subj = preproc_transforms(subject_dict)\n",
    "\n",
    "    # Subject-and-channel-wise standardization/normalization of both the LR and FR vols.\n",
    "    # Note that LR and FR images should have the same means, but *not* the same variances.\n",
    "    fr_vol = preproced_subj.fr_dti.tensor\n",
    "    fr_mask = preproced_subj.fr_brain_mask.tensor.bool()\n",
    "    masked_fr_vol = torch.masked_select(fr_vol, fr_mask).reshape(fr_vol.shape[0], -1)\n",
    "    fr_channel_means = masked_fr_vol.mean(dim=1)\n",
    "    fr_channel_means = fr_channel_means.reshape(-1, 1, 1, 1)\n",
    "    fr_channel_vars = masked_fr_vol.var(dim=1)\n",
    "    fr_channel_vars = fr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "    # Store subject-and-channel-wise means and vars in order to reverse the normalization\n",
    "    # for the final visualization/output.\n",
    "    preproced_subj[\"fr_means\"] = fr_channel_means.detach().cpu().numpy()\n",
    "    preproced_subj[\"fr_vars\"] = fr_channel_vars.detach().cpu().numpy()\n",
    "\n",
    "    lr_vol = preproced_subj.lr_dti[\"data\"]\n",
    "    lr_mask = preproced_subj.lr_brain_mask[\"data\"].bool()\n",
    "    masked_lr_vol = torch.masked_select(lr_vol, lr_mask).reshape(lr_vol.shape[0], -1)\n",
    "    lr_channel_means = masked_lr_vol.mean(dim=1)\n",
    "    lr_channel_means = lr_channel_means.reshape(-1, 1, 1, 1)\n",
    "    lr_channel_vars = masked_lr_vol.var(dim=1)\n",
    "    lr_channel_vars = lr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "    # Store subject-and-channel-wise means and vars in order to reverse the normalization\n",
    "    # for the final visualization/output.\n",
    "    preproced_subj[\"lr_means\"] = lr_channel_means.detach().cpu().numpy()\n",
    "    preproced_subj[\"lr_vars\"] = lr_channel_vars.detach().cpu().numpy()\n",
    "\n",
    "    # Print and log some statistics of the subject data.\n",
    "    # Add FR stats to the summary table.\n",
    "    fr_vol_stats = batch_boxplot_stats(masked_fr_vol)\n",
    "    subj_stats[\"Subj ID\"].extend(\n",
    "        list(itertools.repeat(subj_id, len(fr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Resolution\"].extend(\n",
    "        list(itertools.repeat(tuple(fr_vol.shape[1:]), len(fr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "    subj_stats[\"Mean\"].extend(fr_channel_means.cpu().flatten().tolist())\n",
    "    subj_stats[\"Var\"].extend(fr_channel_vars.cpu().flatten().tolist())\n",
    "    # Append FR boxplot stats to their corresponding fields. In other words, all columns\n",
    "    # after the var column.\n",
    "    for i, field in enumerate(\n",
    "        summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "    ):\n",
    "        if \"Num\" in field:\n",
    "            subj_stats[field].extend(list(map(len, fr_vol_stats[i])))\n",
    "        else:\n",
    "            subj_stats[field].extend(fr_vol_stats[i])\n",
    "\n",
    "    # Add LR stats to the summary table.\n",
    "    lr_vol_stats = batch_boxplot_stats(masked_lr_vol)\n",
    "    subj_stats[\"Subj ID\"].extend(\n",
    "        list(itertools.repeat(subj_id, len(fr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Resolution\"].extend(\n",
    "        list(itertools.repeat(tuple(lr_vol.shape[1:]), len(lr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "    subj_stats[\"Mean\"].extend(lr_channel_means.cpu().flatten().tolist())\n",
    "    subj_stats[\"Var\"].extend(lr_channel_vars.cpu().flatten().tolist())\n",
    "    # Append LR boxplot stats to their corresponding fields. In other words, all columns\n",
    "    # after the var column.\n",
    "    for i, field in enumerate(\n",
    "        summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "    ):\n",
    "        if \"Num\" in field:\n",
    "            subj_stats[field].extend(list(map(len, lr_vol_stats[i])))\n",
    "        else:\n",
    "            subj_stats[field].extend(lr_vol_stats[i])\n",
    "\n",
    "    # Optionally apply image-level or global normalization.\n",
    "    if isinstance(data_norm_method, str) and \"channel\" in data_norm_method.casefold():\n",
    "\n",
    "        # Standardize the volumes.\n",
    "        preproced_subj.fr_dti.set_data(\n",
    "            pitn.data.norm.normalize_dti(fr_vol, fr_channel_means, fr_channel_vars)\n",
    "        )\n",
    "        preproced_subj.lr_dti[\"data\"] = pitn.data.norm.normalize_dti(\n",
    "            lr_vol, lr_channel_means, lr_channel_vars\n",
    "        )\n",
    "\n",
    "        # Keep reference to non-normalized volumes.\n",
    "        non_normal_fr_vol = masked_fr_vol\n",
    "        non_normal_lr_vol = masked_lr_vol\n",
    "\n",
    "        # Re-calculate the same statistics post-normalization.\n",
    "        fr_vol = preproced_subj.fr_dti[\"data\"]\n",
    "        fr_mask = preproced_subj.fr_brain_mask[\"data\"].bool()\n",
    "        masked_fr_vol = torch.masked_select(fr_vol, fr_mask).reshape(\n",
    "            fr_vol.shape[0], -1\n",
    "        )\n",
    "        fr_channel_means = masked_fr_vol.mean(dim=1)\n",
    "        fr_channel_means = fr_channel_means.reshape(-1, 1, 1, 1)\n",
    "        fr_channel_vars = masked_fr_vol.var(dim=1)\n",
    "        fr_channel_vars = fr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "        # Print and log some statistics of the subject data.\n",
    "        # Add FR stats to the summary table.\n",
    "        fr_vol_stats = batch_boxplot_stats(masked_fr_vol)\n",
    "        norm_subj_stats[\"Subj ID\"].extend(\n",
    "            list(itertools.repeat(subj_id, len(fr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Resolution\"].extend(\n",
    "            list(itertools.repeat(tuple(fr_vol.shape[1:]), len(fr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "        norm_subj_stats[\"Mean\"].extend(fr_channel_means.cpu().flatten().tolist())\n",
    "        norm_subj_stats[\"Var\"].extend(fr_channel_vars.cpu().flatten().tolist())\n",
    "        # Append FR boxplot stats to their corresponding fields. In other words, all\n",
    "        # columns after the var column.\n",
    "        for i, field in enumerate(\n",
    "            summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "        ):\n",
    "            if \"Num\" in field:\n",
    "                norm_subj_stats[field].extend(list(map(len, fr_vol_stats[i])))\n",
    "            else:\n",
    "                norm_subj_stats[field].extend(fr_vol_stats[i])\n",
    "\n",
    "        # Add LR stats to the summary table.\n",
    "        lr_vol = preproced_subj.lr_dti[\"data\"]\n",
    "        lr_mask = preproced_subj.lr_brain_mask[\"data\"].bool()\n",
    "        masked_lr_vol = torch.masked_select(lr_vol, lr_mask).reshape(\n",
    "            lr_vol.shape[0], -1\n",
    "        )\n",
    "        lr_channel_means = masked_lr_vol.mean(dim=1)\n",
    "        lr_channel_means = lr_channel_means.reshape(-1, 1, 1, 1)\n",
    "        lr_channel_vars = masked_lr_vol.var(dim=1)\n",
    "        lr_channel_vars = lr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "        # Keep references to the norm volumes.\n",
    "        normal_fr_vol = masked_fr_vol\n",
    "        normal_lr_vol = masked_lr_vol\n",
    "\n",
    "        lr_vol_stats = batch_boxplot_stats(masked_lr_vol)\n",
    "        norm_subj_stats[\"Subj ID\"].extend(\n",
    "            list(itertools.repeat(subj_id, len(lr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Resolution\"].extend(\n",
    "            list(itertools.repeat(tuple(lr_vol.shape[1:]), len(lr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "        norm_subj_stats[\"Mean\"].extend(lr_channel_means.cpu().flatten().tolist())\n",
    "        norm_subj_stats[\"Var\"].extend(lr_channel_vars.cpu().flatten().tolist())\n",
    "        # Append LR boxplot stats to their corresponding fields. In other words, all columns\n",
    "        # after the var column.\n",
    "        for i, field in enumerate(\n",
    "            summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "        ):\n",
    "            if \"Num\" in field:\n",
    "                norm_subj_stats[field].extend(list(map(len, lr_vol_stats[i])))\n",
    "            else:\n",
    "                norm_subj_stats[field].extend(lr_vol_stats[i])\n",
    "\n",
    "        subj_idx = list(subj_dirs.keys()).index(subj_id)\n",
    "\n",
    "        # Generate row of boxplots for the non-normalized volumes.\n",
    "        fig_non_norm, share_axs_rows, share_axs_cols = plot_dti_box_row(\n",
    "            fig_non_norm,\n",
    "            grid_non_norm,\n",
    "            row_idx=subj_idx,\n",
    "            subj_id=subj_id,\n",
    "            shared_axs_rows=share_axs_non_norm[\"row\"],\n",
    "            shared_axs_cols=share_axs_non_norm[\"col\"],\n",
    "            fr_vol=non_normal_fr_vol.detach().cpu().numpy(),\n",
    "            lr_vol=non_normal_lr_vol.detach().cpu().numpy(),\n",
    "        )\n",
    "        share_axs_non_norm[\"row\"] = share_axs_rows\n",
    "        share_axs_non_norm[\"col\"] = share_axs_cols\n",
    "\n",
    "        # Generate row of boxplots for the normalized volumes.\n",
    "        fig_norm, share_axs_rows, share_axs_cols = plot_dti_box_row(\n",
    "            fig_norm,\n",
    "            grid_norm,\n",
    "            row_idx=subj_idx,\n",
    "            subj_id=subj_id,\n",
    "            shared_axs_rows=share_axs_norm[\"row\"],\n",
    "            shared_axs_cols=share_axs_norm[\"col\"],\n",
    "            fr_vol=normal_fr_vol.detach().cpu().numpy(),\n",
    "            lr_vol=normal_lr_vol.detach().cpu().numpy(),\n",
    "        )\n",
    "        share_axs_norm[\"row\"] = share_axs_rows\n",
    "        share_axs_norm[\"col\"] = share_axs_cols\n",
    "\n",
    "    subj_data[subj_id] = preproced_subj\n",
    "    print(\"=\" * 20)\n",
    "#     breakpoint()\n",
    "\n",
    "print(\"===Data Loaded & Transformed===\")\n",
    "\n",
    "subj_stats_str = tabulate(\n",
    "    subj_stats, headers=summary_stats_header, tablefmt=summary_stats_fmt\n",
    ")\n",
    "\n",
    "if norm_subj_stats[\"Subj ID\"]:\n",
    "    norm_subj_stats_str = tabulate(\n",
    "        norm_subj_stats, headers=summary_stats_header, tablefmt=summary_stats_fmt\n",
    "    )\n",
    "else:\n",
    "    norm_subj_stats_str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = torch.quantile(masked_fr_vol, torch.as_tensor([0.25, 0.75]), dim=1)\n",
    "print((masked_fr_vol <= (1.5 * r[0].view(-1, 1))).sum(dim=1) / masked_fr_vol.shape[1])\n",
    "print((masked_fr_vol >= (1.5 * r[1].view(-1, 1))).sum(dim=1) / masked_fr_vol.shape[1])\n",
    "\n",
    "r = torch.quantile(masked_lr_vol, torch.as_tensor([0.25, 0.75]), dim=1)\n",
    "print((masked_lr_vol <= (1.5 * r[0].view(-1, 1))).sum(dim=1) / masked_lr_vol.shape[1])\n",
    "print((masked_lr_vol >= (1.5 * r[1].view(-1, 1))).sum(dim=1) / masked_lr_vol.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "\n",
    "# n_subj = len(subj_dirs.keys())\n",
    "# fig_non_norm = plt.figure(dpi=120, figsize=(6 * 2.5, 1.5 * n_subj))\n",
    "# fig_non_norm.suptitle(\"Non-Normalized Subject DTI Distributions\")\n",
    "# grid_non_norm = mpl.gridspec.GridSpec(\n",
    "#     nrows=len(subj_dirs.keys()), ncols=len(dti_channel_names), figure=fig_non_norm\n",
    "# )\n",
    "\n",
    "# fig_norm = plt.figure(dpi=120, figsize=(6 * 2.5, 1.5 * n_subj))\n",
    "# fig_norm.suptitle(\"Normalized Subject DTI Distributions\")\n",
    "# grid_norm = mpl.gridspec.GridSpec(\n",
    "#     nrows=len(subj_dirs.keys()), ncols=len(dti_channel_names), figure=fig_norm\n",
    "# )\n",
    "\n",
    "# share_axs_non_norm = collections.defaultdict(\n",
    "#     lambda: None,\n",
    "#     row=collections.defaultdict(lambda: None),\n",
    "#     col=collections.defaultdict(lambda: None),\n",
    "# )\n",
    "# share_axs_norm = collections.defaultdict(\n",
    "#     lambda: None,\n",
    "#     row=collections.defaultdict(lambda: None),\n",
    "#     col=collections.defaultdict(lambda: None),\n",
    "# )\n",
    "\n",
    "# for subj_id in subj_dirs.keys():\n",
    "\n",
    "#     # Create boxplots for non-normed data.\n",
    "#     # Set up sub-grid for this subject.\n",
    "#     subj_idx = list(subj_dirs.keys()).index(subj_id)\n",
    "#     for i_channel, channel_name in enumerate(dti_channel_names):\n",
    "#         cell = grid_non_norm[subj_idx, i_channel]\n",
    "\n",
    "#         ax = fig_non_norm.add_subplot(\n",
    "#             cell,\n",
    "#             sharex=share_axs_non_norm[\"col\"][channel_name],\n",
    "#             sharey=share_axs_non_norm[\"row\"][subj_id],\n",
    "#         )\n",
    "#         if share_axs_non_norm[\"col\"][channel_name] is None:\n",
    "#             share_axs_non_norm[\"col\"][channel_name] = ax\n",
    "#         if share_axs_non_norm[\"row\"][subj_id] is None:\n",
    "#             share_axs_non_norm[\"row\"][subj_id] = ax\n",
    "\n",
    "#         quantile_outlier_cutoff = (0.1, 0.9)\n",
    "#         fr_nn = masked_fr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         fr_nn = fr_nn[\n",
    "#         #             (np.quantile(fr_nn, quantile_outlier_cutoff[0]) <= fr_nn)\n",
    "#         #             & (fr_nn <= np.quantile(fr_nn, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         lr_nn = masked_lr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         lr_nn = lr_nn[\n",
    "#         #             (np.quantile(lr_nn, quantile_outlier_cutoff[0]) <= lr_nn)\n",
    "#         #             & (lr_nn <= np.quantile(lr_nn, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         #         fr_norm = normed_fr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         lr_norm = normed_lr_vol[i_channel].detach().cpu().numpy()\n",
    "\n",
    "#         num_fr_vox = len(fr_nn)\n",
    "#         num_lr_vox = len(lr_nn)\n",
    "\n",
    "#         resolution_labels = ([\"FR\",] * num_fr_vox) + (\n",
    "#             [\n",
    "#                 \"LR\",\n",
    "#             ]\n",
    "#             * num_lr_vox\n",
    "#         )\n",
    "\n",
    "#         df = pd.DataFrame(\n",
    "#             {\n",
    "#                 \"data\": np.concatenate([fr_nn, lr_nn]),\n",
    "#                 \"resolution\": resolution_labels,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         sns.boxenplot(\n",
    "#             data=df,\n",
    "#             y=\"resolution\",\n",
    "#             x=\"data\",\n",
    "#             orient=\"h\",\n",
    "#             ax=ax,\n",
    "#             palette=colors,\n",
    "#             k_depth=\"proportion\",\n",
    "#             outlier_prop=0.11,\n",
    "#             showfliers=False,\n",
    "#         )\n",
    "\n",
    "#         if not cell.is_last_row():\n",
    "#             plt.setp(ax.get_xticklabels(), visible=False)\n",
    "#         else:\n",
    "#             plt.setp(ax.get_xticklabels(), fontsize=\"x-small\", rotation=25)\n",
    "\n",
    "#         if not cell.is_first_col():\n",
    "#             plt.setp(ax.get_yticklabels(), visible=False)\n",
    "#             ax.set_ylabel(\"\")\n",
    "#         else:\n",
    "#             ax.set_ylabel(subj_id)\n",
    "\n",
    "#         ax.set_xlabel(\"\")\n",
    "#         if cell.is_first_row():\n",
    "#             ax.set_title(channel_name)\n",
    "\n",
    "#         # ============================================\n",
    "\n",
    "#         # Create boxplots for normed data.\n",
    "#         cell = grid_norm[subj_idx, i_channel]\n",
    "\n",
    "#         ax = fig_norm.add_subplot(\n",
    "#             cell,\n",
    "#             sharex=share_axs_norm[\"col\"][channel_name],\n",
    "#             sharey=share_axs_norm[\"row\"][subj_id],\n",
    "#         )\n",
    "#         if share_axs_norm[\"col\"][channel_name] is None:\n",
    "#             share_axs_norm[\"col\"][channel_name] = ax\n",
    "#         if share_axs_norm[\"row\"][subj_id] is None:\n",
    "#             share_axs_norm[\"row\"][subj_id] = ax\n",
    "\n",
    "#         fr_norm = normed_fr_vol[i_channel].detach().cpu().numpy()\n",
    "#         lr_norm = normed_lr_vol[i_channel].detach().cpu().numpy()\n",
    "#         #         fr_norm = fr_norm[\n",
    "#         #             (np.quantile(fr_norm, quantile_outlier_cutoff[0]) <= fr_norm)\n",
    "#         #             & (fr_norm <= np.quantile(fr_norm, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         #         lr_norm = lr_norm[\n",
    "#         #             (np.quantile(lr_norm, quantile_outlier_cutoff[0]) <= lr_norm)\n",
    "#         #             & (lr_norm <= np.quantile(lr_norm, quantile_outlier_cutoff[1]))\n",
    "#         #         ]\n",
    "#         num_fr_vox = len(fr_norm)\n",
    "#         num_lr_vox = len(lr_norm)\n",
    "\n",
    "#         resolution_labels = ([\"FR\",] * num_fr_vox) + (\n",
    "#             [\n",
    "#                 \"LR\",\n",
    "#             ]\n",
    "#             * num_lr_vox\n",
    "#         )\n",
    "\n",
    "#         df = pd.DataFrame(\n",
    "#             {\n",
    "#                 \"data\": np.concatenate([fr_norm, lr_norm]),\n",
    "#                 \"resolution\": resolution_labels,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         sns.boxenplot(\n",
    "#             data=df,\n",
    "#             y=\"resolution\",\n",
    "#             x=\"data\",\n",
    "#             orient=\"h\",\n",
    "#             k_depth=\"proportion\",\n",
    "#             outlier_prop=0.11,\n",
    "#             ax=ax,\n",
    "#             palette=colors,\n",
    "#             showfliers=False,\n",
    "#         )\n",
    "\n",
    "#         if not cell.is_last_row():\n",
    "#             plt.setp(ax.get_xticklabels(), visible=False)\n",
    "#         else:\n",
    "#             plt.setp(ax.get_xticklabels(), fontsize=\"x-small\", rotation=25)\n",
    "\n",
    "#         if not cell.is_first_col():\n",
    "#             plt.setp(ax.get_yticklabels(), visible=False)\n",
    "#             ax.set_ylabel(\"\")\n",
    "#         else:\n",
    "#             ax.set_ylabel(subj_id)\n",
    "\n",
    "#         ax.set_xlabel(\"\")\n",
    "#         if cell.is_first_row():\n",
    "#             ax.set_title(channel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Preprocessing transformation pipeline: {str(preproc_transforms)}\\n\")\n",
    "    f.write(f\"Data Summary Statistics, no normalization:\\n {subj_stats_str}\\n\\n\")\n",
    "\n",
    "# If the subject data was normalized and those stats were recorded, log those stats.\n",
    "if norm_subj_stats_str:\n",
    "    with open(log_txt_file, \"a+\") as f:\n",
    "        f.write(\n",
    "            f\"Data Summary Statistics, after normalization:\\n {norm_subj_stats_str}\\n\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_non_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Markdown(subj_stats_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Markdown(norm_subj_stats_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj_dataset = torchio.SubjectsDataset(list(subj_data.values()), load_getitem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_dataset)\n",
    "num_test_subjs = int(np.ceil(num_subjs * test_percent))\n",
    "num_val_subjs = int(np.ceil(num_subjs * val_percent))\n",
    "num_train_subjs = num_subjs - (num_test_subjs + num_val_subjs)\n",
    "subj_list = subj_dataset.dry_iter()\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1:\n",
    "    warnings.warn(\n",
    "        \"DEBUG: Only 1 subject selected, mixing training, validation, and testing sets\"\n",
    "    )\n",
    "    num_train_subjs = num_val_subjs = num_test_subjs = 1\n",
    "\n",
    "    test_subjs = subj_list\n",
    "    val_subjs = subj_list\n",
    "    train_subjs = subj_list\n",
    "else:\n",
    "    test_subjs = subj_list[:num_test_subjs]\n",
    "    val_subjs = subj_list[num_test_subjs : (num_test_subjs + num_val_subjs)]\n",
    "    train_subjs = subj_list[(num_test_subjs + num_val_subjs) :]\n",
    "\n",
    "test_dataset = torchio.SubjectsDataset(test_subjs, load_getitem=False)\n",
    "val_dataset = torchio.SubjectsDataset(val_subjs, load_getitem=False)\n",
    "train_dataset = torchio.SubjectsDataset(train_subjs, load_getitem=False)\n",
    "\n",
    "# Training patch sampler, random across all patches of all volumes.\n",
    "train_sampler = pitn.samplers.MultiresSampler(\n",
    "    source_img_key=\"fr_dti\",\n",
    "    low_res_key=\"lr_dti\",\n",
    "    downsample_factor=exp_params.downsample_factor,\n",
    "    low_res_sample_extension=exp_params.patch.low_res_sample_extension,\n",
    "    label_name=\"fr_brain_mask\",\n",
    "    source_spatial_patch_size=output_spatial_patch_shape,\n",
    "    low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "    label_probabilities={0: 0, 1: 1},\n",
    "    source_mask_key=\"fr_brain_mask\",\n",
    ")\n",
    "\n",
    "patches_per_subj = 8000\n",
    "# Set length of the queue.\n",
    "queue_max_length = patches_per_subj * num_train_subjs\n",
    "\n",
    "# Set up a torchio.Queue to act as a sampler proxy for the torch DataLoader\n",
    "train_queue = torchio.Queue(\n",
    "    train_dataset,\n",
    "    max_length=queue_max_length,\n",
    "    samples_per_volume=patches_per_subj,\n",
    "    sampler=train_sampler,\n",
    "    shuffle_patches=True,\n",
    "    shuffle_subjects=True,\n",
    "    num_workers=7,\n",
    "    #     verbose=True,\n",
    ")\n",
    "\n",
    "# Create partial function to collect list of samples and form a tuple of tensors.\n",
    "collate_fn = functools.partial(\n",
    "    pitn.samplers.collate_subj_mask,\n",
    "    full_res_key=\"fr_dti\",\n",
    "    low_res_key=\"lr_dti\",\n",
    "    full_res_mask_key=\"fr_brain_mask\",\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_queue,\n",
    "    batch_size=exp_params.patch.batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Statically set training patches\n",
    "# static_train_patches = [train_queue[i] for i in range(train_queue.iterations_per_epoch)]\n",
    "# static_dataset = torchio.SubjectsDataset(static_train_patches)\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     static_dataset,\n",
    "#     batch_size=exp_params.patch.batch_size,\n",
    "#     shuffle=True,\n",
    "#     collate_fn=collate_fn,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up validation and testing objects.\n",
    "\n",
    "# Validation samplers/datasets\n",
    "# Alter the collate function to include locations, masks, and subj ids in batches for\n",
    "# visualization, reconstruction, analysis, etc.\n",
    "# This collate function determines the contents of the `batch` parameters in the\n",
    "# PytorchLightning system's `test_step` and `validation_step` methods.\n",
    "collate_meta = functools.partial(\n",
    "    pitn.viz.collate_locs_and_keys,\n",
    "    full_res_key=\"fr_dti\",\n",
    "    low_res_key=\"lr_dti\",\n",
    "    full_res_mask_key=\"source_mask\",\n",
    "    subj_ids=\"subj_id\",\n",
    "    fr_means=\"fr_means\",\n",
    "    fr_vars=\"fr_vars\",\n",
    ")\n",
    "\n",
    "# No backward pass is performed here, so we can increase the batch size to lower\n",
    "# inference time.\n",
    "tv_batch_size = 128\n",
    "val_samplers = list()\n",
    "for subj in val_dataset.dry_iter():\n",
    "    val_sampler_i = pitn.samplers.MultiresGridSampler(\n",
    "        subject=subj,\n",
    "        source_img_key=\"fr_dti\",\n",
    "        low_res_key=\"lr_dti\",\n",
    "        downsample_factor=exp_params.downsample_factor,\n",
    "        low_res_sample_extension=exp_params.patch.low_res_sample_extension,\n",
    "        source_spatial_patch_size=output_spatial_patch_shape,\n",
    "        low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "        patch_overlap=0,\n",
    "        # Due to the oversampling in the LR->HR patch mapping, a mask is necessary\n",
    "        # to avoid sampling from out of bounds.\n",
    "        source_mask=subj[\"fr_brain_mask\"].tensor[0].bool(),\n",
    "        mask_patch_filter_fn=lambda p: bool(p.any()),\n",
    "        subj_keys_to_copy=(\"fr_means\", \"fr_vars\", \"subj_id\"),\n",
    "    )\n",
    "\n",
    "    val_samplers.append(val_sampler_i)\n",
    "\n",
    "concat_val_dataset = torch.utils.data.ConcatDataset(val_samplers)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    concat_val_dataset,\n",
    "    batch_size=tv_batch_size,\n",
    "    collate_fn=collate_meta,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# Test samplers/datasets\n",
    "test_samplers = list()\n",
    "for subj in test_dataset.dry_iter():\n",
    "    test_sampler_i = pitn.samplers.MultiresGridSampler(\n",
    "        subject=subj,\n",
    "        source_img_key=\"fr_dti\",\n",
    "        low_res_key=\"lr_dti\",\n",
    "        downsample_factor=exp_params.downsample_factor,\n",
    "        low_res_sample_extension=exp_params.patch.low_res_sample_extension,\n",
    "        source_spatial_patch_size=output_spatial_patch_shape,\n",
    "        low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "        patch_overlap=0,\n",
    "        # Due to the oversampling in the LR->HR patch mapping, a mask is necessary\n",
    "        # to avoid sampling from out of bounds.\n",
    "        source_mask=subj[\"fr_brain_mask\"].tensor[0].bool(),\n",
    "        mask_patch_filter_fn=lambda p: bool(p.any()),\n",
    "        subj_keys_to_copy=(\"fr_means\", \"fr_vars\", \"subj_id\"),\n",
    "    )\n",
    "\n",
    "    test_samplers.append(test_sampler_i)\n",
    "\n",
    "concat_test_dataset = torch.utils.data.ConcatDataset(test_samplers)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    concat_test_dataset,\n",
    "    batch_size=tv_batch_size,\n",
    "    collate_fn=collate_meta,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Training subject ID(s): \", [s.subj_id for s in train_dataset.dry_iter()])\n",
    "print(\"Validation subject ID(s): \", [s.subj_id for s in val_dataset.dry_iter()])\n",
    "print(\"Test subject ID(s): \", [s.subj_id for s in test_dataset.dry_iter()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Box Selection for Visualization During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bbox coordinates for visualizing validation aggregate patches.\n",
    "# NOTE: This presumes that there are no overlap patches in the validation step, and that\n",
    "# each validation volume is divisible by the patch shape in each spatial dimension.\n",
    "bbox_coords = list()\n",
    "region_size = torch.as_tensor(output_spatial_patch_shape) * 3\n",
    "vol_shape = torch.as_tensor(val_dataset.dry_iter()[0][\"fr_dti\"].shape[1:])\n",
    "possible_bbox_ini = [\n",
    "    torch.arange(0, vol_shape[0], output_spatial_patch_shape[0]),\n",
    "    torch.arange(0, vol_shape[1], output_spatial_patch_shape[1]),\n",
    "    torch.arange(0, vol_shape[2], output_spatial_patch_shape[2]),\n",
    "]\n",
    "\n",
    "# Create bbox that spans roughly the center of the volume.\n",
    "bbox_idx_ini = list()\n",
    "for possible_bbox_part in possible_bbox_ini:\n",
    "    num_parts = len(possible_bbox_part)\n",
    "    bbox_idx_ini.append(possible_bbox_part[round(num_parts * 0.4)])\n",
    "bbox_idx_ini = torch.as_tensor(bbox_idx_ini)\n",
    "\n",
    "bbox_coord = torch.cat([bbox_idx_ini, bbox_idx_ini + region_size])\n",
    "bbox_coords.append(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bbox that covers an edge.\n",
    "vol_mask = val_dataset.dry_iter()[0][\"fr_brain_mask\"].tensor[0]\n",
    "bbox_mask_coverage = list()\n",
    "possible_bbox_coords_ini = list(itertools.product(*possible_bbox_ini))\n",
    "for bbox_w, bbox_h, bbox_d in possible_bbox_coords_ini:\n",
    "    bbox_start = (bbox_w, bbox_h, bbox_d)\n",
    "    bbox_end = (\n",
    "        bbox_start[0] + output_spatial_patch_shape[0],\n",
    "        bbox_start[1] + output_spatial_patch_shape[1],\n",
    "        bbox_start[2] + output_spatial_patch_shape[2],\n",
    "    )\n",
    "    patch = vol_mask[\n",
    "        bbox_start[0] : bbox_end[0],\n",
    "        bbox_start[1] : bbox_end[1],\n",
    "        bbox_start[2] : bbox_end[2],\n",
    "    ]\n",
    "    bbox_mask_coverage.append(patch.sum().item())\n",
    "\n",
    "# Now search all coordinates' mask coverages for the one closest to a 50% of the total\n",
    "# patch volume.\n",
    "patch_vol = np.prod(output_spatial_patch_shape)\n",
    "target_mask_vol = patch_vol // (2 ** 3)\n",
    "\n",
    "bbox_coord_idx = np.argmin(np.abs(np.asarray(bbox_mask_coverage) - patch_vol))\n",
    "bbox_idx_ini = torch.tensor(possible_bbox_coords_ini[bbox_coord_idx])\n",
    "bbox_coord = torch.cat([bbox_idx_ini, bbox_idx_ini + region_size])\n",
    "bbox_coords.append(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bbox_coords = torch.stack(bbox_coords)\n",
    "\n",
    "bbox_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Training Set Subjects: {[s.subj_id for s in train_dataset.dry_iter()]}\\n\")\n",
    "    f.write(f\"Validation Set Subjects: {[s.subj_id for s in val_dataset.dry_iter()]}\\n\")\n",
    "    f.write(f\"Test Set Subjects: {[s.subj_id for s in test_dataset.dry_iter()]}\\n\")\n",
    "\n",
    "logger.add_text(\"train_subjs\", str([s.subj_id for s in train_dataset.dry_iter()]))\n",
    "logger.add_text(\"val_subjs\", str([s.subj_id for s in val_dataset.dry_iter()]))\n",
    "logger.add_text(\"test_subjs\", str([s.subj_id for s in test_dataset.dry_iter()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "debug_prob = -1 / (patches_per_subj * num_train_subjs / exp_params.patch.batch_size)\n",
    "\n",
    "\n",
    "class DIQTSystem(pl.LightningModule):\n",
    "\n",
    "    # Specify training loss methods with mappings to their names as strings.\n",
    "    loss_methods = {\n",
    "        \"MSE\".casefold(): torch.nn.MSELoss(reduction=\"mean\"),\n",
    "        \"SSE\".casefold(): torch.nn.MSELoss(reduction=\"sum\"),\n",
    "        \"RMSE\".casefold(): lambda y_hat, y: torch.sqrt(\n",
    "            F.mse_loss(y_hat, y, reduction=\"mean\")\n",
    "        ),\n",
    "        \"L1\".casefold(): torch.nn.L1Loss(reduction=\"mean\"),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        downsample_factor,\n",
    "        train_loss_method: str,\n",
    "        opt_params: dict,\n",
    "        norm_method=None,\n",
    "        val_viz_bboxes=None,\n",
    "        val_patch_overlap=(0, 0, 0),\n",
    "        val_viz_every_n_epochs=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = channels\n",
    "        self._downsample_factor = downsample_factor\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = pitn.nn.models.ThreeConv(\n",
    "            self._channels, self._downsample_factor, norm_method=norm_method\n",
    "        )\n",
    "        #         self.net = pitn.nn.models.DebugFC(\n",
    "        #             input_patch_shape, output_patch_shape\n",
    "        #         )\n",
    "        self._norm_eps = 1e-10\n",
    "        ## Training parameters\n",
    "        self.opt_params = opt_params\n",
    "\n",
    "        # Select loss method as either one of the pre-selected methods, or a custom\n",
    "        # callable.\n",
    "        try:\n",
    "            self._loss_fn = self.loss_methods[train_loss_method.casefold()]\n",
    "        except (AttributeError, KeyError):\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"ERROR: Invalid loss function specification {train_loss_method}, \"\n",
    "                    + f\"expected one of {self.loss_methods.keys()} or a callable.\"\n",
    "                )\n",
    "\n",
    "        # Sub-regions of the volume that should be logged in validation.\n",
    "        if val_viz_bboxes is None:\n",
    "            self.val_bboxes = torch.zeros(0, 6)\n",
    "        else:\n",
    "            self.val_bboxes = val_viz_bboxes\n",
    "        self.val_patch_overlap = val_patch_overlap\n",
    "\n",
    "        # Store the validation set min and max for each bounding box, to keep a consistent\n",
    "        # color scale on the color bar.\n",
    "        self.val_vmin = [\n",
    "            None,\n",
    "        ] * self.val_bboxes.shape[0]\n",
    "        self.val_vmax = [\n",
    "            None,\n",
    "        ] * self.val_bboxes.shape[0]\n",
    "        self.val_viz_every_n_epochs = val_viz_every_n_epochs\n",
    "        self._last_val_viz_epoch = -1\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = Addict(\n",
    "            {\n",
    "                \"train_loss\": list(),\n",
    "                \"val_loss\": list(),\n",
    "                \"test_loss\": list(),\n",
    "                \"spline_loss\": list(),\n",
    "                \"viz\": Addict(\n",
    "                    {\n",
    "                        \"test_preds\": Addict(),\n",
    "                        \"test_squared_error\": Addict(),\n",
    "                    }\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "        #         if self.net.norm is not None:\n",
    "        #             y = self.normalize_with_layer(self.net.norm, y)\n",
    "\n",
    "        loss = self._loss_fn(\n",
    "            torch.masked_select(y_pred, masks), torch.masked_select(y, masks)\n",
    "        )\n",
    "\n",
    "        # Random debug scheduling.\n",
    "        if random.random() <= debug_prob:\n",
    "            batch_size = x.shape[0]\n",
    "            images = list()\n",
    "            tab_labels = list()\n",
    "            image_labels = list()\n",
    "            channel_labels = [\n",
    "                \"D x,x\",\n",
    "                \"D x,y\",\n",
    "                \"D y,y\",\n",
    "                \"D x,z\",\n",
    "                \"D y,z\",\n",
    "                \"D z,z\",\n",
    "            ]\n",
    "            # Construct the images to display, their names, and their batch index\n",
    "            # as the \"class\" tab label.\n",
    "            # ipyplot only takes flat lists as parameters, so no fancy multi-dimensional\n",
    "            # lists or anything like that.\n",
    "            # Each batch is its own \"class\" (UI tab).\n",
    "            for batch_i in range(batch_size):\n",
    "                # Create a new set of images for every channel.\n",
    "                for channel_i, channel_name in enumerate(channel_labels):\n",
    "\n",
    "                    # Collect the input image.\n",
    "                    input_img = x[batch_i, channel_i].detach().cpu().numpy()\n",
    "                    # ipyplot will use PIL.Image when given a numpy array to display, so\n",
    "                    # float ndarrays must be scaled between 0 and 1.\n",
    "                    input_img = skimage.exposure.rescale_intensity(\n",
    "                        input_img, out_range=(0.0, 1.0)\n",
    "                    )\n",
    "                    # Remove the oversampled pixels.\n",
    "                    input_img = input_img[2:-2, 2:-2, 2:-2]\n",
    "                    input_img = input_img[:, 7 // 2]\n",
    "                    tab_labels.append(str(batch_i))\n",
    "                    images.append(input_img)\n",
    "                    image_labels.append(f\"Input {channel_name}\")\n",
    "\n",
    "                    # Collect the target image.\n",
    "                    target_img = y[batch_i, channel_i].detach().cpu().numpy()\n",
    "                    target_img = skimage.exposure.rescale_intensity(\n",
    "                        target_img, out_range=(0.0, 1.0)\n",
    "                    )\n",
    "                    tab_labels.append(str(batch_i))\n",
    "                    target_img = target_img[:, (7 // 2) * 2, :]\n",
    "                    images.append(target_img)\n",
    "                    image_labels.append(f\"Target {channel_name}\")\n",
    "\n",
    "                    # Collect the predicted image.\n",
    "                    pred_img = y_pred[batch_i, channel_i].detach().cpu().numpy()\n",
    "                    pred_img = skimage.exposure.rescale_intensity(\n",
    "                        pred_img, out_range=(0.0, 1.0)\n",
    "                    )\n",
    "                    tab_labels.append(str(batch_i))\n",
    "                    pred_img = pred_img[:, (7 // 2) * 2, :]\n",
    "                    images.append(pred_img)\n",
    "                    image_labels.append(f\"Prediction {channel_name}\")\n",
    "\n",
    "                # Collect the mask image (only 1 per batch).\n",
    "                mask_img = masks[batch_i][0].detach().cpu().numpy()\n",
    "                mask_img = mask_img.astype(bool)\n",
    "                mask_img = mask_img[:, (7 // 2) * 2, :]\n",
    "                tab_labels.append(str(batch_i))\n",
    "                images.append(mask_img)\n",
    "                image_labels.append(\"Mask\")\n",
    "\n",
    "            ipyplot.plot_class_tabs(\n",
    "                images, tab_labels, custom_texts=image_labels, show_url=False\n",
    "            )\n",
    "            breakpoint()\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx):\n",
    "        # The validation samples include extra metadata regarding the patches.\n",
    "        batch = Addict(batch)\n",
    "        x = batch.low_res\n",
    "        y = batch.full_res\n",
    "        y_locs = batch.full_res_locs\n",
    "        y_masks = batch.full_res_masks\n",
    "        fr_means = batch.fr_means\n",
    "        fr_vars = batch.fr_vars\n",
    "\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "\n",
    "        # Denormalize the patches and predictions and calculate RMSE on intensity values\n",
    "        # in the original data's scale.\n",
    "        if (not (fr_means == 0).all()) and (not (fr_vars == 1).all()):\n",
    "            y = pitn.data.norm.denormalize_batch(\n",
    "                y, mean=fr_means, var=fr_vars, eps=self._norm_eps\n",
    "            )\n",
    "            y_pred = pitn.data.norm.denormalize_batch(\n",
    "                y_pred, mean=fr_means, var=fr_vars, eps=self._norm_eps\n",
    "            )\n",
    "\n",
    "        squared_error = F.mse_loss(y_pred, y, reduction=\"none\") * y_masks\n",
    "\n",
    "        bbox_patches = list()\n",
    "        y_locs = y_locs.detach().cpu()\n",
    "        for bbox in self.val_bboxes:\n",
    "\n",
    "            bbox = bbox.detach().cpu()\n",
    "            locs_to_keep = torch.prod(\n",
    "                y_locs[:, :3] >= bbox[None, :3], dim=1\n",
    "            ) & torch.prod(y_locs[:, 3:] <= bbox[None, 3:], dim=1)\n",
    "            locs_to_keep = locs_to_keep.to(y_pred).bool()\n",
    "            bbox_patches.append(\n",
    "                {\n",
    "                    \"full_res\": y[locs_to_keep].detach().cpu(),\n",
    "                    \"pred\": y_pred[locs_to_keep].detach().cpu(),\n",
    "                    \"locations\": y_locs[locs_to_keep].detach().cpu(),\n",
    "                    \"abs_error\": torch.sqrt(squared_error[locs_to_keep].detach()).cpu(),\n",
    "                }\n",
    "            )\n",
    "            assert (bbox_patches[-1][\"locations\"] >= 0).all()\n",
    "\n",
    "        return {\"squared_error\": squared_error, \"masks\": y_masks, \"bbox\": bbox_patches}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        # Combine all squared error patches and take the mean over the number of voxels in\n",
    "        # all the masks, a.k.a. the number of valid voxels.\n",
    "        sse = sum([step[\"squared_error\"].sum() for step in outputs])\n",
    "        N = sum([step[\"masks\"].sum() for step in outputs])\n",
    "        val_loss = torch.sqrt(sse / N)\n",
    "\n",
    "        # Log the final RMSE value for this validation epoch.\n",
    "        self.log(\"val_loss\", val_loss, logger=True)\n",
    "        self.plain_log[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        # Create validation set visualizations, if necessary.\n",
    "        # Only create a validation visualization if the current global epoch has reached a\n",
    "        # threshold.\n",
    "        if (\n",
    "            self.current_epoch % self.val_viz_every_n_epochs == 0\n",
    "            or (self.current_epoch - self._last_val_viz_epoch)\n",
    "            > self.val_viz_every_n_epochs\n",
    "        ):\n",
    "\n",
    "            self._last_val_viz_epoch = self.current_epoch\n",
    "\n",
    "            # Sub-select only bboxes from the val step outputs.\n",
    "            batched_bbox_patches = [b[\"bbox\"] for b in outputs]\n",
    "\n",
    "            # Construct validation outputs within the selected bboxes.\n",
    "            sub_regions = list()\n",
    "            for (\n",
    "                i,\n",
    "                bbox,\n",
    "            ) in enumerate(self.val_bboxes):\n",
    "\n",
    "                bbox = bbox.detach().cpu()\n",
    "                bbox_offset = bbox[:3]\n",
    "\n",
    "                fr_patches = torch.cat(\n",
    "                    [batch[i][\"full_res\"] for batch in batched_bbox_patches]\n",
    "                )\n",
    "\n",
    "                pred_patches = torch.cat(\n",
    "                    [batch[i][\"pred\"] for batch in batched_bbox_patches]\n",
    "                )\n",
    "                abs_error_patches = torch.cat(\n",
    "                    [batch[i][\"abs_error\"] for batch in batched_bbox_patches]\n",
    "                )\n",
    "                locs = torch.cat(\n",
    "                    [batch[i][\"locations\"] for batch in batched_bbox_patches]\n",
    "                )\n",
    "\n",
    "                fr_agg = pitn.viz.SubGridAggregator(\n",
    "                    bbox[3:] - bbox[:3],\n",
    "                    location_offset=bbox_offset,\n",
    "                    patch_overlap=self.val_patch_overlap,\n",
    "                )\n",
    "                fr_agg.add_batch(fr_patches, locs)\n",
    "                fr_sub_vol = fr_agg.get_output_tensor()\n",
    "\n",
    "                pred_agg = pitn.viz.SubGridAggregator(\n",
    "                    bbox[3:] - bbox[:3],\n",
    "                    location_offset=bbox_offset,\n",
    "                    patch_overlap=self.val_patch_overlap,\n",
    "                )\n",
    "                pred_agg.add_batch(pred_patches, locs)\n",
    "                pred_sub_vol = pred_agg.get_output_tensor()\n",
    "\n",
    "                abs_error_agg = pitn.viz.SubGridAggregator(\n",
    "                    bbox[3:] - bbox[:3],\n",
    "                    location_offset=bbox_offset,\n",
    "                    patch_overlap=self.val_patch_overlap,\n",
    "                )\n",
    "                abs_error_agg.add_batch(abs_error_patches, locs)\n",
    "                abs_error_sub_vol = abs_error_agg.get_output_tensor()\n",
    "\n",
    "                sub_regions.append(\n",
    "                    {\n",
    "                        \"full_res\": fr_sub_vol,\n",
    "                        \"pred\": pred_sub_vol,\n",
    "                        \"abs_error\": abs_error_sub_vol,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # Create visualization for each bbox/sub-region.\n",
    "            for i, reg in enumerate(sub_regions):\n",
    "                # Slice into full volume and just grab a B x C x H x W slice.\n",
    "                slice_idx = (\n",
    "                    slice(None),\n",
    "                    None,\n",
    "                    slice(None),\n",
    "                    reg[\"full_res\"].shape[1] // 2,\n",
    "                    slice(None),\n",
    "                )\n",
    "\n",
    "                row_fr = torchvision.utils.make_grid(\n",
    "                    reg[\"full_res\"][slice_idx], padding=3, pad_value=-2, nrow=1\n",
    "                )\n",
    "                row_pred = torchvision.utils.make_grid(\n",
    "                    reg[\"pred\"][slice_idx], padding=3, pad_value=-2, nrow=1\n",
    "                )\n",
    "                row_abs_error = torchvision.utils.make_grid(\n",
    "                    reg[\"abs_error\"][slice_idx], padding=3, pad_value=-2, nrow=1\n",
    "                )\n",
    "                reg_grid = torchvision.utils.make_grid(\n",
    "                    [row_fr, row_pred, row_abs_error], nrow=3, pad_value=-2\n",
    "                )[0]\n",
    "\n",
    "                fig = plt.figure(figsize=(8, 4.5), dpi=110, clear=True)\n",
    "\n",
    "                vmin = self.val_vmin[i]\n",
    "                vmax = self.val_vmax[i]\n",
    "                # Calculate vmin and vmax only *once* for the entire training run, per bbox.\n",
    "                if vmin is None:\n",
    "                    vmin = np.quantile(\n",
    "                        reg[\"full_res\"][slice_idx].cpu().numpy().flatten(), 0.05\n",
    "                    )\n",
    "                    self.val_vmin[i] = vmin\n",
    "                if vmax is None:\n",
    "                    vmax = np.quantile(\n",
    "                        reg[\"full_res\"][slice_idx].cpu().numpy().flatten(), 0.95\n",
    "                    )\n",
    "                    self.val_vmax[i] = vmax\n",
    "\n",
    "                plt.imshow(\n",
    "                    np.rot90(reg_grid.cpu().numpy(), axes=(-2, -1)),\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax,\n",
    "                    cmap=\"jet\",\n",
    "                )\n",
    "                plt.xticks([], [])\n",
    "                plt.yticks([], [])\n",
    "                plt.colorbar(location=\"bottom\")\n",
    "                self.logger.experiment.add_figure(\n",
    "                    f\"val_samples_{i}\", fig, self.global_step\n",
    "                )\n",
    "\n",
    "    def test_step(self, batch: dict, batch_idx):\n",
    "\n",
    "        # The test samples include extra metadata regarding the patches.\n",
    "        batch = Addict(batch)\n",
    "        x = batch.low_res\n",
    "        y = batch.full_res\n",
    "        y_locs = batch.full_res_locs\n",
    "        y_masks = batch.full_res_masks\n",
    "        fr_means = batch.fr_means\n",
    "        fr_vars = batch.fr_vars\n",
    "        ids = batch.subj_ids\n",
    "\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "\n",
    "        # Denormalize the patches and predictions and calculate RMSE on intensity values\n",
    "        # in the original data's scale.\n",
    "        if (not (fr_means == 0).all()) and (not (fr_vars == 1).all()):\n",
    "            y = pitn.data.norm.denormalize_batch(\n",
    "                y, mean=fr_means, var=fr_vars, eps=self._norm_eps\n",
    "            )\n",
    "            y_pred = pitn.data.norm.denormalize_batch(\n",
    "                y_pred, mean=fr_means, var=fr_vars, eps=self._norm_eps\n",
    "            )\n",
    "\n",
    "        squared_error = F.mse_loss(y_pred, y, reduction=\"none\")\n",
    "        # Zero out all voxels outside the brain.\n",
    "        squared_error *= y_masks\n",
    "        # Update or instantiate all test subject reconstructions according to subj id.\n",
    "        for subj_id in torch.unique(ids).tolist():\n",
    "            id_selection_mask = ids == subj_id\n",
    "            if subj_id not in self.plain_log.viz.test_preds.keys():\n",
    "                # TODO Remove the `subj_data` global reference and move the subj shape\n",
    "                # into the function/class scope.\n",
    "                self.plain_log.viz.test_preds[subj_id] = pitn.viz.SubGridAggregator(\n",
    "                    spatial_shape=subj_data[subj_id][\"fr_dti\"].spatial_shape,\n",
    "                    patch_overlap=0,\n",
    "                )\n",
    "            #             subj_abs_error = torch.sqrt(\n",
    "            #                 squared_error[id_selection_mask] * y_masks[id_selection_mask]\n",
    "            #             ).cpu()\n",
    "            self.plain_log.viz.test_preds[subj_id].add_batch(\n",
    "                y_pred[id_selection_mask].detach().cpu(),\n",
    "                y_locs[id_selection_mask].detach().cpu(),\n",
    "            )\n",
    "\n",
    "        return {\"squared_error\": squared_error, \"masks\": y_masks, \"ids\": ids}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "\n",
    "        rmses = list()\n",
    "        ids = torch.cat([step[\"ids\"] for step in outputs])\n",
    "        # Combine all squared error patches and take the mean over the number of voxels in\n",
    "        # all the masks, a.k.a. the number of valid voxels.\n",
    "        squared_error = torch.cat([step[\"squared_error\"] for step in outputs])\n",
    "        masks = torch.cat([step[\"masks\"] for step in outputs])\n",
    "\n",
    "        for subj_id in torch.unique(ids):\n",
    "\n",
    "            id_mask = ids == subj_id\n",
    "            subj_squared_error = squared_error[id_mask]\n",
    "            subj_vol_mask = masks[id_mask]\n",
    "            # All non-masked squared error terms should already be zeroed out.\n",
    "            sse = subj_squared_error.sum()\n",
    "            # The total voxels in the mask equals the total number of voxels considered for\n",
    "            # evaluation.\n",
    "            N = subj_vol_mask.sum()\n",
    "            test_loss = torch.sqrt(sse / N)\n",
    "            # Log the final RMSE value for this test subject.\n",
    "            self.plain_log[\"test_loss\"].append(test_loss.cpu().item())\n",
    "            rmses.append(test_loss.cpu().item())\n",
    "\n",
    "            subj_squared_error_dist = (\n",
    "                torch.masked_select(squared_error, masks).flatten().cpu().numpy()\n",
    "            )\n",
    "            se_counts, se_bins = np.histogram(subj_squared_error_dist, bins=40)\n",
    "            self.plain_log.viz.test_squared_error[subj_id].bins = se_bins\n",
    "            self.plain_log.viz.test_squared_error[subj_id].counts = se_counts\n",
    "\n",
    "        self.log(\"test_loss\", np.asarray(rmses).mean(), logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), **self.opt_params)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "model = DIQTSystem(\n",
    "    channels=channels,\n",
    "    downsample_factor=downsample_factor,\n",
    "    norm_method=network_norm_method,\n",
    "    train_loss_method=train_loss_name,\n",
    "    opt_params=opt_params,\n",
    "    val_viz_bboxes=bbox_coords,\n",
    "    val_patch_overlap=0,\n",
    "    val_viz_every_n_epochs=5,\n",
    ")\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Model overview: {model}\\n\")\n",
    "\n",
    "# Create trainer object.\n",
    "trainer = pl.Trainer(\n",
    "    #     fast_dev_run=20,\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger=pl_logger,\n",
    "    log_every_n_steps=50,\n",
    "    check_val_every_n_epoch=10,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    terminate_on_nan=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out trained model\n",
    "trainer.save_checkpoint(str(experiment_results_dir / \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + train_loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store test reconstructions along the way for later visualization.\n",
    "test_vol_viz = Addict()\n",
    "\n",
    "# Structure is as follows:\n",
    "# {subj_id_1:\n",
    "#    fr_mask: np.ndarray,\n",
    "#    dti: {\n",
    "#          diqt: np.ndarray,\n",
    "#          spline: np.ndarray,\n",
    "#          fr: np.ndarray,\n",
    "#          lr: np.ndarray\n",
    "#          ...\n",
    "#         }\n",
    "#    fa: {\n",
    "#         diqt: np.ndarray,\n",
    "#         ...\n",
    "#        },\n",
    "# pitn.data.norm.denormalize_batch(y, mean=fr_means, var=fr_vars, eps=self._norm_eps)\n",
    "#  subj_id_2:\n",
    "#     ....\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debug code for model editing after training has been completed.\n",
    "\n",
    "# _model = DIQTSystem(\n",
    "#     channels=channels,\n",
    "#     downsample_factor=downsample_factor,\n",
    "#     norm_method=network_norm_method,\n",
    "#     train_loss_method=train_loss_name,\n",
    "#     opt_params=opt_params,\n",
    "#     val_viz_bboxes=bbox_coords,\n",
    "#     val_patch_overlap=0,\n",
    "#     val_viz_every_n_epochs=5,\n",
    "# )\n",
    "# _model.load_from_checkpoint(\n",
    "#     experiment_results_dir / \"model.ckpt\",\n",
    "#     channels=channels,\n",
    "#     downsample_factor=downsample_factor,\n",
    "#     norm_method=network_norm_method,\n",
    "#     train_loss_method=train_loss_name,\n",
    "#     opt_params=opt_params,\n",
    "#     val_viz_bboxes=bbox_coords,\n",
    "#     val_patch_overlap=0,\n",
    "#     val_viz_every_n_epochs=5,\n",
    "# )\n",
    "# trainer.test(_model, test_dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(model, test_dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store DIQT test reconstructions for visualization.\n",
    "for subj in test_dataset.dry_iter():\n",
    "    subj_id = subj.subj_id\n",
    "    test_vol_viz[subj_id].dti.diqt = (\n",
    "        model.plain_log.viz.test_preds[subj_id].get_output_tensor().cpu().numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss_name = \"RMSE\"\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Test loss function: {test_loss_name}\\n\")\n",
    "\n",
    "row_iter = enumerate(model.plain_log[\"test_loss\"])\n",
    "test_loss_tabular = \"\".join([f\"{batch_idx}, {loss}\\n\" for batch_idx, loss in row_iter])\n",
    "\n",
    "with open(test_loss_log_file, \"a+\") as f:\n",
    "    f.write(\"batch_idx, loss\\n\")\n",
    "    f.write(test_loss_tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spline Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spline_test_log = dict()\n",
    "\n",
    "for subj in test_dataset.dry_iter():\n",
    "    #     breakpoint()\n",
    "    print(\"---\")\n",
    "    target_shape = subj[\"fr_dti\"][\"data\"].cpu().numpy().shape\n",
    "    interp_spline = scipy.ndimage.zoom(\n",
    "        subj[\"lr_dti\"][\"data\"].cpu().numpy(),\n",
    "        zoom=(1, downsample_factor, downsample_factor, downsample_factor),\n",
    "        order=exp_params.spline.order,\n",
    "    )\n",
    "    # 0-out everything not in the mask, for both visualization and quantification.\n",
    "    interp_spline = interp_spline * subj[\"fr_brain_mask\"][\"data\"].bool().cpu().numpy()\n",
    "    if interp_spline.shape != target_shape:\n",
    "        # Crop off the end few voxels to account for the lack of padding used in full-\n",
    "        # volume inference.\n",
    "        interp_spline = interp_spline[\n",
    "            :, : target_shape[1], : target_shape[2], : target_shape[3]\n",
    "        ]\n",
    "    subj_id = subj[\"subj_id\"]\n",
    "    print(f\"Subj {subj_id} done\")\n",
    "\n",
    "    spline_test_log[subj_id] = interp_spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spline_loss = list()\n",
    "\n",
    "# Calculate spline loss for test images.\n",
    "for subj in test_dataset.dry_iter():\n",
    "    #     breakpoint()\n",
    "    # De-normalize the ground truth volume.\n",
    "    subj_id = subj[\"subj_id\"]\n",
    "    spline_pred = spline_test_log[subj_id]\n",
    "\n",
    "    gt = subj[\"fr_dti\"][\"data\"]\n",
    "    gt_means = torch.from_numpy(subj[\"fr_means\"])\n",
    "    gt_vars = torch.from_numpy(subj[\"fr_vars\"])\n",
    "    lr_means = torch.from_numpy(subj[\"lr_means\"])\n",
    "    lr_vars = torch.from_numpy(subj[\"lr_vars\"])\n",
    "\n",
    "    brain_mask = subj[\"fr_brain_mask\"][\"data\"].bool().cpu().numpy()[0]\n",
    "    if (\n",
    "        exp_params.data.data_norm_method is not None\n",
    "        and \"channel\" in exp_params.data.data_norm_method.casefold()\n",
    "    ):\n",
    "        print(\"De-normalizing\")\n",
    "        gt = pitn.data.norm.denormalize_batch(gt, mean=gt_means, var=gt_vars, eps=1e-10)\n",
    "        spline_pred = torch.from_numpy(spline_pred)\n",
    "        spline_pred = pitn.data.norm.denormalize_batch(\n",
    "            spline_pred, mean=lr_means, var=lr_vars, eps=1e-10\n",
    "        )\n",
    "\n",
    "        spline_pred = spline_pred.detach().cpu().numpy()\n",
    "\n",
    "    gt = gt.detach().cpu().numpy()\n",
    "\n",
    "    # Calculate the RMSE of just the values found in the mask.\n",
    "    se = (gt - spline_pred) ** 2\n",
    "    se = se[:, brain_mask]\n",
    "    loss = np.sqrt(se.mean())\n",
    "    spline_loss.append(loss)\n",
    "\n",
    "    # Store spline test reconstructions for visualization.\n",
    "    test_vol_viz[subj_id].dti.spline = spline_pred.copy()\n",
    "\n",
    "# Find the grand mean of the spline RMSE's\n",
    "spline_loss_mean = np.mean(spline_loss)\n",
    "print(spline_loss_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = False\n",
    "\n",
    "sns.histplot(\n",
    "    model.plain_log[\"test_loss\"],\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    ")\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"-\", \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Our spline mean performance.\n",
    "plt.axvline(\n",
    "    spline_loss_mean,\n",
    "    label=f\"(Ours) Spline Mean Order {exp_params.spline.order}\",\n",
    "    color=\"black\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Tanno, et. al., 2021 model comparisons.\n",
    "# Taken from Table 2, HCP exterior.\n",
    "plt.axvline(\n",
    "    31.738e-4,\n",
    "    label=\"(Tanno etal, 2021) C-spline Mean\",\n",
    "    color=\"red\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    23.139e-4,\n",
    "    label=\"(Tanno etal, 2021) RF\",\n",
    "    color=\"orange\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.609e-4,\n",
    "    label=\"(Tanno etal, 2021) ESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.412e-4,\n",
    "    label=\"(Tanno etal, 2021) Best\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    12.78e-4,\n",
    "    label=\"(Blumberg etal, 2018) Best\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(f\"Test Loss Histogram Over All Subjects with Test Metric {test_loss_name}\")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "\n",
    "models = (\n",
    "    \"(Ours)\\nCurrent Model\",\n",
    "    f\"(Ours)\\nSpline Order {exp_params.spline.order}\",\n",
    "    \"(Tanno etal, 2021)\\nC-spline Mean\",\n",
    "    \"(Tanno etal, 2021)\\nRF\",\n",
    "    \"(Tanno etal, 2021)\\nESPCN Baseline\",\n",
    "    \"(Tanno etal, 2021)\\nBest\",\n",
    "    \"(Blumberg etal, 2018)\\nBest\",\n",
    ")\n",
    "\n",
    "rmse_scores = (\n",
    "    np.asarray(model.plain_log[\"test_loss\"]).mean(),\n",
    "    spline_loss_mean,\n",
    "    31.738e-4,\n",
    "    23.139e-4,\n",
    "    13.609e-4,\n",
    "    13.412e-4,\n",
    "    12.13e-4,\n",
    ")\n",
    "rmse_std_error = np.asarray([0, 0, 0, 0.351e-4, 0.084e-4, 0.041e-4, 1.24e-4])\n",
    "\n",
    "ax.grid(True, axis=\"y\", zorder=1000)\n",
    "ax.set_axisbelow(True)\n",
    "ax.bar(\n",
    "    models,\n",
    "    rmse_scores,\n",
    "    yerr=rmse_std_error,\n",
    "    color=sns.color_palette(\"deep\", n_colors=len(rmse_scores)),\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    if isinstance(container, mpl.container.BarContainer):\n",
    "        ax.bar_label(container, fmt=\"%.3e\")\n",
    "\n",
    "ax.set_ylim(bottom=0, top=ax.get_ylim()[1] * 1.1)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "ax.set_title(f\"Mean Over Subjects Test Loss {test_loss_name}\")\n",
    "ax.set_xticks(models)\n",
    "ax.set_xticklabels(\n",
    "    models, fontsize=\"x-small\", rotation=25, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.plain_log[\"test_loss\"])\n",
    "print(np.mean(model.plain_log[\"test_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(spline_loss)\n",
    "print(spline_loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.add_histogram(\"test/rmse_dist\", np.asarray(model.plain_log[\"test_loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save out metrics and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_hparams.metric[\"hparam/rmse\"] = np.mean(model.plain_log[\"test_loss\"])\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Mean RMSE Testing Value: {np.mean(model.plain_log['test_loss'])}\\n\")\n",
    "    f.write(f\"Mean RMSE Spline Value: {spline_loss_mean}\\n\")\n",
    "\n",
    "logger.add_scalar(\"metric/rmse\", np.mean(model.plain_log[\"test_loss\"]))\n",
    "logger.add_scalar(\"metric/spline\", spline_loss_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debug flag(s)\n",
    "disable_fig_save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volume of full-res ground truth, low-res downsample, full-res mask, and\n",
    "# full-res predictions.\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj_i in test_dataset.dry_iter():\n",
    "        subj = copy.copy(subj_i)\n",
    "        subj_id = subj[\"subj_id\"]\n",
    "        print(f\"Starting subject {subj_id}\")\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "        fr_vol = subj[\"fr_dti\"][\"data\"].clone()\n",
    "        lr_vol = subj[\"lr_dti\"][\"data\"].clone()\n",
    "\n",
    "        full_res_predicted = torch.from_numpy(test_vol_viz[subj_id].dti.diqt.copy())\n",
    "        full_res_spline = torch.from_numpy(test_vol_viz[subj_id].dti.spline.copy())\n",
    "\n",
    "        #         warnings.warn(\"======== Skipping all de-normalization for visualization.\")\n",
    "        #         if False:\n",
    "        if data_norm_method is not None and \"channel\" in data_norm_method.casefold():\n",
    "            print(\"Normalizing\")\n",
    "            fr_means = torch.as_tensor(subj[\"fr_means\"]).to(fr_vol).clone()\n",
    "            fr_vars = torch.as_tensor(subj[\"fr_vars\"]).to(fr_vol).clone()\n",
    "\n",
    "            lr_means = torch.as_tensor(subj[\"lr_means\"]).to(lr_vol).clone()\n",
    "            lr_vars = torch.as_tensor(subj[\"lr_vars\"]).to(lr_vol).clone()\n",
    "\n",
    "            fr_vol = pitn.data.norm.denormalize_dti(\n",
    "                fr_vol, mean=fr_means, var=fr_vars\n",
    "            ).clone()\n",
    "            lr_vol = pitn.data.norm.denormalize_dti(\n",
    "                lr_vol, mean=lr_means, var=lr_vars\n",
    "            ).clone()\n",
    "\n",
    "        #             full_res_spline = pitn.data.norm.denormalize_dti(\n",
    "        #                 full_res_spline, lr_means, lr_vars\n",
    "        #             )\n",
    "        #             full_res_predicted = pitn.data.norm.denormalize_dti(\n",
    "        #                 full_res_predicted, lr_means, lr_vars\n",
    "        #             )\n",
    "        # Zero-out all voxels outside the mask.\n",
    "\n",
    "        fr_mask = subj[\"fr_brain_mask\"][\"data\"].bool().clone()\n",
    "        full_res_spline = full_res_spline * fr_mask.to(full_res_spline).bool()\n",
    "        fr_vol = fr_vol * fr_mask.to(fr_vol).bool()\n",
    "        full_res_predicted = full_res_predicted * fr_mask.to(full_res_predicted).bool()\n",
    "        lr_vol = lr_vol * subj[\"lr_brain_mask\"][\"data\"].to(lr_vol).bool()\n",
    "        abs_error = torch.abs(full_res_predicted - fr_vol)\n",
    "\n",
    "        #         print(\n",
    "        #             \"RMSE of Non-Normalized FR to itself normalized: \",\n",
    "        #             torch.sqrt(\n",
    "        #                 (\n",
    "        #                     (\n",
    "        #                         torch.masked_select(fr_vol, fr_mask)\n",
    "        #                         - torch.masked_select(subj[\"fr_dti\"][\"data\"], fr_mask)\n",
    "        #                     )\n",
    "        #                     ** 2\n",
    "        #                 ).mean()\n",
    "        #             ),\n",
    "        #         )\n",
    "\n",
    "        #         print(\n",
    "        #             \"RMSE of LR to itself: \",\n",
    "        #             torch.sqrt(((lr_vol - subj[\"lr_dti\"][\"data\"]) ** 2).mean()),\n",
    "        #         )\n",
    "\n",
    "        test_vol_viz[subj.subj_id].dti.update(\n",
    "            fr=fr_vol.cpu().numpy(),\n",
    "            lr=lr_vol.cpu().numpy(),\n",
    "            diqt=full_res_predicted.cpu().numpy(),\n",
    "            spline=full_res_spline.cpu().numpy(),\n",
    "        )\n",
    "\n",
    "        test_vol_viz[subj.subj_id].fa.update(\n",
    "            itertools.starmap(\n",
    "                lambda k, v: (k, pitn.viz.fa_map(test_vol_viz[subj_id].dti[k])),\n",
    "                test_vol_viz[subj_id].dti.items(),\n",
    "            )\n",
    "        )\n",
    "        test_vol_viz[subj_id].fr_mask = fr_mask.cpu().numpy()\n",
    "        test_vol_viz[subj_id].dti.abs_error = abs_error.cpu().numpy()\n",
    "\n",
    "        #         subj_result = SubjResult(\n",
    "        #             subj_id=subj[\"subj_id\"],\n",
    "        #             full_res=fr_vol,\n",
    "        #             low_res=lr_vol,\n",
    "        #             full_res_predicted=full_res_predicted,\n",
    "        #             full_res_cubic_spline=full_res_cubic_spline,\n",
    "        #         )\n",
    "\n",
    "        #         test_vol_results.append(subj_result)\n",
    "        print(f\"Finished subject {subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out all network predictions to Nifti2 files and compress them into a zip archive.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in test_vol_viz.items():\n",
    "        pred_vol = viz.dti.diqt\n",
    "        affine = subj_data[subj_id][\"fr_dti\"].affine\n",
    "        nib_img = nib.Nifti2Image(pred_vol, affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_dti.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(experiment_results_dir / \"predicted_dti.zip\", \"w\") as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=6,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "    # Make sure we exit the 'with' statement above.\n",
    "    print(\"Done with files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz_subj_idx = 1\n",
    "viz_subj_id = list(test_vol_viz.keys())[viz_subj_idx]\n",
    "print(list(test_vol_viz.keys()))\n",
    "print(viz_subj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FA-Weighted Direction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for prediction.\n",
    "pred_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.diqt)\n",
    "# Set channels last for matplotlib\n",
    "pred_dir_map = pred_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.diqt = pred_dir_map\n",
    "\n",
    "spline_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.spline)\n",
    "# Set channels last for matplotlib\n",
    "spline_dir_map = spline_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.spline = spline_dir_map\n",
    "\n",
    "fr_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.fr)\n",
    "# Set channels last for matplotlib\n",
    "fr_dir_map = fr_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.fr = fr_dir_map\n",
    "\n",
    "lr_dir_map = pitn.viz.direction_map(test_vol_viz[viz_subj_id].dti.lr)\n",
    "# Set channels last for matplotlib\n",
    "lr_dir_map = lr_dir_map.transpose(1, 2, 3, 0)\n",
    "test_vol_viz[viz_subj_id].color_fa.lr = lr_dir_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_idx = (slice(None, None, None), slice(None, None, None), 86)\n",
    "low_res_slice_idx = tuple(s // 2 if isinstance(s, int) else s for s in slice_idx)\n",
    "print(slice_idx)\n",
    "print(low_res_slice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(pred_dir_map[slice_idx]), interpolation=\"none\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Predicted with DIQT Net\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"pred_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(spline_dir_map[slice_idx]), interpolation=\"none\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Spline Interpolation Order {exp_params.spline.order}\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"cubic_spline_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(fr_dir_map[slice_idx]), interpolation=\"none\")\n",
    "# plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Ground Truth\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"ground_truth_dir_map_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(lr_dir_map[low_res_slice_idx]), interpolation=\"none\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"LR Input\")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"low_res_map_sample.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DTI Channel-Wise Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"$D_{x,x}$\",\n",
    "    \"$D_{x,y}$\",\n",
    "    \"$D_{y,y}$\",\n",
    "    \"$D_{x,z}$\",\n",
    "    \"$D_{y,z}$\",\n",
    "    \"$D_{z,z}$\",\n",
    "]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    f\"Spline Order {exp_params.spline.order}\",\n",
    "    \"Predicted\",\n",
    "    \"Absolute Error\\nFR vs. Predicted\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "cmap = \"jet\"\n",
    "\n",
    "dtis = [\n",
    "    test_vol_viz[viz_subj_id].dti.fr[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.lr[(slice(None), *low_res_slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.spline[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.diqt[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.abs_error[(slice(None), *slice_idx)],\n",
    "]\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(np.rot90(dti[j_col]), cmap=cmap, interpolation=None)\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Per-Image Normalization\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"DTI_channel_sample_per_img_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "cmap = \"jet\"\n",
    "\n",
    "dtis = [\n",
    "    test_vol_viz[viz_subj_id].dti.fr[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.lr[(slice(None), *low_res_slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.spline[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.diqt[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.abs_error[(slice(None), *slice_idx)],\n",
    "]\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95)\n",
    "min_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05)\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dti,\n",
    "            vmax=max_dti,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "color_norm = mpl.colors.Normalize(vmin=min_dti, vmax=max_dti)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap),\n",
    "    ax=axs,\n",
    "    location=\"right\",\n",
    "    fraction=0.1,\n",
    "    pad=0.03,\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Normalized over All Images\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"DTI_channel_sample_global_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel-Wise Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, low-res input, and root squared error\n",
    "# Normalize by index in the DTI coefficients.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "\n",
    "cmap = \"coolwarm\"\n",
    "dtis = [\n",
    "    test_vol_viz[viz_subj_id].dti.fr[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.lr[(slice(None), *low_res_slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.spline[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.diqt[(slice(None), *slice_idx)],\n",
    "    test_vol_viz[viz_subj_id].dti.abs_error[(slice(None), *slice_idx)],\n",
    "]\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "max_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95, axis=1\n",
    ")\n",
    "min_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05, axis=1\n",
    ")\n",
    "\n",
    "max_dtis = np.max(np.abs([max_dtis, min_dtis]), axis=0)\n",
    "min_dtis = -1 * max_dtis\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "    axs_cols = list()\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dtis[j_col],\n",
    "            vmax=max_dtis[j_col],\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        axs_cols.append(ax)\n",
    "\n",
    "    axs.append(axs_cols)\n",
    "\n",
    "# Place colorbars on each column.\n",
    "for j_col in range(ncols):\n",
    "\n",
    "    full_col_ax = [axs[i][j_col] for i in range(nrows)]\n",
    "\n",
    "    color_norm = mpl.colors.Normalize(vmin=min_dtis[j_col], vmax=max_dtis[j_col])\n",
    "\n",
    "    color_mappable = mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap)\n",
    "    cbar = fig.colorbar(\n",
    "        color_mappable,\n",
    "        ax=full_col_ax,\n",
    "        location=\"top\",\n",
    "        orientation=\"horizontal\",\n",
    "        pad=0.01,\n",
    "        shrink=0.85,\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=8, rotation=35)\n",
    "    cbar.ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:g}\"))\n",
    "#     cbar.ax.ticklabel_format(scilimits=(3, -3), useOffset=False)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Channel-Wise Normalization\",\n",
    "    y=max_subplot_height + 0.01,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"DTI_channel_sample_channel_wise_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FA Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Slice locations for 2D visualization\n",
    "\n",
    "half_fr_space_shape = np.asarray(test_vol_viz[viz_subj_id].fa.fr.shape) // 2\n",
    "half_fr_space_shape = half_fr_space_shape.tolist()\n",
    "\n",
    "slice_indices = [\n",
    "    (half_fr_space_shape[0], slice(None, None, None), slice(None, None, None)),\n",
    "    (slice(None, None, None), half_fr_space_shape[1], slice(None, None, None)),\n",
    "    (slice(None, None, None), slice(None, None, None), half_fr_space_shape[2]),\n",
    "]\n",
    "\n",
    "low_res_slice_indices = list()\n",
    "for slice_idx_i in slice_indices:\n",
    "    slice_coords = tuple()\n",
    "    for s in slice_idx_i:\n",
    "        slice_coords = slice_coords + (s // 2 if isinstance(s, int) else s,)\n",
    "    low_res_slice_indices.append(slice_coords)\n",
    "\n",
    "print(slice_indices)\n",
    "print()\n",
    "print(low_res_slice_indices)\n",
    "\n",
    "row_names = [\n",
    "    \"Saggital\",\n",
    "    \"Coronal\",\n",
    "    \"Horizontal\",\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    f\"Spline Order {exp_params.spline.order}\",\n",
    "    \"Predicted\",\n",
    "    #     \"Absolute Error\\nFR vs. Predicted\",\n",
    "]\n",
    "\n",
    "nrows = len(row_names)\n",
    "ncols = len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = dict()\n",
    "for i_row, slice_i in enumerate(slice_indices):\n",
    "    low_res_slice_i = low_res_slice_indices[i_row]\n",
    "    imgs[i_row] = dict()\n",
    "    col_imgs = [\n",
    "        test_vol_viz[viz_subj_id].fa.fr[(*slice_i,)],\n",
    "        test_vol_viz[viz_subj_id].fa.lr[(*low_res_slice_i,)],\n",
    "        test_vol_viz[viz_subj_id].fa.spline[(*slice_i,)],\n",
    "        test_vol_viz[viz_subj_id].fa.diqt[(*slice_i,)],\n",
    "        #         test_vol_viz[viz_subj_id].fa.abs_error[(*slice_i,)],\n",
    "    ]\n",
    "\n",
    "    imgs[i_row].update(tuple(enumerate(col_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "cmap = \"jet\"\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Concatenate the images in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_intensity = np.max(\n",
    "    np.concatenate(\n",
    "        [imgs[i][j] for (i, j) in itertools.product(range(nrows), range(ncols))],\n",
    "        axis=None,\n",
    "    )\n",
    ")\n",
    "min_intensity = np.min(\n",
    "    np.concatenate(\n",
    "        [imgs[i][j] for (i, j) in itertools.product(range(nrows), range(ncols))],\n",
    "        axis=None,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(5 * 1.5, 3 * 1.5), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    img_row = imgs[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(img_row[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(row_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(model_names[j_col], size=\"small\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"FA Maps, Normalized Within Image\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"fa_sample_per_img_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "cmap = \"gist_gray\"\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Concatenate the images in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_intensity = np.quantile(\n",
    "    np.concatenate(\n",
    "        [imgs[i][j] for (i, j) in itertools.product(range(nrows), range(ncols))],\n",
    "        axis=None,\n",
    "    ),\n",
    "    0.95,\n",
    ")\n",
    "min_intensity = np.quantile(\n",
    "    np.concatenate(\n",
    "        [imgs[i][j] for (i, j) in itertools.product(range(nrows), range(ncols))],\n",
    "        axis=None,\n",
    "    ),\n",
    "    0.05,\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(5 * 1.5, 3 * 1.5), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    img_row = imgs[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(img_row[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_intensity,\n",
    "            vmax=max_intensity,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(row_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(model_names[j_col], size=\"small\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "color_norm = mpl.colors.Normalize(vmin=min_intensity, vmax=max_intensity)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap),\n",
    "    ax=axs,\n",
    "    location=\"right\",\n",
    "    fraction=0.1,\n",
    "    pad=0.03,\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"FA Maps, Normalized over All Images\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"fa_sample_global_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close tensorboard logger.\n",
    "# Don't finalize if the experiment was to debug.\n",
    "if \"debug\" not in EXPERIMENT_NAME.casefold():\n",
    "    # if True:\n",
    "    pl_logger.finalize(\"success\")\n",
    "    # Experiment is complete, move the results directory to its final location.\n",
    "    if experiment_results_dir != final_experiment_results_dir:\n",
    "        print(\"Moving out of tmp location\")\n",
    "        experiment_results_dir = experiment_results_dir.rename(\n",
    "            final_experiment_results_dir\n",
    "        )\n",
    "        log_txt_file = experiment_results_dir / log_txt_file.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
