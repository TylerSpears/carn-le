{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Pain in the Net\n",
    "Replication of *Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images*\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "Source work:\n",
    "`S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T14:59:57.555797Z",
     "iopub.status.busy": "2021-05-27T14:59:57.555305Z",
     "iopub.status.idle": "2021-05-27T15:00:00.907715Z",
     "shell.execute_reply": "2021-05-27T15:00:00.907016Z",
     "shell.execute_reply.started": "2021-05-27T14:59:57.555766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/pitn/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning:\n",
      "\n",
      "Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "from typing import Generator\n",
    "\n",
    "import ants\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython\n",
    "\n",
    "# Try importing GPUtil for printing GPU specs.\n",
    "# May not be installed if using CPU only.\n",
    "try:\n",
    "    import GPUtil\n",
    "except ImportError:\n",
    "    warnings.warn(\"WARNING: Package GPUtil not found, cannot print GPU specs\")\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import nilearn.plotting\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "import addict\n",
    "from addict import Addict\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "import einops\n",
    "import einops.layers\n",
    "import einops.layers.torch\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:00.909271Z",
     "iopub.status.busy": "2021-05-27T15:00:00.909103Z",
     "iopub.status.idle": "2021-05-27T15:00:01.616514Z",
     "shell.execute_reply": "2021-05-27T15:00:01.615637Z",
     "shell.execute_reply.started": "2021-05-27T15:00:00.909252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "direnv: loading ~/work/pitn/.envrc\n",
      "\u001b[31mdirenv: Could not find environment.yml\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.618124Z",
     "iopub.status.busy": "2021-05-27T15:00:01.617781Z",
     "iopub.status.idle": "2021-05-27T15:00:01.632174Z",
     "shell.execute_reply": "2021-05-27T15:00:01.631581Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.618090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-specific scripts\n",
    "# It's easier to import it this way rather than make an entirely new package, due to\n",
    "# conflicts with local packages and anaconda installations.\n",
    "# You made me do this, poor python package management!!\n",
    "if \"PROJECT_ROOT\" in os.environ:\n",
    "    lib_location = str(Path(os.environ[\"PROJECT_ROOT\"]).resolve())\n",
    "else:\n",
    "    lib_location = str(Path(\"../../\").resolve())\n",
    "if lib_location not in sys.path:\n",
    "    sys.path.insert(0, lib_location)\n",
    "import lib as pitn\n",
    "\n",
    "# Include the top-level lib module along with its submodules.\n",
    "%aimport lib\n",
    "# Grab all submodules of lib, not including modules outside of the package.\n",
    "includes = list(\n",
    "    filter(\n",
    "        lambda m: m.startswith(\"lib.\"),\n",
    "        map(lambda x: x[1].__name__, inspect.getmembers(pitn, inspect.ismodule)),\n",
    "    )\n",
    ")\n",
    "# Run aimport magic with constructed includes.\n",
    "ipy = IPython.get_ipython()\n",
    "ipy.run_line_magic(\"aimport\", \", \".join(includes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.633664Z",
     "iopub.status.busy": "2021-05-27T15:00:01.633366Z",
     "iopub.status.idle": "2021-05-27T15:00:01.672656Z",
     "shell.execute_reply": "2021-05-27T15:00:01.671889Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.633636Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.675286Z",
     "iopub.status.busy": "2021-05-27T15:00:01.675036Z",
     "iopub.status.idle": "2021-05-27T15:00:01.914083Z",
     "shell.execute_reply": "2021-05-27T15:00:01.912735Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.675267Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # GPU information\n",
    "    # Taken from\n",
    "    # <https://www.thepythoncode.com/article/get-hardware-system-information-python>.\n",
    "    # If GPUtil is not installed, skip this step.\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        print(\"=\" * 50, \"GPU Specs\", \"=\" * 50)\n",
    "        list_gpus = []\n",
    "        for gpu in gpus:\n",
    "            # get the GPU id\n",
    "            gpu_id = gpu.id\n",
    "            # name of GPU\n",
    "            gpu_name = gpu.name\n",
    "            driver_version = gpu.driver\n",
    "            cuda_version = torch.version.cuda\n",
    "            # get total memory\n",
    "            gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "            gpu_uuid = gpu.uuid\n",
    "            list_gpus.append(\n",
    "                (\n",
    "                    gpu_id,\n",
    "                    gpu_name,\n",
    "                    driver_version,\n",
    "                    cuda_version,\n",
    "                    gpu_total_memory,\n",
    "                    gpu_uuid,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            tabulate(\n",
    "                list_gpus,\n",
    "                headers=(\n",
    "                    \"id\",\n",
    "                    \"Name\",\n",
    "                    \"Driver Version\",\n",
    "                    \"CUDA Version\",\n",
    "                    \"Total Memory\",\n",
    "                    \"uuid\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.916780Z",
     "iopub.status.busy": "2021-05-27T15:00:01.916197Z",
     "iopub.status.idle": "2021-05-27T15:00:01.921660Z",
     "shell.execute_reply": "2021-05-27T15:00:01.921015Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.916719Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2021-05-27T15:00:01.692800+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-72-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: fefac297dfe654b99cd65da2730ef02f39d2f317\n",
      "\n",
      "einops           : 0.3.0\n",
      "torch            : 1.8.1\n",
      "ants             : 0.2.7\n",
      "nibabel          : 3.2.1\n",
      "torchio          : 0.18.37\n",
      "skimage          : 0.18.1\n",
      "IPython          : 7.23.1\n",
      "numpy            : 1.20.2\n",
      "pytorch_lightning: 1.3.2\n",
      "GPUtil           : 1.4.0\n",
      "natsort          : 7.1.1\n",
      "pandas           : 1.2.3\n",
      "nilearn          : 0.7.1\n",
      "addict           : 2.4.0\n",
      "json             : 2.0.9\n",
      "scipy            : 1.5.3\n",
      "torchvision      : 0.9.1\n",
      "matplotlib       : 3.4.1\n",
      "seaborn          : 0.11.1\n",
      "dipy             : 1.4.0\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "\n",
      "================================================== GPU Specs ==================================================\n",
      "  id  Name       Driver Version      CUDA Version  Total Memory    uuid\n",
      "----  ---------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  TITAN RTX  460.73.01                   11.1  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.923192Z",
     "iopub.status.busy": "2021-05-27T15:00:01.922901Z",
     "iopub.status.idle": "2021-05-27T15:00:01.929089Z",
     "shell.execute_reply": "2021-05-27T15:00:01.928513Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.923164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"]) / \"hcp\"\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"]) / \"hcp\"\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.930371Z",
     "iopub.status.busy": "2021-05-27T15:00:01.930076Z",
     "iopub.status.idle": "2021-05-27T15:00:01.938915Z",
     "shell.execute_reply": "2021-05-27T15:00:01.938420Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.930341Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = \"train_norm_only_instnorm_in_instnorm_out_mse\"\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_results_dir = results_dir / \"tmp\"\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 3\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.940354Z",
     "iopub.status.busy": "2021-05-27T15:00:01.940031Z",
     "iopub.status.idle": "2021-05-27T15:00:01.944591Z",
     "shell.execute_reply": "2021-05-27T15:00:01.944111Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.940327Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27T15_00_01__train_norm_only_instnorm_in_instnorm_out_mse\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.945489Z",
     "iopub.status.busy": "2021-05-27T15:00:01.945345Z",
     "iopub.status.idle": "2021-05-27T15:00:01.953833Z",
     "shell.execute_reply": "2021-05-27T15:00:01.953244Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.945473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.955859Z",
     "iopub.status.busy": "2021-05-27T15:00:01.955423Z",
     "iopub.status.idle": "2021-05-27T15:00:01.961575Z",
     "shell.execute_reply": "2021-05-27T15:00:01.960732Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.955822Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dict to keep track of experiment configuration parameters. Will not be logged to\n",
    "# tensorboard.\n",
    "exp_params = Addict()\n",
    "# Dict to keep track of tensorboard hparams that we *specifically* want to compare\n",
    "# between runs.\n",
    "compare_hparams = Addict(hparam=Addict(), metric=Addict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.962591Z",
     "iopub.status.busy": "2021-05-27T15:00:01.962380Z",
     "iopub.status.idle": "2021-05-27T15:00:01.966416Z",
     "shell.execute_reply": "2021-05-27T15:00:01.965964Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.962574Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsample_factor = 2\n",
    "# Include b=0 shells and b=1000 shells for DTI fitting.\n",
    "bval_range = (0, 1500)\n",
    "dti_fit_method = \"WLS\"\n",
    "exp_params.update(\n",
    "    {\n",
    "        \"downsample_factor\": downsample_factor,\n",
    "        \"bval_range\": bval_range,\n",
    "        \"dti_fit_method\": dti_fit_method,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.967630Z",
     "iopub.status.busy": "2021-05-27T15:00:01.967400Z",
     "iopub.status.idle": "2021-05-27T15:00:01.976167Z",
     "shell.execute_reply": "2021-05-27T15:00:01.975677Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.967613Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patch parameters\n",
    "batch_size = 32\n",
    "# 6 channels for the 6 DTI components\n",
    "channels = 6\n",
    "\n",
    "# Output patch shapes\n",
    "h_out = 14\n",
    "w_out = 14\n",
    "d_out = 14\n",
    "\n",
    "# This is the factor that determines how over-extended the input patch should be\n",
    "# relative to the size of the full-res patch.\n",
    "# $low_res_patch_dim = \\frac{full_res_patch_dim}{downsample_factor} \\times low_res_sample_extension$\n",
    "# A value of 1 indicates that the input patch dims will be exactly divided by the\n",
    "# downsample factor. A dilation > 1 increases the \"spatial extent\" of the input\n",
    "# patch, providing information outside of the target HR patch.\n",
    "low_res_sample_extension = 1.57\n",
    "\n",
    "# Output shape after shuffling.\n",
    "output_patch_shape = (channels, h_out, w_out, d_out)\n",
    "output_spatial_patch_shape = output_patch_shape[1:]\n",
    "\n",
    "# Input patch parameters\n",
    "h_in = round(h_out / (downsample_factor) * low_res_sample_extension)\n",
    "w_in = round(w_out / (downsample_factor) * low_res_sample_extension)\n",
    "d_in = round(d_out / (downsample_factor) * low_res_sample_extension)\n",
    "input_patch_shape = (channels, h_in, w_in, d_in)\n",
    "input_spatial_patch_shape = input_patch_shape[1:]\n",
    "\n",
    "# Pre-shuffle output patch sizes.\n",
    "unshuffled_channels_out = channels * downsample_factor ** 3\n",
    "# Output before shuffling\n",
    "unshuffled_output_patch_shape = (unshuffled_channels_out, h_in, w_in, d_in)\n",
    "\n",
    "# Patch size in FR-space when accounting for the low-res over-extension/over-sampling\n",
    "# factor.\n",
    "fr_extension_patch_size = tuple(\n",
    "    np.asarray(input_spatial_patch_shape) * downsample_factor\n",
    ")\n",
    "fr_extension_amount = tuple(\n",
    "    np.asarray(fr_extension_patch_size) - np.asarray(output_spatial_patch_shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.979176Z",
     "iopub.status.busy": "2021-05-27T15:00:01.978969Z",
     "iopub.status.idle": "2021-05-27T15:00:01.982981Z",
     "shell.execute_reply": "2021-05-27T15:00:01.982476Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.979158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_params.patch.update(\n",
    "    batch_size=batch_size,\n",
    "    channels=channels,\n",
    "    low_res_sample_extension=low_res_sample_extension,\n",
    "    input_shape=input_patch_shape,\n",
    "    output_shape=output_patch_shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.983961Z",
     "iopub.status.busy": "2021-05-27T15:00:01.983803Z",
     "iopub.status.idle": "2021-05-27T15:00:01.988062Z",
     "shell.execute_reply": "2021-05-27T15:00:01.987441Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.983943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data parameters.\n",
    "num_subject_samples = 10\n",
    "# Should the data be normalized as a pre-processing step?\n",
    "# Can be:\n",
    "# { None, \"channels\" }\n",
    "data_norm_method = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.989108Z",
     "iopub.status.busy": "2021-05-27T15:00:01.988894Z",
     "iopub.status.idle": "2021-05-27T15:00:01.993072Z",
     "shell.execute_reply": "2021-05-27T15:00:01.992476Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.989089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_params.data.update(\n",
    "    num_subject=num_subject_samples, data_norm_method=data_norm_method\n",
    ")\n",
    "\n",
    "compare_hparams.hparam[\"hparam/data_norm\"] = data_norm_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:01.994185Z",
     "iopub.status.busy": "2021-05-27T15:00:01.993961Z",
     "iopub.status.idle": "2021-05-27T15:00:01.999329Z",
     "shell.execute_reply": "2021-05-27T15:00:01.998820Z",
     "shell.execute_reply.started": "2021-05-27T15:00:01.994164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training/testing parameters.\n",
    "# Percentages will be rounded off to the nearest subject, with the test and validation\n",
    "# sizes rounded *up*, ensuring at least 1 subject in each.\n",
    "test_percent = 0.2\n",
    "val_percent = 0.01\n",
    "train_percent = 1 - (test_percent + val_percent)\n",
    "\n",
    "# NN parameters.\n",
    "max_epochs = 50\n",
    "network_norm_method = None\n",
    "train_loss_name = \"SSE\"\n",
    "\n",
    "# Optimization parameters.\n",
    "opt_name = \"Adam\"\n",
    "opt_params = {\"lr\": 10e-3, \"betas\": (0.9, 0.999)}\n",
    "\n",
    "# Spline interpolation baseline parameters.\n",
    "spline_interp_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.000660Z",
     "iopub.status.busy": "2021-05-27T15:00:02.000412Z",
     "iopub.status.idle": "2021-05-27T15:00:02.005300Z",
     "shell.execute_reply": "2021-05-27T15:00:02.004496Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.000639Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of voxels to dilate the mask in FR space.\n",
    "# Dilate to allow the outer-most perimeter to be completely outside the brain, and no\n",
    "# more.\n",
    "dilation_size = math.ceil((max(fr_extension_patch_size) + 1) / 2)\n",
    "# 12 is too much, nearly doubles the volume of the brain mask. Lower it some more...\n",
    "dilation_size = dilation_size // 3\n",
    "# Even 4 is a chunky bit! Just make it 0.\n",
    "dilation_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.006513Z",
     "iopub.status.busy": "2021-05-27T15:00:02.006289Z",
     "iopub.status.idle": "2021-05-27T15:00:02.012789Z",
     "shell.execute_reply": "2021-05-27T15:00:02.012278Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.006493Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_params.update(test_percent=test_percent)\n",
    "exp_params.train.update(\n",
    "    train_percent=train_percent, max_epochs=max_epochs, train_loss_name=train_loss_name\n",
    ")\n",
    "exp_params.nn.update(network_norm_method=network_norm_method)\n",
    "exp_params.opt.update(opt_params)\n",
    "exp_params.opt.name = opt_name\n",
    "exp_params.spline.update(order=spline_interp_order)\n",
    "exp_params.preproc.update(dilation_size=dilation_size)\n",
    "\n",
    "# Save out hyper params that we want to compare between runs.\n",
    "compare_hparams.hparam[\"hparam/network_norm\"] = network_norm_method\n",
    "compare_hparams.hparam[\"hparam/train_loss_type\"] = train_loss_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.014026Z",
     "iopub.status.busy": "2021-05-27T15:00:02.013797Z",
     "iopub.status.idle": "2021-05-27T15:00:02.018763Z",
     "shell.execute_reply": "2021-05-27T15:00:02.018223Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.014006Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(pprint.pformat(exp_params) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.020839Z",
     "iopub.status.busy": "2021-05-27T15:00:02.020132Z",
     "iopub.status.idle": "2021-05-27T15:00:02.029126Z",
     "shell.execute_reply": "2021-05-27T15:00:02.028576Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.020809Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BoxplotStats = collections.namedtuple(\n",
    "    \"BoxplotStats\",\n",
    "    [\"low_outliers\", \"low\", \"q1\", \"median\", \"q3\", \"high\", \"high_outliers\"],\n",
    ")\n",
    "\n",
    "\n",
    "def batch_boxplot_stats(batch):\n",
    "    \"\"\"Quick calculation of a batch of 1D values for showing boxplot stats.\"\"\"\n",
    "    q1, median, q3 = np.quantile(batch, q=[0.25, 0.5, 0.75], axis=1)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - (1.5 * iqr)\n",
    "    high = q3 + (1.5 * iqr)\n",
    "    low_outliers = list()\n",
    "    high_outliers = list()\n",
    "    # Number of outliers may be different for each batch, so it needs to be a list of\n",
    "    # arrays.\n",
    "    for i_batch in range(len(batch)):\n",
    "        batch_i = batch[i_batch]\n",
    "        low_i = low[i_batch]\n",
    "        low_outliers.append(batch_i[np.where(batch_i < low_i)])\n",
    "        high_i = high[i_batch]\n",
    "        high_outliers.append(batch_i[np.where(batch_i > high_i)])\n",
    "\n",
    "    return BoxplotStats(low_outliers, low, q1, median, q3, high, high_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.030355Z",
     "iopub.status.busy": "2021-05-27T15:00:02.030042Z",
     "iopub.status.idle": "2021-05-27T15:00:02.042652Z",
     "shell.execute_reply": "2021-05-27T15:00:02.041559Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.030322Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick check on full volume/batch distributions.\n",
    "\n",
    "\n",
    "def desc_channel_dists(vols, mask=None):\n",
    "    t_vols = torch.as_tensor(vols)\n",
    "\n",
    "    if t_vols.ndim == 4:\n",
    "        t_vols = t_vols[None, ...]\n",
    "\n",
    "    if mask is not None:\n",
    "        t_mask = torch.as_tensor(mask)\n",
    "        if mask.ndim == 4:\n",
    "            mask = mask[0]\n",
    "    else:\n",
    "        t_mask = torch.ones_like(t_vols[0, 0]).bool()\n",
    "\n",
    "    results = \"means | vars\\n\"\n",
    "    for t_vol_i in t_vols:\n",
    "        masked_vol = torch.masked_select(t_vol_i, t_mask).reshape(t_vol_i.shape[0], -1)\n",
    "        mean_i = torch.mean(masked_vol, dim=1)\n",
    "        var_i = torch.var(masked_vol, dim=1)\n",
    "        mvs = [\n",
    "            (f\"{mv[0]} | {mv[1]}\\n\")\n",
    "            for mv in torch.stack([mean_i, var_i], dim=-1).tolist()\n",
    "        ]\n",
    "        results = results + \"\".join(mvs)\n",
    "        results = results + (\"=\" * (len(mvs[-1]) - 1)) + \"\\n\"\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.045048Z",
     "iopub.status.busy": "2021-05-27T15:00:02.044554Z",
     "iopub.status.idle": "2021-05-27T15:00:02.056124Z",
     "shell.execute_reply": "2021-05-27T15:00:02.055616Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.044998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44210/2765378097.py:25: UserWarning:\n",
      "\n",
      "WARNING: Sub-selecting participants for dev and debugging. Subj IDs selected: ['135528', '156637', '894774', '751348', '303624', '397154', '224022', '753251', '810439', '700634']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{135528: PosixPath('/mnt/storage/data/pitn/hcp/135528/T1w/Diffusion'),\n",
       " 156637: PosixPath('/mnt/storage/data/pitn/hcp/156637/T1w/Diffusion'),\n",
       " 224022: PosixPath('/mnt/storage/data/pitn/hcp/224022/T1w/Diffusion'),\n",
       " 303624: PosixPath('/mnt/storage/data/pitn/hcp/303624/T1w/Diffusion'),\n",
       " 397154: PosixPath('/mnt/storage/data/pitn/hcp/397154/T1w/Diffusion'),\n",
       " 700634: PosixPath('/mnt/storage/data/pitn/hcp/700634/T1w/Diffusion'),\n",
       " 751348: PosixPath('/mnt/storage/data/pitn/hcp/751348/T1w/Diffusion'),\n",
       " 753251: PosixPath('/mnt/storage/data/pitn/hcp/753251/T1w/Diffusion'),\n",
       " 810439: PosixPath('/mnt/storage/data/pitn/hcp/810439/T1w/Diffusion'),\n",
       " 894774: PosixPath('/mnt/storage/data/pitn/hcp/894774/T1w/Diffusion')}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: dict = dict()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "selected_ids = random.sample(selected_ids, num_subject_samples)\n",
    "warnings.warn(\n",
    "    \"WARNING: Sub-selecting participants for dev and debugging. \"\n",
    "    + f\"Subj IDs selected: {selected_ids}\"\n",
    ")\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_ids = natsorted(list(map(lambda s: int(s), selected_ids)))\n",
    "\n",
    "for subj_id in selected_ids:\n",
    "    subj_dirs[subj_id] = data_dir / f\"{subj_id}/T1w/Diffusion\"\n",
    "    assert subj_dirs[subj_id].exists()\n",
    "subj_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 90 scans are taken from the $b=1000 \\ s/mm^2$. However, the $b=0$ shells are still required for fitting the diffusion tensors (DTI's), so those will need to be kept, too.\n",
    "\n",
    "To find those, sub-select with the $0 < bvals < 1500$, or roughly thereabout. A b-val of $995$ or $1005$ still counts as a b=1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.057392Z",
     "iopub.status.busy": "2021-05-27T15:00:02.057138Z",
     "iopub.status.idle": "2021-05-27T15:00:02.062176Z",
     "shell.execute_reply": "2021-05-27T15:00:02.061650Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.057373Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.063292Z",
     "iopub.status.busy": "2021-05-27T15:00:02.063131Z",
     "iopub.status.idle": "2021-05-27T15:00:02.075032Z",
     "shell.execute_reply": "2021-05-27T15:00:02.074508Z",
     "shell.execute_reply.started": "2021-05-27T15:00:02.063274Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the transformation pipeline.\n",
    "\n",
    "preproc_transforms = torchio.Compose(\n",
    "    [\n",
    "        torchio.transforms.ToCanonical(include=(\"dwi\", \"brain_mask\"), copy=False),\n",
    "        pitn.transforms.BValSelectionTransform(\n",
    "            bval_range=bval_range,\n",
    "            bval_key=\"bvals\",\n",
    "            bvec_key=\"bvecs\",\n",
    "            include=\"dwi\",\n",
    "            copy=False,\n",
    "        ),\n",
    "        # Pad by the dilation factor, then dilate the mask.\n",
    "        torchio.transforms.Pad(\n",
    "            dilation_size,\n",
    "            padding_mode=0,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.DilateMaskTransform(\n",
    "            dilation_size=dilation_size, include=(\"brain_mask\",), copy=False\n",
    "        ),\n",
    "        # Pad by the amount of extension voxels in FR space, so LR indices cannot\n",
    "        # go out of bounds.\n",
    "        torchio.transforms.Pad(\n",
    "            fr_extension_amount,\n",
    "            padding_mode=0,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        # Ensure FR dims are divisible by the downsample factor, to more reliably\n",
    "        # convert between FR indices and LR indices.\n",
    "        torchio.transforms.EnsureShapeMultiple(\n",
    "            downsample_factor, method=\"pad\", include=(\"dwi\", \"brain_mask\"), copy=False\n",
    "        ),\n",
    "        pitn.transforms.MeanDownsampleTransform(\n",
    "            downsample_factor,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            keep={\"dwi\": \"fr_dwi\", \"brain_mask\": \"fr_brain_mask\"},\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"dwi\": \"lr_dwi\", \"brain_mask\": \"lr_brain_mask\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"fr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"fr_dwi\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"lr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"lr_dwi\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"fr_dwi\": \"fr_dti\", \"lr_dwi\": \"lr_dti\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.ImageToDictTransform(\n",
    "            include=(\"lr_dti\", \"lr_brain_mask\"), copy=False\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T15:00:02.076076Z",
     "iopub.status.busy": "2021-05-27T15:00:02.075913Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain mask volume before dilation: 635172\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/135528/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 135528...Selected\n",
      "Downsampling: Subject 135528...Downsampled\n",
      "Fitting to DTI: Subject 135528......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 135528......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 635172\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 894163\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/156637/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 156637...Selected\n",
      "Downsampling: Subject 156637...Downsampled\n",
      "Fitting to DTI: Subject 156637......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 156637......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 894163\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 652877\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/224022/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 224022...Selected\n",
      "Downsampling: Subject 224022...Downsampled\n",
      "Fitting to DTI: Subject 224022......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 224022......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 652877\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 890811\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/303624/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 303624...Selected\n",
      "Downsampling: Subject 303624...Downsampled\n",
      "Fitting to DTI: Subject 303624......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 303624......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 890811\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 751395\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/397154/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 397154...Selected\n",
      "Downsampling: Subject 397154...Downsampled\n",
      "Fitting to DTI: Subject 397154......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 397154......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 751395\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 944118\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/700634/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 700634...Selected\n",
      "Downsampling: Subject 700634...Downsampled\n",
      "Fitting to DTI: Subject 700634......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 700634......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 944118\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 850200\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/751348/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 751348...Selected\n",
      "Downsampling: Subject 751348...Downsampled\n",
      "Fitting to DTI: Subject 751348......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 751348......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 850200\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 968744\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/753251/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 753251...Selected\n",
      "Downsampling: Subject 753251...Downsampled\n",
      "Fitting to DTI: Subject 753251......DWI shape: torch.Size([72, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 753251......DWI shape: torch.Size([72, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 968744\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 829367\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/810439/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 810439...Selected\n",
      "Downsampling: Subject 810439...Downsampled\n",
      "Fitting to DTI: Subject 810439......DWI shape: torch.Size([72, 162, 190, 162])..."
     ]
    }
   ],
   "source": [
    "# Import all image data into a sequence of `torchio.Subject` objects.\n",
    "subj_data: dict = dict()\n",
    "summary_stats_fmt = \"github\"\n",
    "summary_stats_header = [\n",
    "    \"Subj ID\",\n",
    "    \"Resolution\",\n",
    "    \"Channel Index\",\n",
    "    \"Mean\",\n",
    "    \"Var\",\n",
    "    \"Num Outliers (Lower)\",\n",
    "    \"Low\",\n",
    "    \"25th Percentile\",\n",
    "    \"Median\",\n",
    "    \"75th Percentile\",\n",
    "    \"High\",\n",
    "    \"Num Outliers (Upper)\",\n",
    "]\n",
    "dti_channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "subj_stats = dict()\n",
    "# Dictionary to hold the subject's summary statistics if image-level or global\n",
    "# normalization is used.\n",
    "norm_subj_stats = dict()\n",
    "for k in summary_stats_header:\n",
    "    subj_stats[k] = list()\n",
    "    norm_subj_stats[k] = list()\n",
    "\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "    # Sub-select volumes with only bvals in a certain range. E.x. bvals <= 1100 mm/s^2,\n",
    "    # a.k.a. only the b=0 and b=1000 shells.\n",
    "    bvals = torch.as_tensor(np.loadtxt(subj_dir / \"bvals\").astype(int))\n",
    "    bvecs = torch.as_tensor(np.loadtxt(subj_dir / \"bvecs\"))\n",
    "    # Reshape to be N x 3\n",
    "    if bvecs.shape[0] == 3:\n",
    "        bvecs = bvecs.T\n",
    "\n",
    "    brain_mask = torchio.LabelMap(\n",
    "        subj_dir / \"nodif_brain_mask.nii.gz\",\n",
    "        type=torchio.LABEL,\n",
    "        channels_last=False,\n",
    "    )\n",
    "    brain_mask.set_data(brain_mask.data.bool())\n",
    "    mask_volume = brain_mask[\"data\"].sum()\n",
    "    print(f\"Brain mask volume before dilation: {mask_volume}\")\n",
    "    dwi = torchio.ScalarImage(\n",
    "        subj_dir / \"data.nii.gz\",\n",
    "        type=torchio.INTENSITY,\n",
    "        bvals=bvals,\n",
    "        bvecs=bvecs,\n",
    "        reader=pitn.io.nifti_reader,\n",
    "        channels_last=True,\n",
    "    )\n",
    "\n",
    "    subject_dict = torchio.Subject(subj_id=subj_id, dwi=dwi, brain_mask=brain_mask)\n",
    "    preproced_subj = preproc_transforms(subject_dict)\n",
    "    dilated_mask_volume = preproced_subj[\"fr_brain_mask\"][\"data\"].sum()\n",
    "    print(f\"Dilated mask volume: {dilated_mask_volume}\")\n",
    "    print(f\"Mask volume difference: {dilated_mask_volume - mask_volume}\")\n",
    "    # Subject-and-channel-wise standardization/normalization of both the LR and FR vols.\n",
    "    # Note that LR and FR images should have the same means, but *not* the same variances.\n",
    "    fr_vol = preproced_subj.fr_dti.tensor\n",
    "    fr_mask = preproced_subj.fr_brain_mask.tensor.bool()\n",
    "    masked_fr_vol = torch.masked_select(fr_vol, fr_mask).reshape(fr_vol.shape[0], -1)\n",
    "    fr_channel_means = masked_fr_vol.mean(dim=1)\n",
    "    fr_channel_means = fr_channel_means.reshape(-1, 1, 1, 1)\n",
    "    fr_channel_vars = masked_fr_vol.var(dim=1)\n",
    "    fr_channel_vars = fr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "    # Store subject-and-channel-wise means and vars in order to reverse the normalization\n",
    "    # for the final visualization/output.\n",
    "    preproced_subj[\"fr_means\"] = fr_channel_means.detach().cpu().numpy()\n",
    "    preproced_subj[\"fr_vars\"] = fr_channel_vars.detach().cpu().numpy()\n",
    "\n",
    "    lr_vol = preproced_subj.lr_dti[\"data\"]\n",
    "    lr_mask = preproced_subj.lr_brain_mask[\"data\"].bool()\n",
    "    masked_lr_vol = torch.masked_select(lr_vol, lr_mask).reshape(lr_vol.shape[0], -1)\n",
    "    lr_channel_means = masked_lr_vol.mean(dim=1)\n",
    "    lr_channel_means = lr_channel_means.reshape(-1, 1, 1, 1)\n",
    "    lr_channel_vars = masked_lr_vol.var(dim=1)\n",
    "    lr_channel_vars = lr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "    # Store subject-and-channel-wise means and vars in order to reverse the normalization\n",
    "    # for the final visualization/output.\n",
    "    preproced_subj[\"lr_means\"] = lr_channel_means.detach().cpu().numpy()\n",
    "    preproced_subj[\"lr_vars\"] = lr_channel_vars.detach().cpu().numpy()\n",
    "\n",
    "    # Print and log some statistics of the subject data.\n",
    "    # Add FR stats to the summary table.\n",
    "    fr_vol_stats = batch_boxplot_stats(masked_fr_vol)\n",
    "    subj_stats[\"Subj ID\"].extend(\n",
    "        list(itertools.repeat(subj_id, len(fr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Resolution\"].extend(\n",
    "        list(itertools.repeat(tuple(fr_vol.shape[1:]), len(fr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "    subj_stats[\"Mean\"].extend(fr_channel_means.cpu().flatten().tolist())\n",
    "    subj_stats[\"Var\"].extend(fr_channel_vars.cpu().flatten().tolist())\n",
    "    # Append FR boxplot stats to their corresponding fields. In other words, all columns\n",
    "    # after the var column.\n",
    "    for i, field in enumerate(\n",
    "        summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "    ):\n",
    "        if \"Num\" in field:\n",
    "            subj_stats[field].extend(list(map(len, fr_vol_stats[i])))\n",
    "        else:\n",
    "            subj_stats[field].extend(fr_vol_stats[i])\n",
    "\n",
    "    # Add LR stats to the summary table.\n",
    "    lr_vol_stats = batch_boxplot_stats(masked_lr_vol)\n",
    "    subj_stats[\"Subj ID\"].extend(\n",
    "        list(itertools.repeat(subj_id, len(fr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Resolution\"].extend(\n",
    "        list(itertools.repeat(tuple(lr_vol.shape[1:]), len(lr_vol_stats.median)))\n",
    "    )\n",
    "    subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "    subj_stats[\"Mean\"].extend(lr_channel_means.cpu().flatten().tolist())\n",
    "    subj_stats[\"Var\"].extend(lr_channel_vars.cpu().flatten().tolist())\n",
    "    # Append LR boxplot stats to their corresponding fields. In other words, all columns\n",
    "    # after the var column.\n",
    "    for i, field in enumerate(\n",
    "        summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "    ):\n",
    "        if \"Num\" in field:\n",
    "            subj_stats[field].extend(list(map(len, lr_vol_stats[i])))\n",
    "        else:\n",
    "            subj_stats[field].extend(lr_vol_stats[i])\n",
    "\n",
    "    # Optionally apply image-level or global normalization.\n",
    "    if isinstance(data_norm_method, str) and \"channel\" in data_norm_method.casefold():\n",
    "        # Standardize the volumes.\n",
    "        preproced_subj.fr_dti.set_data(\n",
    "            pitn.data.norm.normalize_dti(fr_vol, fr_channel_means, fr_channel_vars)\n",
    "        )\n",
    "        preproced_subj.lr_dti[\"data\"] = pitn.data.norm.normalize_dti(\n",
    "            lr_vol, lr_channel_means, lr_channel_vars\n",
    "        )\n",
    "\n",
    "        # Re-calculate the same statistics post-normalization.\n",
    "        fr_vol = preproced_subj.fr_dti[\"data\"]\n",
    "        fr_mask = preproced_subj.fr_brain_mask[\"data\"].bool()\n",
    "        masked_fr_vol = torch.masked_select(fr_vol, fr_mask).reshape(\n",
    "            fr_vol.shape[0], -1\n",
    "        )\n",
    "        fr_channel_means = masked_fr_vol.mean(dim=1)\n",
    "        fr_channel_means = fr_channel_means.reshape(-1, 1, 1, 1)\n",
    "        fr_channel_vars = masked_fr_vol.var(dim=1)\n",
    "        fr_channel_vars = fr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "        # Print and log some statistics of the subject data.\n",
    "        # Add FR stats to the summary table.\n",
    "        fr_vol_stats = batch_boxplot_stats(masked_fr_vol)\n",
    "        norm_subj_stats[\"Subj ID\"].extend(\n",
    "            list(itertools.repeat(subj_id, len(fr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Resolution\"].extend(\n",
    "            list(itertools.repeat(tuple(fr_vol.shape[1:]), len(fr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "        norm_subj_stats[\"Mean\"].extend(fr_channel_means.cpu().flatten().tolist())\n",
    "        norm_subj_stats[\"Var\"].extend(fr_channel_vars.cpu().flatten().tolist())\n",
    "        # Append FR boxplot stats to their corresponding fields. In other words, all\n",
    "        # columns after the var column.\n",
    "        for i, field in enumerate(\n",
    "            summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "        ):\n",
    "            if \"Num\" in field:\n",
    "                norm_subj_stats[field].extend(list(map(len, fr_vol_stats[i])))\n",
    "            else:\n",
    "                norm_subj_stats[field].extend(fr_vol_stats[i])\n",
    "\n",
    "        # Add LR stats to the summary table.\n",
    "        lr_vol = preproced_subj.lr_dti[\"data\"]\n",
    "        lr_mask = preproced_subj.lr_brain_mask[\"data\"].bool()\n",
    "        masked_lr_vol = torch.masked_select(lr_vol, lr_mask).reshape(\n",
    "            lr_vol.shape[0], -1\n",
    "        )\n",
    "        lr_channel_means = masked_lr_vol.mean(dim=1)\n",
    "        lr_channel_means = lr_channel_means.reshape(-1, 1, 1, 1)\n",
    "        lr_channel_vars = masked_lr_vol.var(dim=1)\n",
    "        lr_channel_vars = lr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "        lr_vol_stats = batch_boxplot_stats(masked_lr_vol)\n",
    "        norm_subj_stats[\"Subj ID\"].extend(\n",
    "            list(itertools.repeat(subj_id, len(lr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Resolution\"].extend(\n",
    "            list(itertools.repeat(tuple(lr_vol.shape[1:]), len(lr_vol_stats.median)))\n",
    "        )\n",
    "        norm_subj_stats[\"Channel Index\"].extend(dti_channel_names)\n",
    "        norm_subj_stats[\"Mean\"].extend(lr_channel_means.cpu().flatten().tolist())\n",
    "        norm_subj_stats[\"Var\"].extend(lr_channel_vars.cpu().flatten().tolist())\n",
    "        # Append LR boxplot stats to their corresponding fields. In other words, all columns\n",
    "        # after the var column.\n",
    "        for i, field in enumerate(\n",
    "            summary_stats_header[(summary_stats_header.index(\"Var\") + 1) :]\n",
    "        ):\n",
    "            if \"Num\" in field:\n",
    "                norm_subj_stats[field].extend(list(map(len, lr_vol_stats[i])))\n",
    "            else:\n",
    "                norm_subj_stats[field].extend(lr_vol_stats[i])\n",
    "\n",
    "    #     with open(log_txt_file, \"a+\") as f:\n",
    "    #         f.write(f\"Subject ID {subj_id} masked voxel distribution by channel:\\n\")\n",
    "    #         f.write(\n",
    "    #             f\"{desc_channel_dists(preproced_subj['fr_dti']['data'], preproced_subj['fr_brain_mask']['data'].bool())}\\n\"\n",
    "    #         )\n",
    "\n",
    "    subj_data[subj_id] = preproced_subj\n",
    "    print(\"=\" * 20)\n",
    "#     breakpoint()\n",
    "\n",
    "print(\"===Data Loaded & Transformed===\")\n",
    "\n",
    "subj_stats_str = tabulate(\n",
    "    subj_stats, headers=summary_stats_header, tablefmt=summary_stats_fmt\n",
    ")\n",
    "\n",
    "if norm_subj_stats[\"Subj ID\"]:\n",
    "    norm_subj_stats_str = tabulate(\n",
    "        norm_subj_stats, headers=summary_stats_header, tablefmt=summary_stats_fmt\n",
    "    )\n",
    "else:\n",
    "    norm_subj_stats_str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# g = [vol[None, ...] for vol in fr_vol[:, :, :, 100]]\n",
    "# g.extend([vol[None, ...] for vol in subj_data[810439].fr_dti.data[:, :, :, 100]])\n",
    "# g = torchvision.utils.make_grid(g, nrow=6)\n",
    "# plt.figure(dpi=120, figsize=(4, 9))\n",
    "# plt.imshow(np.rot90(g.cpu().numpy()[0]))\n",
    "# plt.colorbar()\n",
    "# # plt.imshow().cpu().numpy())\n",
    "# # subj_data[810439].fr_dti.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Preprocessing transformation pipeline: {str(preproc_transforms)}\\n\")\n",
    "    f.write(f\"Data Summary Statistics, no normalization:\\n {subj_stats_str}\\n\\n\")\n",
    "\n",
    "logger.add_text(\"data_dists\", subj_stats_str)\n",
    "# If the subject data was normalized and those stats were recorded, log those stats.\n",
    "if norm_subj_stats_str:\n",
    "    logger.add_text(\"normalized_data_dists\", norm_subj_stats_str)\n",
    "    with open(log_txt_file, \"a+\") as f:\n",
    "        f.write(\n",
    "            f\"Data Summary Statistics, after normalization:\\n {norm_subj_stats_str}\\n\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Markdown(subj_stats_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(norm_subj_stats_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj_dataset = torchio.SubjectsDataset(list(subj_data.values()), load_getitem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_dataset)\n",
    "num_test_subjs = int(np.ceil(num_subjs * test_percent))\n",
    "num_val_subjs = int(np.ceil(num_subjs * val_percent))\n",
    "num_train_subjs = num_subjs - (num_test_subjs + num_val_subjs)\n",
    "subj_list = subj_dataset.dry_iter()\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Create partial function to collect list of samples and form a tuple of tensors.\n",
    "collate_fn = functools.partial(\n",
    "    pitn.samplers.collate_subj, full_res_key=\"fr_dti\", low_res_key=\"lr_dti\"\n",
    ")\n",
    "\n",
    "test_dataset = torchio.SubjectsDataset(subj_list[:num_test_subjs], load_getitem=False)\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1 and num_train_subjs == 0:\n",
    "    print(\"DEBUG: Only 1 subject with no training subjects, mixing train and test set\")\n",
    "    subj_list = subj_list[:]\n",
    "    num_train_subjs = num_test_subjs\n",
    "else:\n",
    "    subj_list = subj_list[num_test_subjs:]\n",
    "\n",
    "val_dataset = torchio.SubjectsDataset(subj_list[:num_val_subjs], load_getitem=False)\n",
    "subj_list = subj_list[num_val_subjs:]\n",
    "\n",
    "train_dataset = torchio.SubjectsDataset(subj_list, load_getitem=False)\n",
    "\n",
    "# Training patch sampler, random across all patches of all volumes.\n",
    "train_sampler = pitn.samplers.MultiresSampler(\n",
    "    source_img_key=\"fr_dti\",\n",
    "    low_res_key=\"lr_dti\",\n",
    "    downsample_factor=downsample_factor,\n",
    "    label_name=\"fr_brain_mask\",\n",
    "    source_spatial_patch_size=output_spatial_patch_shape,\n",
    "    low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "    label_probabilities={0: 0, 1: 1},\n",
    ")\n",
    "\n",
    "patches_per_subj = 8000\n",
    "# Hold enough for 2 epochs at a time.\n",
    "queue_max_length = patches_per_subj * num_train_subjs * 2\n",
    "\n",
    "# Set up a torchio.Queue to act as a sampler proxy for the torch DataLoader\n",
    "train_queue = torchio.Queue(\n",
    "    train_dataset,\n",
    "    max_length=queue_max_length,\n",
    "    samples_per_volume=patches_per_subj,\n",
    "    sampler=train_sampler,\n",
    "    shuffle_patches=True,\n",
    "    shuffle_subjects=True,\n",
    "    num_workers=6,\n",
    "    #     verbose=True,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_queue,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Set up validation and testing objects.\n",
    "# Calculate the patch overlap needed for ~50% of the patch volume overlapping (which is\n",
    "# not the same as dividing each dimension by 2).\n",
    "input_vol_half_overlap = int(\n",
    "    np.floor(np.power(np.prod(input_spatial_patch_shape) / 2, 1 / 3))\n",
    ")\n",
    "# torchio requires an even-numbered overlap.\n",
    "if input_vol_half_overlap % 2 == 1:\n",
    "    input_vol_half_overlap += 1\n",
    "input_vol_half_overlap = np.repeat(input_vol_half_overlap, 3)\n",
    "\n",
    "# Repeat for the output.\n",
    "output_vol_half_overlap = np.floor(\n",
    "    np.power(np.prod(output_spatial_patch_shape) / 2, 1 / 3)\n",
    ").astype(int)\n",
    "# torchio requires an even-numbered overlap.\n",
    "if output_vol_half_overlap % 2 == 1:\n",
    "    output_vol_half_overlap += 1\n",
    "output_vol_half_overlap = np.repeat(output_vol_half_overlap, 3)\n",
    "\n",
    "# Validation samplers\n",
    "# No backward pass is performed here, so we can increase the batch size to lower\n",
    "# inference time.\n",
    "tv_batch_size = 128\n",
    "val_samplers = list()\n",
    "for subj in val_dataset.dry_iter():\n",
    "    val_samplers.append(\n",
    "        pitn.samplers.MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor=downsample_factor,\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            patch_overlap=0,\n",
    "            # Due to the oversampling in the LR->HR patch mapping, a mask is necessary\n",
    "            # to avoid sampling from out of bounds.\n",
    "            source_mask=subj[\"fr_brain_mask\"].tensor[0].bool(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Alter the collate function to include locations in batches for visualization of sub-\n",
    "# regions during validation.\n",
    "val_collate_locs = functools.partial(\n",
    "    pitn.viz.collate_locations, full_res_key=\"fr_dti\", low_res_key=\"lr_dti\"\n",
    ")\n",
    "concat_val_dataset = torch.utils.data.ConcatDataset(val_samplers)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    concat_val_dataset,\n",
    "    batch_size=tv_batch_size,\n",
    "    collate_fn=val_collate_locs,\n",
    "    pin_memory=True,\n",
    "    num_workers=3,\n",
    ")\n",
    "\n",
    "# Test samplers\n",
    "test_samplers = list()\n",
    "for subj in test_dataset.dry_iter():\n",
    "    test_samplers.append(\n",
    "        pitn.samplers.MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor=downsample_factor,\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            patch_overlap=output_vol_half_overlap,\n",
    "            # Due to the oversampling in the LR->HR patch mapping, a mask is necessary\n",
    "            # to avoid sampling from out of bounds.\n",
    "            source_mask=subj[\"fr_brain_mask\"].tensor[0].bool(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "concat_test_dataset = torch.utils.data.ConcatDataset(test_samplers)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    concat_test_dataset,\n",
    "    batch_size=tv_batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=6,\n",
    ")\n",
    "\n",
    "print(\"Training subject ID(s): \", [s.subj_id for s in train_dataset.dry_iter()])\n",
    "print(\"Validation subject ID(s): \", [s.subj_id for s in val_dataset.dry_iter()])\n",
    "print(\"Test subject ID(s): \", [s.subj_id for s in test_dataset.dry_iter()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Training Set Subjects: {[s.subj_id for s in train_dataset.dry_iter()]}\\n\")\n",
    "    f.write(f\"Validation Set Subjects: {[s.subj_id for s in val_dataset.dry_iter()]}\\n\")\n",
    "    f.write(f\"Test Set Subjects: {[s.subj_id for s in test_dataset.dry_iter()]}\\n\")\n",
    "\n",
    "logger.add_text(\"train_subjs\", str([s.subj_id for s in train_dataset.dry_iter()]))\n",
    "logger.add_text(\"val_subjs\", str([s.subj_id for s in val_dataset.dry_iter()]))\n",
    "logger.add_text(\"test_subjs\", str([s.subj_id for s in test_dataset.dry_iter()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "debug_prob_threshold = -0.0005\n",
    "\n",
    "\n",
    "class DIQTSystem(pl.LightningModule):\n",
    "\n",
    "    loss_methods = {\n",
    "        \"MSE\".casefold(): torch.nn.MSELoss(reduction=\"mean\"),\n",
    "        \"SSE\".casefold(): torch.nn.MSELoss(reduction=\"sum\"),\n",
    "        \"RMSE\".casefold(): lambda y_hat, y: torch.sqrt(\n",
    "            F.mse_loss(y_hat, y, reduction=\"mean\")\n",
    "        ),\n",
    "        \"L1\".casefold(): torch.nn.L1Loss(reduction=\"mean\"),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        downsample_factor,\n",
    "        train_loss_method: str,\n",
    "        opt_params: dict,\n",
    "        norm_method=None,\n",
    "        baseline_spline_order=None,\n",
    "        val_viz_bboxes=None,\n",
    "        val_patch_overlap=(0, 0, 0),\n",
    "        val_viz_every_n_epochs=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = channels\n",
    "        self._downsample_factor = downsample_factor\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = pitn.nn.models.ThreeConv(\n",
    "            self._channels, self._downsample_factor, norm_method=norm_method\n",
    "        )\n",
    "        self._norm_eps = 10e-10\n",
    "        ## Training parameters\n",
    "        self.opt_params = opt_params\n",
    "\n",
    "        try:\n",
    "            self._loss_fn = self.loss_methods[train_loss_method.casefold()]\n",
    "        except (AttributeError, KeyError) as e:\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise e\n",
    "        # Sub-regions of the volume that should be logged in validation.\n",
    "        if val_viz_bboxes is None:\n",
    "            self.val_bboxes = torch.zeros(0, 6)\n",
    "        else:\n",
    "            self.val_bboxes = val_viz_bboxes\n",
    "        self.val_patch_overlap = val_patch_overlap\n",
    "\n",
    "        if baseline_spline_order is not None:\n",
    "\n",
    "            def spline_pred_batch(batch: torch.Tensor, spline_model):\n",
    "                nd_batch = batch.detach().cpu().numpy()\n",
    "                output = list()\n",
    "                for b in nd_batch:\n",
    "                    output.append(spline_model(b))\n",
    "\n",
    "                output = torch.as_tensor(output).to(batch)\n",
    "                return output\n",
    "\n",
    "            self._spline_model = functools.partial(\n",
    "                scipy.ndimage.zoom,\n",
    "                zoom=(1, downsample_factor, downsample_factor, downsample_factor),\n",
    "                order=baseline_spline_order,\n",
    "            )\n",
    "\n",
    "            self.spline_comparison = functools.partial(\n",
    "                spline_pred_batch, spline_model=self._spline_model\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.spline_comparison = None\n",
    "            self._spline_model = None\n",
    "\n",
    "        self.val_vmin = [\n",
    "            None,\n",
    "        ] * self.val_bboxes.shape[0]\n",
    "        self.val_vmax = [\n",
    "            None,\n",
    "        ] * self.val_bboxes.shape[0]\n",
    "        self.val_viz_every_n_epochs = val_viz_every_n_epochs\n",
    "        self._last_val_viz_epoch = -1\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = {\"train_loss\": list(), \"val_loss\": list(), \"test_loss\": list(), \"spline_loss\": list()}\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_with_layer(norm_layer, y):\n",
    "\n",
    "        if norm_layer is not None:\n",
    "            if not norm_layer.track_running_stats:\n",
    "                y = norm_layer(y)\n",
    "            else:\n",
    "                if isinstance(norm_layer, torch.nn.InstanceNorm3d):\n",
    "                    y = F.instance_norm(\n",
    "                        y,\n",
    "                        eps=norm_layer.eps,\n",
    "                    )\n",
    "                elif isinstance(norm_layer, torch.nn.BatchNorm3d):\n",
    "                    y = F.batch_norm(\n",
    "                        y,\n",
    "                        eps=norm_layer.eps,\n",
    "                    )\n",
    "\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = F.instance_norm(x, eps=self._norm_eps)\n",
    "        y = F.instance_norm(y, eps=self._norm_eps)\n",
    "        # We need both prediction and ground truth to be a standard normal distribution\n",
    "        # for a fair calculation of the loss.\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "        #         if self.net.norm is not None:\n",
    "        #             y = self.normalize_with_layer(self.net.norm, y)\n",
    "\n",
    "        loss = self._loss_fn(y_pred, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # The validation samples also include the voxel coordinates within the volume(s).\n",
    "        x, y, y_locs = batch\n",
    "\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "\n",
    "        val_loss = torch.sqrt(F.mse_loss(y_pred, y, reduction=\"mean\"))\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.plain_log[\"val_loss\"].append(float(val_loss.cpu()))\n",
    "\n",
    "        bbox_patches = list()\n",
    "        y_locs = y_locs.detach().cpu()\n",
    "        for bbox in self.val_bboxes:\n",
    "\n",
    "            bbox = bbox.detach().cpu()\n",
    "            locs_to_keep = torch.prod(\n",
    "                y_locs[:, :3] >= bbox[None, :3], dim=1\n",
    "            ) & torch.prod(y_locs[:, 3:] <= bbox[None, 3:], dim=1)\n",
    "            locs_to_keep = locs_to_keep.to(y_pred).bool()\n",
    "            bbox_patches.append(\n",
    "                {\n",
    "                    \"full_res\": y[locs_to_keep].detach().cpu(),\n",
    "                    \"pred\": y_pred[locs_to_keep].detach().cpu(),\n",
    "                    \"locations\": y_locs[locs_to_keep].detach().cpu(),\n",
    "                }\n",
    "            )\n",
    "            assert (bbox_patches[-1][\"locations\"] >= 0).all()\n",
    "        return {\"loss\": val_loss, \"bbox\": bbox_patches}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        if (\n",
    "            self.current_epoch % self.val_viz_every_n_epochs == 0\n",
    "            or (self.current_epoch - self._last_val_viz_epoch)\n",
    "            > self.val_viz_every_n_epochs\n",
    "        ):\n",
    "\n",
    "            self._last_val_viz_epoch = self.current_epoch\n",
    "            batched_bbox_patches = [b[\"bbox\"] for b in outputs]\n",
    "\n",
    "            sub_regions = list()\n",
    "            for (\n",
    "                i,\n",
    "                bbox,\n",
    "            ) in enumerate(self.val_bboxes):\n",
    "\n",
    "                bbox = bbox.detach().cpu()\n",
    "                bbox_offset = bbox[:3]\n",
    "\n",
    "                fr_patches = torch.cat(\n",
    "                    [batch[i][\"full_res\"] for batch in batched_bbox_patches]\n",
    "                )\n",
    "\n",
    "                pred_patches = torch.cat(\n",
    "                    [batch[i][\"pred\"] for batch in batched_bbox_patches]\n",
    "                )\n",
    "                locs = torch.cat(\n",
    "                    [batch[i][\"locations\"] for batch in batched_bbox_patches]\n",
    "                )\n",
    "\n",
    "                fr_agg = pitn.viz.SubGridAggregator(\n",
    "                    bbox[3:] - bbox[:3],\n",
    "                    location_offset=bbox_offset,\n",
    "                    patch_overlap=self.val_patch_overlap,\n",
    "                )\n",
    "                fr_agg.add_batch(fr_patches, locs)\n",
    "                fr_sub_vol = fr_agg.get_output_tensor()\n",
    "\n",
    "                pred_agg = pitn.viz.SubGridAggregator(\n",
    "                    bbox[3:] - bbox[:3],\n",
    "                    location_offset=bbox_offset,\n",
    "                    patch_overlap=self.val_patch_overlap,\n",
    "                )\n",
    "                pred_agg.add_batch(pred_patches, locs)\n",
    "                pred_sub_vol = pred_agg.get_output_tensor()\n",
    "\n",
    "                sub_regions.append({\"full_res\": fr_sub_vol, \"pred\": pred_sub_vol})\n",
    "\n",
    "            for i, reg in enumerate(sub_regions):\n",
    "                # Slice into full volume and just grab a B x C x H x W slice.\n",
    "                slice_idx = (\n",
    "                    slice(None),\n",
    "                    None,\n",
    "                    slice(None),\n",
    "                    reg[\"full_res\"].shape[1] // 2,\n",
    "                    slice(None),\n",
    "                )\n",
    "\n",
    "                row_fr = torchvision.utils.make_grid(\n",
    "                    reg[\"full_res\"][slice_idx], pad_value=4, nrow=1\n",
    "                )\n",
    "                row_pred = torchvision.utils.make_grid(\n",
    "                    reg[\"pred\"][slice_idx], pad_value=4, nrow=1\n",
    "                )\n",
    "                # Calculate voxel-wise root squared-error\n",
    "                rse = torch.sqrt(\n",
    "                    F.mse_loss(reg[\"pred\"], reg[\"full_res\"], reduction=\"none\")\n",
    "                )\n",
    "                row_rse = torchvision.utils.make_grid(\n",
    "                    rse[slice_idx], pad_value=4, nrow=1\n",
    "                )\n",
    "\n",
    "                reg_grid = torchvision.utils.make_grid(\n",
    "                    [row_fr, row_pred, row_rse], nrow=3, pad_value=4\n",
    "                )[0]\n",
    "\n",
    "                fig = plt.figure(figsize=(8, 4.5), dpi=110, clear=True)\n",
    "\n",
    "                vmin = self.val_vmin[i]\n",
    "                vmax = self.val_vmax[i]\n",
    "                # Calculate vmin and vmax only *once* for the entire training run, per bbox.\n",
    "                if vmin is None:\n",
    "                    vmin = np.quantile(\n",
    "                        reg[\"full_res\"][slice_idx].cpu().numpy().flatten(), 0.05\n",
    "                    )\n",
    "                    self.val_vmin[i] = vmin\n",
    "                if vmax is None:\n",
    "                    vmax = np.quantile(\n",
    "                        reg[\"full_res\"][slice_idx].cpu().numpy().flatten(), 0.95\n",
    "                    )\n",
    "                    self.val_vmax[i] = vmax\n",
    "\n",
    "                plt.imshow(\n",
    "                    np.rot90(reg_grid.cpu().numpy(), axes=(-2, -1)),\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax,\n",
    "                    cmap=\"jet\",\n",
    "                )\n",
    "                plt.xticks([], [])\n",
    "                plt.yticks([], [])\n",
    "                plt.colorbar(location=\"bottom\")\n",
    "                self.logger.experiment.add_figure(\n",
    "                    f\"val_samples_{i}\", fig, self.global_step\n",
    "                )\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        # We can't normalize the outputs or ground truth because it would change\n",
    "        # our units out of $mm^2/s$.\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "        #         if self.net.norm is not None:\n",
    "        #             y = self.normalize_with_layer(self.net.norm, y)\n",
    "\n",
    "        test_loss = torch.sqrt(F.mse_loss(y_pred, y, reduction=\"mean\"))\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        self.plain_log[\"test_loss\"].append(float(test_loss.cpu()))\n",
    "\n",
    "        if self.spline_comparison is not None:\n",
    "            y_pred_spline = self.spline_comparison(x)\n",
    "            spline_loss = torch.sqrt(F.mse_loss(y_pred_spline, y, reduction=\"mean\"))\n",
    "            self.log(\"test/spline\", spline_loss)\n",
    "            self.plain_log['spline_loss'].append(float(spline_loss.cpu()))\n",
    "\n",
    "        return test_loss\n",
    "\n",
    "    def viz_step(self, x, norm_net_output=True, norm_output=True):\n",
    "        \"\"\"Step for running inference for the purpose of a visualization.\n",
    "\n",
    "        Mainly deals with normalization.\"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.net.training:\n",
    "                was_training = True\n",
    "            else:\n",
    "                was_training = False\n",
    "\n",
    "            self.net.eval()\n",
    "\n",
    "            y_pred = self.net(x, norm_output=norm_net_output)\n",
    "            if norm_output:\n",
    "                if isinstance(self.net.norm, torch.nn.InstanceNorm3d):\n",
    "                    target_mean = torch.mean(x, dim=(2, 3, 4), keepdim=True)\n",
    "                    target_var = torch.var(x, dim=(2, 3, 4), keepdim=True)\n",
    "                    eps = self.net.norm.eps\n",
    "\n",
    "                elif isinstance(self.net.norm, torch.nn.BatchNorm3d):\n",
    "                    target_mean = torch.mean(x, dim=(0, 2, 3, 4), keepdim=True)\n",
    "                    target_var = torch.var(x, dim=(0, 2, 3, 4), keepdim=True)\n",
    "                    eps = self.net.norm.eps\n",
    "\n",
    "                y_pred = pitn.data.norm.denormalize_batch(\n",
    "                    y_pred, target_mean, target_var, eps=eps\n",
    "                )\n",
    "\n",
    "            if was_training:\n",
    "                self.net.train()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), **self.opt_params)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bbox coordinates for visualizing validation aggregate patches.\n",
    "bbox_coords = list()\n",
    "region_size = torch.as_tensor(output_spatial_patch_shape) * 3\n",
    "vol_shape = torch.as_tensor(val_dataset.dry_iter()[0][\"fr_dti\"].shape[1:])\n",
    "possible_bbox_ini = [\n",
    "    torch.arange(0, vol_shape[0], output_spatial_patch_shape[0]),\n",
    "    torch.arange(0, vol_shape[1], output_spatial_patch_shape[1]),\n",
    "    torch.arange(0, vol_shape[2], output_spatial_patch_shape[2]),\n",
    "]\n",
    "\n",
    "# Create bbox that spans roughly the center of the volume.\n",
    "bbox_idx_ini = list()\n",
    "for possible_bbox_part in possible_bbox_ini:\n",
    "    num_parts = len(possible_bbox_part)\n",
    "    bbox_idx_ini.append(possible_bbox_part[round(num_parts * 0.4)])\n",
    "bbox_idx_ini = torch.as_tensor(bbox_idx_ini)\n",
    "\n",
    "bbox_coord = torch.cat([bbox_idx_ini, bbox_idx_ini + region_size])\n",
    "bbox_coords.append(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bbox that covers an edge.\n",
    "vol_mask = val_dataset.dry_iter()[0][\"fr_brain_mask\"].tensor[0]\n",
    "bbox_mask_coverage = list()\n",
    "possible_bbox_coords_ini = list(itertools.product(*possible_bbox_ini))\n",
    "for bbox_w, bbox_h, bbox_d in possible_bbox_coords_ini:\n",
    "    bbox_start = (bbox_w, bbox_h, bbox_d)\n",
    "    bbox_end = (\n",
    "        bbox_start[0] + output_spatial_patch_shape[0],\n",
    "        bbox_start[1] + output_spatial_patch_shape[1],\n",
    "        bbox_start[2] + output_spatial_patch_shape[2],\n",
    "    )\n",
    "    patch = vol_mask[\n",
    "        bbox_start[0] : bbox_end[0],\n",
    "        bbox_start[1] : bbox_end[1],\n",
    "        bbox_start[2] : bbox_end[2],\n",
    "    ]\n",
    "    bbox_mask_coverage.append(patch.sum().item())\n",
    "\n",
    "# Now search all coordinates' mask coverages for the one closest to a 50% coverage in each\n",
    "# dimension.\n",
    "patch_vol = np.prod(output_spatial_patch_shape)\n",
    "target_mask_vol = patch_vol // (2 ** 3)\n",
    "\n",
    "bbox_coord_idx = np.argmin(np.abs(np.asarray(bbox_mask_coverage) - patch_vol))\n",
    "bbox_idx_ini = torch.tensor(possible_bbox_coords_ini[bbox_coord_idx])\n",
    "bbox_coord = torch.cat([bbox_idx_ini, bbox_idx_ini + region_size])\n",
    "bbox_coords.append(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bbox_coords = torch.stack(bbox_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bbox_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "model = DIQTSystem(\n",
    "    channels=channels,\n",
    "    downsample_factor=downsample_factor,\n",
    "    norm_method=network_norm_method,\n",
    "    train_loss_method=train_loss_name,\n",
    "    opt_params=opt_params,\n",
    "    baseline_spline_order=spline_interp_order,\n",
    "    val_viz_bboxes=bbox_coords,\n",
    "    val_patch_overlap=val_samplers[0].patch_overlap,\n",
    "    val_viz_every_n_epochs=5,\n",
    ")\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Model overview: {model}\\n\")\n",
    "\n",
    "# Create trainer object. Note: `automatic_optimization` needs to be set to `False` when\n",
    "# manually performing backprop. See\n",
    "# <https://colab.research.google.com/drive/1nGtvBFirIvtNQdppe2xBes6aJnZMjvl8?usp=sharing>\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger=pl_logger,\n",
    "    log_every_n_steps=50,\n",
    "    check_val_every_n_epoch=3,\n",
    "    progress_bar_refresh_rate=max_epochs // 4,\n",
    "    terminate_on_nan=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + train_loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss_name = \"RMSE\"\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Test loss function: {test_loss_name}\\n\")\n",
    "\n",
    "row_iter = enumerate(model.plain_log[\"test_loss\"])\n",
    "test_loss_tabular = \"\".join([f\"{batch_idx}, {loss}\\n\" for batch_idx, loss in row_iter])\n",
    "\n",
    "with open(test_loss_log_file, \"a+\") as f:\n",
    "    f.write(\"batch_idx, loss\\n\")\n",
    "    f.write(test_loss_tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cubic Spline Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if spline_interp_order is not None:\n",
    "    cspline_loss_mean = np.asarray(model.plain_log['spline_loss']).mean()\n",
    "else:\n",
    "    cspline_loss_mean = np.nan\n",
    "# cubic_spline_test_log = list()\n",
    "\n",
    "# for subj in test_dataset.dry_iter():\n",
    "#     print(\"---\")\n",
    "#     target_shape = subj[\"fr_dti\"][\"data\"].cpu().numpy().shape\n",
    "#     interp_cubic_spline = scipy.ndimage.zoom(\n",
    "#         subj[\"lr_dti\"][\"data\"].cpu().numpy(),\n",
    "#         zoom=(1, downsample_factor, downsample_factor, downsample_factor),\n",
    "#         order=spline_interp_order,\n",
    "#     )\n",
    "#     if interp_cubic_spline.shape != target_shape:\n",
    "#         # Crop off the end few voxels to account for the lack of padding used in full-\n",
    "#         # volume inference.\n",
    "#         interp_cubic_spline = interp_cubic_spline[\n",
    "#             :, : target_shape[1], : target_shape[2], : target_shape[3]\n",
    "#         ]\n",
    "#     print(f\"Subj {subj['subj_id']} done\")\n",
    "\n",
    "#     cubic_spline_test_log.append(interp_cubic_spline)\n",
    "\n",
    "# cspline_loss = list()\n",
    "\n",
    "# # Calculate spline loss for test images.\n",
    "# for subj, cspline_pred in zip(test_dataset.dry_iter(), cubic_spline_test_log):\n",
    "#     # De-normalize the ground truth volume.\n",
    "#     gt = subj[\"fr_dti\"][\"data\"]\n",
    "#     gt = gt.detach().cpu().numpy()\n",
    "#     gt = (gt * (subj[\"fr_vars\"] + 1 ** (-10))) + subj[\"fr_means\"]\n",
    "#     # De-normalize the spline prediction to match the channel-wise distribution of the\n",
    "#     # ground truth.\n",
    "#     cspline_pred = (cspline_pred * (subj[\"fr_vars\"] + 10 ** (-10))) + subj[\"fr_means\"]\n",
    "#     # Calculate the RMSE of just the values found in the mask.\n",
    "#     se = (gt - cspline_pred) ** 2\n",
    "#     se = se[:, subj[\"fr_brain_mask\"][\"data\"].bool().cpu().numpy()[0]]\n",
    "#     loss = np.sqrt(se.mean())\n",
    "#     cspline_loss.append(loss)\n",
    "\n",
    "# # Find the grand mean of the spline RMSE's\n",
    "# cspline_loss_mean = np.mean(cspline_loss)\n",
    "# print(cspline_loss_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = True\n",
    "\n",
    "sns.histplot(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]),\n",
    "    kde=True,\n",
    "    stat=\"probability\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    label=\"Current Model\",\n",
    "    legend=False,\n",
    ")\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw an entire other plot, invisibly, to have another y-axis.\n",
    "ax_count = ax_prob.twinx()\n",
    "sns.histplot(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]),\n",
    "    alpha=0,\n",
    "    ax=ax_count,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    zorder=1.1,\n",
    ")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"--\", \"alpha\": 0.8, \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Our spline mean performance.\n",
    "plt.axvline(\n",
    "    cspline_loss_mean,\n",
    "    label=\"(Ours) C-spline Mean\",\n",
    "    color=\"black\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Tanno, et. al., 2021 model comparisons.\n",
    "# Taken from Table 2, HCP exterior.\n",
    "plt.axvline(\n",
    "    31.738e-4,\n",
    "    label=\"(Tanno etal, 2021) C-spline Mean\",\n",
    "    color=\"red\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    23.139e-4,\n",
    "    label=\"(Tanno etal, 2021) RF\",\n",
    "    color=\"orange\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.609e-4,\n",
    "    label=\"(Tanno etal, 2021) ESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.412e-4,\n",
    "    label=\"(Tanno etal, 2021) Best\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    12.78e-4,\n",
    "    label=\"(Blumberg etal, 2018) Best\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(f\"Test Loss Histogram with Test Metric {test_loss_name}\")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.add_histogram(\n",
    "    \"test/rmse_dist\", np.asarray(model.plain_log[\"test_loss\"]), bins=\"doane\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save out metrics and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.asarray(model.plain_log[\"test_loss\"]).max())\n",
    "print(np.asarray(model.plain_log[\"test_loss\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_hparams.metric[\"hparam/rmse\"] = np.asarray(model.plain_log[\"test_loss\"]).mean()\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\n",
    "        f\"Mean RMSE Testing Value: {np.asarray(model.plain_log['test_loss']).mean()}\\n\"\n",
    "    )\n",
    "    f.write(f\"Mean RMSE Spline Value: {cspline_loss_mean}\\n\")\n",
    "\n",
    "# logger.add_hparams(compare_hparams.hparam.to_dict(), compare_hparams.metric.to_dict())\n",
    "logger.add_scalar(\"metric/rmse\", np.asarray(model.plain_log[\"test_loss\"]).mean())\n",
    "logger.add_scalar('metric/spline', cspline_loss_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volume of full-res ground truth, low-res downsample, and high-res\n",
    "# inferences.\n",
    "@dataclass\n",
    "class SubjResult:\n",
    "    subj_id: int\n",
    "    full_res: torch.Tensor\n",
    "    low_res: torch.Tensor\n",
    "    full_res_predicted: torch.Tensor\n",
    "    full_res_cubic_spline: np.ndarray\n",
    "\n",
    "\n",
    "test_vol_results = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj in test_dataset.dry_iter():\n",
    "        print(f\"Starting subject {subj.subj_id}\")\n",
    "        # Create a grid sampler for this subject.\n",
    "        #         pdb.set_trace()\n",
    "        subj_sampler = pitn.samplers.MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor=downsample_factor,\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            source_mask=subj[\"fr_brain_mask\"].tensor,\n",
    "            patch_overlap=0,\n",
    "        )\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            subj_sampler, batch_size=256, pin_memory=True\n",
    "        )\n",
    "        aggregator = torchio.GridAggregator(subj_sampler)\n",
    "        spline_agg = torchio.GridAggregator(subj_sampler)\n",
    "\n",
    "        # Iterate over all batches of patches.\n",
    "        for batch in loader:\n",
    "\n",
    "            x = batch[\"lr_dti\"][\"data\"]\n",
    "            # Locations are in reference to the full-res ground truth.\n",
    "            locations = batch[\"location\"]\n",
    "            predictions = (\n",
    "                model.viz_step(\n",
    "                    x.to(model.device), norm_net_output=False, norm_output=False\n",
    "                )\n",
    "                .detach()\n",
    "                .cpu()\n",
    "            )\n",
    "\n",
    "            aggregator.add_batch(predictions, locations)\n",
    "\n",
    "            spline_predictions = model.spline_comparison(x)\n",
    "            spline_agg.add_batch(spline_predictions, locations)\n",
    "\n",
    "        print(\"\\tFinished network predictions\")\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "\n",
    "        # Calculate cubic spline as a baseline.\n",
    "        full_res_cubic_spline = spline_agg.get_output_tensor()\n",
    "\n",
    "        fr_vol = subj[\"fr_dti\"][\"data\"]\n",
    "        lr_vol = subj[\"lr_dti\"][\"data\"]\n",
    "\n",
    "        full_res_predicted = aggregator.get_output_tensor()\n",
    "\n",
    "        if data_norm_method is not None and \"channel\" in data_norm_method.casefold():\n",
    "\n",
    "            fr_means = torch.as_tensor(subj[\"fr_means\"]).to(fr_vol)\n",
    "            fr_vars = torch.as_tensor(subj[\"fr_vars\"]).to(fr_vol)\n",
    "            fr_vol = pitn.data.norm.denormalize_dti(fr_vol, fr_means, fr_vars)\n",
    "            lr_means = torch.as_tensor(subj[\"lr_means\"]).to(lr_vol)\n",
    "            lr_vars = torch.as_tensor(subj[\"lr_vars\"]).to(lr_vol)\n",
    "            lr_vol = pitn.data.norm.denormalize_dti(lr_vol, lr_means, lr_vars)\n",
    "\n",
    "            full_res_cubic_spline = pitn.data.norm.denormalize_dti(\n",
    "                full_res_cubic_spline, fr_means, fr_vars\n",
    "            )\n",
    "            full_res_predicted = pitn.data.norm.denormalize_dti(\n",
    "                full_res_predicted, fr_means, fr_vars\n",
    "            )\n",
    "        # Zero-out all voxels outside the mask.\n",
    "        fr_mask = subj[\"fr_brain_mask\"][\"data\"]\n",
    "        full_res_cubic_spline = full_res_cubic_spline * fr_mask.to(\n",
    "            full_res_cubic_spline\n",
    "        )\n",
    "        fr_vol = fr_vol * fr_mask.to(fr_vol)\n",
    "        full_res_predicted = full_res_predicted * fr_mask.to(full_res_predicted)\n",
    "        lr_vol = lr_vol * subj[\"lr_brain_mask\"][\"data\"].to(lr_vol)\n",
    "\n",
    "        subj_result = SubjResult(\n",
    "            subj_id=subj[\"subj_id\"],\n",
    "            full_res=fr_vol,\n",
    "            low_res=lr_vol,\n",
    "            full_res_predicted=full_res_predicted,\n",
    "            full_res_cubic_spline=full_res_cubic_spline,\n",
    "        )\n",
    "\n",
    "        test_vol_results.append(subj_result)\n",
    "        print(f\"Finished subject {subj.subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis_subj_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for prediction.\n",
    "tensor_key = \"full_res_predicted\"\n",
    "pred_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "pred_dir_map = pred_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for cubic spline interpolation.\n",
    "tensor_key = \"full_res_cubic_spline\"\n",
    "cspline_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "cspline_dir_map = cspline_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map.\n",
    "tensor_key = \"full_res\"\n",
    "fr_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "fr_dir_map = fr_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for low-res input.\n",
    "tensor_key = \"low_res\"\n",
    "lr_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "lr_dir_map = lr_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_idx = (slice(None, None, None), slice(None, None, None), 100)\n",
    "low_res_slice_idx = tuple(s // 2 if isinstance(s, int) else s for s in slice_idx)\n",
    "print(slice_idx)\n",
    "print(low_res_slice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(pred_dir_map[slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"pred_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(cspline_dir_map[slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"cubic_spline_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(fr_dir_map[slice_idx]))\n",
    "# plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"ground_truth_dir_map_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(lr_dir_map[low_res_slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"low_res_map_sample.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"jet\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error between FR and prediction.\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(np.rot90(dti[j_col]), cmap=cmap, interpolation=None)\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Per-Image Normalization\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_per_img_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"jet\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95)\n",
    "min_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05)\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dti,\n",
    "            vmax=max_dti,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "color_norm = mpl.colors.Normalize(vmin=min_dti, vmax=max_dti)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap),\n",
    "    ax=axs,\n",
    "    location=\"right\",\n",
    "    fraction=0.1,\n",
    "    pad=0.03,\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Normalized over All Images\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_global_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel-Wise Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, low-res input, and root squared error\n",
    "# Normalize by index in the DTI coefficients.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "\n",
    "channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"coolwarm\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "max_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95, axis=1\n",
    ")\n",
    "min_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05, axis=1\n",
    ")\n",
    "\n",
    "max_dtis = np.max(np.abs([max_dtis, min_dtis]), axis=0)\n",
    "min_dtis = -1 * max_dtis\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "    axs_cols = list()\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dtis[j_col],\n",
    "            vmax=max_dtis[j_col],\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        axs_cols.append(ax)\n",
    "\n",
    "    axs.append(axs_cols)\n",
    "\n",
    "# Place colorbars on each column.\n",
    "for j_col in range(ncols):\n",
    "\n",
    "    full_col_ax = [axs[i][j_col] for i in range(nrows)]\n",
    "\n",
    "    color_norm = mpl.colors.Normalize(vmin=min_dtis[j_col], vmax=max_dtis[j_col])\n",
    "\n",
    "    color_mappable = mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap)\n",
    "    cbar = fig.colorbar(\n",
    "        color_mappable,\n",
    "        ax=full_col_ax,\n",
    "        location=\"top\",\n",
    "        orientation=\"horizontal\",\n",
    "        pad=0.01,\n",
    "        shrink=0.85,\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=8, rotation=35)\n",
    "    cbar.ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:g}\"))\n",
    "#     cbar.ax.ticklabel_format(scilimits=(3, -3), useOffset=False)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Channel-Wise Normalization\",\n",
    "    y=max_subplot_height + 0.01,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_channel_wise_norm.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close tensorboard logger.\n",
    "pl_logger.finalize(\"success\")\n",
    "# Experiment is complete, move the results directory to its final location.\n",
    "if experiment_results_dir != final_experiment_results_dir:\n",
    "    print(\"Moving out of tmp location\")\n",
    "    experiment_results_dir = experiment_results_dir.rename(final_experiment_results_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
