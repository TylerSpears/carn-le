{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain in the Net\n",
    "Replication of *Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images*\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "Source work:\n",
    "`S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:29.878925Z",
     "iopub.status.busy": "2021-05-20T02:46:29.878369Z",
     "iopub.status.idle": "2021-05-20T02:46:33.225726Z",
     "shell.execute_reply": "2021-05-20T02:46:33.225114Z",
     "shell.execute_reply.started": "2021-05-20T02:46:29.878863Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/pitn/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning:\n",
      "\n",
      "Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import IPython\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "from typing import Generator\n",
    "\n",
    "import ants\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Try importing GPUtil for printing GPU specs.\n",
    "# May not be installed if using CPU only.\n",
    "try:\n",
    "    import GPUtil\n",
    "except ImportError:\n",
    "    warnings.warn(\"WARNING: Package GPUtil not found, cannot print GPU specs\")\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import nilearn.plotting\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "import einops\n",
    "import einops.layers\n",
    "import einops.layers.torch\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:33.234666Z",
     "iopub.status.busy": "2021-05-20T02:46:33.234511Z",
     "iopub.status.idle": "2021-05-20T02:46:34.714270Z",
     "shell.execute_reply": "2021-05-20T02:46:34.713493Z",
     "shell.execute_reply.started": "2021-05-20T02:46:33.234647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:34.716004Z",
     "iopub.status.busy": "2021-05-20T02:46:34.715838Z",
     "iopub.status.idle": "2021-05-20T02:46:34.727412Z",
     "shell.execute_reply": "2021-05-20T02:46:34.726832Z",
     "shell.execute_reply.started": "2021-05-20T02:46:34.715983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-specific scripts\n",
    "# It's easier to import it this way rather than make an entirely new package, due to\n",
    "# conflicts with local packages and anaconda installations.\n",
    "# You made me do this, poor python package management!!\n",
    "if \"PROJECT_ROOT\" in os.environ:\n",
    "    lib_location = str(Path(os.environ[\"PROJECT_ROOT\"]).resolve())\n",
    "else:\n",
    "    lib_location = str(Path(\"../../\").resolve())\n",
    "if lib_location not in sys.path:\n",
    "    sys.path.insert(0, lib_location)\n",
    "import lib as pitn\n",
    "\n",
    "# Include the top-level lib module along with its submodules.\n",
    "%aimport lib\n",
    "# Grab all submodules of lib, not including modules outside of the package.\n",
    "includes = list(\n",
    "    filter(\n",
    "        lambda m: m.startswith(\"lib.\"),\n",
    "        map(lambda x: x[1].__name__, inspect.getmembers(pitn, inspect.ismodule)),\n",
    "    )\n",
    ")\n",
    "# Run aimport magic with constructed includes.\n",
    "ipy = IPython.get_ipython()\n",
    "ipy.run_line_magic(\"aimport\", \", \".join(includes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:34.728283Z",
     "iopub.status.busy": "2021-05-20T02:46:34.728128Z",
     "iopub.status.idle": "2021-05-20T02:46:34.777753Z",
     "shell.execute_reply": "2021-05-20T02:46:34.777246Z",
     "shell.execute_reply.started": "2021-05-20T02:46:34.728264Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:34.785052Z",
     "iopub.status.busy": "2021-05-20T02:46:34.784896Z",
     "iopub.status.idle": "2021-05-20T02:46:35.013282Z",
     "shell.execute_reply": "2021-05-20T02:46:35.012081Z",
     "shell.execute_reply.started": "2021-05-20T02:46:34.785033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # GPU information\n",
    "    # Taken from\n",
    "    # <https://www.thepythoncode.com/article/get-hardware-system-information-python>.\n",
    "    # If GPUtil is not installed, skip this step.\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        print(\"=\" * 50, \"GPU Specs\", \"=\" * 50)\n",
    "        list_gpus = []\n",
    "        for gpu in gpus:\n",
    "            # get the GPU id\n",
    "            gpu_id = gpu.id\n",
    "            # name of GPU\n",
    "            gpu_name = gpu.name\n",
    "            driver_version = gpu.driver\n",
    "            cuda_version = torch.version.cuda\n",
    "            # get total memory\n",
    "            gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "            gpu_uuid = gpu.uuid\n",
    "            list_gpus.append(\n",
    "                (\n",
    "                    gpu_id,\n",
    "                    gpu_name,\n",
    "                    driver_version,\n",
    "                    cuda_version,\n",
    "                    gpu_total_memory,\n",
    "                    gpu_uuid,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            tabulate(\n",
    "                list_gpus,\n",
    "                headers=(\n",
    "                    \"id\",\n",
    "                    \"Name\",\n",
    "                    \"Driver Version\",\n",
    "                    \"CUDA Version\",\n",
    "                    \"Total Memory\",\n",
    "                    \"uuid\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:35.078794Z",
     "iopub.status.busy": "2021-05-20T02:46:35.078338Z",
     "iopub.status.idle": "2021-05-20T02:46:35.086048Z",
     "shell.execute_reply": "2021-05-20T02:46:35.084968Z",
     "shell.execute_reply.started": "2021-05-20T02:46:35.078738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2021-05-20T02:46:34.798459+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-72-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 13e47db6ff51b6e5cba2e0bcd0d0ab4bad82df84\n",
      "\n",
      "torchvision      : 0.9.1\n",
      "matplotlib       : 3.4.1\n",
      "torchio          : 0.18.37\n",
      "dipy             : 1.4.0\n",
      "ipywidgets       : 7.6.3\n",
      "scipy            : 1.5.3\n",
      "pytorch_lightning: 1.2.6\n",
      "nilearn          : 0.7.1\n",
      "GPUtil           : 1.4.0\n",
      "seaborn          : 0.11.1\n",
      "ants             : 0.2.7\n",
      "nibabel          : 3.2.1\n",
      "torch            : 1.8.1\n",
      "json             : 2.0.9\n",
      "pandas           : 1.2.3\n",
      "natsort          : 7.1.1\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "einops           : 0.3.0\n",
      "IPython          : 7.22.0\n",
      "skimage          : 0.18.1\n",
      "numpy            : 1.20.2\n",
      "\n",
      "================================================== GPU Specs ==================================================\n",
      "  id  Name       Driver Version      CUDA Version  Total Memory    uuid\n",
      "----  ---------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  TITAN RTX  460.73.01                   11.1  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:36.597582Z",
     "iopub.status.busy": "2021-05-20T02:46:36.596990Z",
     "iopub.status.idle": "2021-05-20T02:46:36.608721Z",
     "shell.execute_reply": "2021-05-20T02:46:36.607524Z",
     "shell.execute_reply.started": "2021-05-20T02:46:36.597517Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"]) / \"hcp\"\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"]) / \"hcp\"\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:43.782810Z",
     "iopub.status.busy": "2021-05-20T02:46:43.782210Z",
     "iopub.status.idle": "2021-05-20T02:46:43.803086Z",
     "shell.execute_reply": "2021-05-20T02:46:43.801226Z",
     "shell.execute_reply.started": "2021-05-20T02:46:43.782744Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment results directory:  /home/jovyan/work/pitn/results/tmp/2021-05-20T02_46_43__debug_norm\n"
     ]
    }
   ],
   "source": [
    "# Experiment logging setup\n",
    "EXPERIMENT_NAME = \"debug_norm\"\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "tmp_results_dir = results_dir / \"tmp\"\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 3\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "(experiment_results_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(\n",
    "    \"Experiment results directory: \",\n",
    "    experiment_results_dir,\n",
    ")\n",
    "assert experiment_results_dir.exists()\n",
    "\n",
    "experiment_results_log = experiment_results_dir / \"log.txt\"\n",
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:45.773209Z",
     "iopub.status.busy": "2021-05-20T02:46:45.772704Z",
     "iopub.status.idle": "2021-05-20T02:46:45.779382Z",
     "shell.execute_reply": "2021-05-20T02:46:45.778358Z",
     "shell.execute_reply.started": "2021-05-20T02:46:45.773153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsample_factor = 2\n",
    "# Include b=0 shells and b=1000 shells for DTI fitting.\n",
    "bval_range = (0, 1500)\n",
    "dti_fit_method = \"WLS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:48.026135Z",
     "iopub.status.busy": "2021-05-20T02:46:48.025554Z",
     "iopub.status.idle": "2021-05-20T02:46:48.040029Z",
     "shell.execute_reply": "2021-05-20T02:46:48.039460Z",
     "shell.execute_reply.started": "2021-05-20T02:46:48.026070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patch parameters\n",
    "batch_size = 32\n",
    "# 6 channels for the 6 DTI components\n",
    "channels = 6\n",
    "\n",
    "# Output patch shapes\n",
    "h_out = 14\n",
    "w_out = 14\n",
    "d_out = 14\n",
    "\n",
    "# This is the factor that determines how over-extended the input patch should be\n",
    "# relative to the size of the full-res patch.\n",
    "# $low_res_patch_dim = \\frac{full_res_patch_dim}{downsample_factor} \\times low_res_sample_extension$\n",
    "# A value of 1 indicates that the input patch dims will be exactly divided by the\n",
    "# downsample factor. A dilation > 1 increases the \"spatial extent\" of the input\n",
    "# patch, providing information outside of the target HR patch.\n",
    "low_res_sample_extension = 1.57\n",
    "\n",
    "# Output shape after shuffling.\n",
    "output_patch_shape = (channels, h_out, w_out, d_out)\n",
    "output_spatial_patch_shape = output_patch_shape[1:]\n",
    "\n",
    "# Input patch parameters\n",
    "h_in = round(h_out / (downsample_factor) * low_res_sample_extension)\n",
    "w_in = round(w_out / (downsample_factor) * low_res_sample_extension)\n",
    "d_in = round(d_out / (downsample_factor) * low_res_sample_extension)\n",
    "input_patch_shape = (channels, h_in, w_in, d_in)\n",
    "input_spatial_patch_shape = input_patch_shape[1:]\n",
    "\n",
    "# Pre-shuffle output patch sizes.\n",
    "unshuffled_channels_out = channels * downsample_factor ** 3\n",
    "# Output before shuffling\n",
    "unshuffled_output_patch_shape = (unshuffled_channels_out, h_in, w_in, d_in)\n",
    "\n",
    "# Patch size in FR-space when accounting for the low-res over-extension/over-sampling\n",
    "# factor.\n",
    "fr_extension_patch_size = tuple(\n",
    "    np.asarray(input_spatial_patch_shape) * downsample_factor\n",
    ")\n",
    "fr_extension_amount = tuple(\n",
    "    np.asarray(fr_extension_patch_size) - np.asarray(output_spatial_patch_shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:49.663637Z",
     "iopub.status.busy": "2021-05-20T02:46:49.663110Z",
     "iopub.status.idle": "2021-05-20T02:46:49.670788Z",
     "shell.execute_reply": "2021-05-20T02:46:49.669430Z",
     "shell.execute_reply.started": "2021-05-20T02:46:49.663575Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data parameters.\n",
    "num_subject_samples = 10\n",
    "# Should the data be normalized as a pre-processing step?\n",
    "data_norm_method = \"channels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:51.091405Z",
     "iopub.status.busy": "2021-05-20T02:46:51.090862Z",
     "iopub.status.idle": "2021-05-20T02:46:51.100159Z",
     "shell.execute_reply": "2021-05-20T02:46:51.098763Z",
     "shell.execute_reply.started": "2021-05-20T02:46:51.091344Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training/testing parameters.\n",
    "test_percent = 0.2\n",
    "# test_percent = 0.5\n",
    "train_percent = 1 - test_percent\n",
    "# val_percent = 0.1\n",
    "\n",
    "# NN parameters.\n",
    "max_epochs = 50\n",
    "network_norm_method = None\n",
    "train_loss_name = \"MSE\"\n",
    "\n",
    "# Spline interpolation baseline parameters.\n",
    "spline_interp_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:52.463352Z",
     "iopub.status.busy": "2021-05-20T02:46:52.462784Z",
     "iopub.status.idle": "2021-05-20T02:46:52.472103Z",
     "shell.execute_reply": "2021-05-20T02:46:52.470684Z",
     "shell.execute_reply.started": "2021-05-20T02:46:52.463287Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of voxels to dilate the mask in FR space.\n",
    "# Dilate to allow the outer-most perimeter to be completely outside the brain, and no\n",
    "# more.\n",
    "dilation_size = math.ceil((max(fr_extension_patch_size) + 1) / 2)\n",
    "# 12 is too much, nearly doubles the volume of the brain mask. Lower it some more...\n",
    "dilation_size = dilation_size // 3\n",
    "# Even 4 is a chunky bit! Just make it 0.\n",
    "dilation_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:53.535478Z",
     "iopub.status.busy": "2021-05-20T02:46:53.534960Z",
     "iopub.status.idle": "2021-05-20T02:46:53.546079Z",
     "shell.execute_reply": "2021-05-20T02:46:53.544893Z",
     "shell.execute_reply.started": "2021-05-20T02:46:53.535417Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Downsample Factor: {downsample_factor}\\n\")\n",
    "    f.write(f\"Low-Res oversampling factor: {low_res_sample_extension}\\n\")\n",
    "    f.write(f\"DTI Fit Method: {dti_fit_method}\\n\")\n",
    "    f.write(f\"Input Patch Size: {input_patch_shape}\\n\")\n",
    "    f.write(f\"Output Patch Size: {output_patch_shape}\\n\")\n",
    "    f.write(f\"Brain Mask Dilation Size: {dilation_size}\\n\")\n",
    "    f.write(f\"Batch Size: {batch_size}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:55.299633Z",
     "iopub.status.busy": "2021-05-20T02:46:55.299076Z",
     "iopub.status.idle": "2021-05-20T02:46:55.314684Z",
     "shell.execute_reply": "2021-05-20T02:46:55.314096Z",
     "shell.execute_reply.started": "2021-05-20T02:46:55.299571Z"
    }
   },
   "outputs": [],
   "source": [
    "BoxplotStats = collections.namedtuple(\n",
    "    \"BoxplotStats\",\n",
    "    [\"low_outliers\", \"low\", \"q1\", \"median\", \"q3\", \"high\", \"high_outliers\"],\n",
    ")\n",
    "\n",
    "\n",
    "def batch_boxplot_stats(batch):\n",
    "    \"\"\"Quick calculation of a batch of 1D values for showing boxplot stats.\"\"\"\n",
    "    q1, median, q3 = np.quantile(batch, q=[0.25, 0.5, 0.75], axis=1)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - (1.5 * iqr)\n",
    "    high = q3 + (1.5 * iqr)\n",
    "    low_outliers = list()\n",
    "    high_outliers = list()\n",
    "    # Number of outliers may be different for each batch, so it needs to be a list of\n",
    "    # arrays.\n",
    "    for i_batch in range(len(batch)):\n",
    "        batch_i = batch[i_batch]\n",
    "        low_i = low[i_batch]\n",
    "        low_outliers.append(batch_i[np.where(batch_i < low_i)])\n",
    "        high_i = high[i_batch]\n",
    "        high_outliers.append(batch_i[np.where(batch_i > high_i)])\n",
    "\n",
    "    return BoxplotStats(low_outliers, low, q1, median, q3, high, high_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:56.083712Z",
     "iopub.status.busy": "2021-05-20T02:46:56.083182Z",
     "iopub.status.idle": "2021-05-20T02:46:56.096772Z",
     "shell.execute_reply": "2021-05-20T02:46:56.095789Z",
     "shell.execute_reply.started": "2021-05-20T02:46:56.083650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick check on full volume/batch distributions.\n",
    "\n",
    "\n",
    "def print_channel_dists(vols):\n",
    "    if not torch.is_tensor(vols):\n",
    "        t_vols = torch.as_tensor(vols)\n",
    "    else:\n",
    "        t_vols = vols\n",
    "\n",
    "    if t_vols.ndim == 4:\n",
    "        t_vols = t_vols[None, ...]\n",
    "\n",
    "    results = \"means | vars\\n\"\n",
    "    for t_vol_i in t_vols:\n",
    "        mean_i = torch.mean(t_vol_i, dim=(1, 2, 3))\n",
    "        var_i = torch.var(t_vol_i, dim=(1, 2, 3))\n",
    "        mvs = [\n",
    "            (f\"{mv[0]} | {mv[1]}\\n\")\n",
    "            for mv in torch.stack([mean_i, var_i], dim=-1).tolist()\n",
    "        ]\n",
    "        results = results + \"\".join(mvs)\n",
    "        results = results + (\"=\" * (len(mvs[-1]) - 1)) + \"\\n\"\n",
    "\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:46:57.594824Z",
     "iopub.status.busy": "2021-05-20T02:46:57.594282Z",
     "iopub.status.idle": "2021-05-20T02:46:57.612002Z",
     "shell.execute_reply": "2021-05-20T02:46:57.610852Z",
     "shell.execute_reply.started": "2021-05-20T02:46:57.594762Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-7175a7d586cd>:25: UserWarning:\n",
      "\n",
      "WARNING: Sub-selecting participants for dev and debugging. Subj IDs selected: ['156637', '303624', '135528', '753251', '227432', '141422', '751348', '700634', '644246', '810439']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{135528: PosixPath('/mnt/storage/data/pitn/hcp/135528/T1w/Diffusion'),\n",
       " 141422: PosixPath('/mnt/storage/data/pitn/hcp/141422/T1w/Diffusion'),\n",
       " 156637: PosixPath('/mnt/storage/data/pitn/hcp/156637/T1w/Diffusion'),\n",
       " 227432: PosixPath('/mnt/storage/data/pitn/hcp/227432/T1w/Diffusion'),\n",
       " 303624: PosixPath('/mnt/storage/data/pitn/hcp/303624/T1w/Diffusion'),\n",
       " 644246: PosixPath('/mnt/storage/data/pitn/hcp/644246/T1w/Diffusion'),\n",
       " 700634: PosixPath('/mnt/storage/data/pitn/hcp/700634/T1w/Diffusion'),\n",
       " 751348: PosixPath('/mnt/storage/data/pitn/hcp/751348/T1w/Diffusion'),\n",
       " 753251: PosixPath('/mnt/storage/data/pitn/hcp/753251/T1w/Diffusion'),\n",
       " 810439: PosixPath('/mnt/storage/data/pitn/hcp/810439/T1w/Diffusion')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: dict = dict()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "selected_ids = random.sample(selected_ids, num_subject_samples)\n",
    "warnings.warn(\n",
    "    \"WARNING: Sub-selecting participants for dev and debugging. \"\n",
    "    + f\"Subj IDs selected: {selected_ids}\"\n",
    ")\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_ids = natsorted(list(map(lambda s: int(s), selected_ids)))\n",
    "\n",
    "for subj_id in selected_ids:\n",
    "    subj_dirs[subj_id] = data_dir / f\"{subj_id}/T1w/Diffusion\"\n",
    "    assert subj_dirs[subj_id].exists()\n",
    "subj_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 90 scans are taken from the $b=1000 \\ s/mm^2$. However, the $b=0$ shells are still required for fitting the diffusion tensors (DTI's), so those will need to be kept, too.\n",
    "\n",
    "To find those, sub-select with the $0 < bvals < 1500$, or roughly thereabout. A b-val of $995$ or $1005$ still counts as a b=1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:47:02.199077Z",
     "iopub.status.busy": "2021-05-20T02:47:02.198518Z",
     "iopub.status.idle": "2021-05-20T02:47:02.207847Z",
     "shell.execute_reply": "2021-05-20T02:47:02.206463Z",
     "shell.execute_reply.started": "2021-05-20T02:47:02.199018Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:47:03.900706Z",
     "iopub.status.busy": "2021-05-20T02:47:03.900135Z",
     "iopub.status.idle": "2021-05-20T02:47:03.920816Z",
     "shell.execute_reply": "2021-05-20T02:47:03.919403Z",
     "shell.execute_reply.started": "2021-05-20T02:47:03.900644Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the transformation pipeline.\n",
    "# Pad the original image & maks to ensure that lr patches cannot have invalid indices.\n",
    "# fr_spatial_padding = tuple(\n",
    "#     (np.ceil(np.asarray(input_spatial_patch_shape) * downsample_factor / 2) + 1).astype(\n",
    "#         int\n",
    "#     )\n",
    "# )\n",
    "\n",
    "preproc_transforms = torchio.Compose(\n",
    "    [\n",
    "        torchio.transforms.ToCanonical(include=(\"dwi\", \"brain_mask\"), copy=False),\n",
    "        pitn.transforms.BValSelectionTransform(\n",
    "            bval_range=bval_range,\n",
    "            bval_key=\"bvals\",\n",
    "            bvec_key=\"bvecs\",\n",
    "            include=\"dwi\",\n",
    "            copy=False,\n",
    "        ),\n",
    "        # Pad by the dilation factor, then dilate the mask.\n",
    "        torchio.transforms.Pad(\n",
    "            dilation_size,\n",
    "            padding_mode=0,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.DilateMaskTransform(\n",
    "            dilation_size=dilation_size, include=(\"brain_mask\",), copy=False\n",
    "        ),\n",
    "        # Pad by the amount of extension voxels in FR space, so LR indices cannot\n",
    "        # go out of bounds.\n",
    "        torchio.transforms.Pad(\n",
    "            fr_extension_amount,\n",
    "            padding_mode=0,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        # Ensure FR dims are divisible by the downsample factor, to more reliably\n",
    "        # convert between FR indices and LR indices.\n",
    "        torchio.transforms.EnsureShapeMultiple(\n",
    "            downsample_factor, method=\"pad\", include=(\"dwi\", \"brain_mask\"), copy=False\n",
    "        ),\n",
    "        pitn.transforms.MeanDownsampleTransform(\n",
    "            downsample_factor,\n",
    "            include=(\"dwi\", \"brain_mask\"),\n",
    "            keep={\"dwi\": \"fr_dwi\", \"brain_mask\": \"fr_brain_mask\"},\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"dwi\": \"lr_dwi\", \"brain_mask\": \"lr_brain_mask\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"fr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"fr_dwi\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.FitDTITransform(\n",
    "            \"bvals\",\n",
    "            \"bvecs\",\n",
    "            \"lr_brain_mask\",\n",
    "            fit_method=dti_fit_method,\n",
    "            include=(\"lr_dwi\"),\n",
    "            copy=False,\n",
    "        ),\n",
    "        pitn.transforms.RenameImageTransform(\n",
    "            {\"fr_dwi\": \"fr_dti\", \"lr_dwi\": \"lr_dti\"}, copy=False\n",
    "        ),\n",
    "        pitn.transforms.ImageToDictTransform(\n",
    "            include=(\"lr_dti\", \"lr_brain_mask\"), copy=False\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T02:47:04.971052Z",
     "iopub.status.busy": "2021-05-20T02:47:04.970511Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain mask volume before dilation: 635172\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/135528/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 135528...Selected\n",
      "Downsampling: Subject 135528...Downsampled\n",
      "Fitting to DTI: Subject 135528......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 135528......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 635172\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 729001\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/141422/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 141422...Selected\n",
      "Downsampling: Subject 141422...Downsampled\n",
      "Fitting to DTI: Subject 141422......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 141422......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 729001\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 894163\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/156637/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 156637...Selected\n",
      "Downsampling: Subject 156637...Downsampled\n",
      "Fitting to DTI: Subject 156637......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 156637......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 894163\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 847825\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/227432/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 227432...Selected\n",
      "Downsampling: Subject 227432...Downsampled\n",
      "Fitting to DTI: Subject 227432......DWI shape: torch.Size([108, 162, 190, 162])......DTI shape: (6, 162, 190, 162)...Fitted DTI model: torch.Size([6, 162, 190, 162])\n",
      "Fitting to DTI: Subject 227432......DWI shape: torch.Size([108, 81, 95, 81])......DTI shape: (6, 81, 95, 81)...Fitted DTI model: torch.Size([6, 81, 95, 81])\n",
      "Dilated mask volume: 847825\n",
      "Mask volume difference: 0\n",
      "====================\n",
      "Brain mask volume before dilation: 890811\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/303624/T1w/Diffusion/data.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Import all image data into a sequence of `torchio.Subject` objects.\n",
    "subj_data: dict = dict()\n",
    "summary_stats_fmt = \"github\"\n",
    "summary_stats_header = [\n",
    "    \"Subj ID\",\n",
    "    \"Resolution\",\n",
    "    \"Channel Index\",\n",
    "    \"Num Outliers (Lower)\",\n",
    "    \"Low\",\n",
    "    \"25th Percentile\",\n",
    "    \"Median\",\n",
    "    \"75th Percentile\",\n",
    "    \"High\",\n",
    "    \"Num Outliers (Upper)\",\n",
    "]\n",
    "dti_channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "subj_stats = dict()\n",
    "for k in summary_stats_header:\n",
    "    subj_stats[k] = list()\n",
    "\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "    # Sub-select volumes with only bvals in a certain range. E.x. bvals <= 1100 mm/s^2,\n",
    "    # a.k.a. only the b=0 and b=1000 shells.\n",
    "    bvals = torch.as_tensor(np.loadtxt(subj_dir / \"bvals\").astype(int))\n",
    "    bvecs = torch.as_tensor(np.loadtxt(subj_dir / \"bvecs\"))\n",
    "    # Reshape to be N x 3\n",
    "    if bvecs.shape[0] == 3:\n",
    "        bvecs = bvecs.T\n",
    "\n",
    "    brain_mask = torchio.LabelMap(\n",
    "        subj_dir / \"nodif_brain_mask.nii.gz\",\n",
    "        type=torchio.LABEL,\n",
    "        channels_last=False,\n",
    "    )\n",
    "    brain_mask.set_data(brain_mask.data.bool())\n",
    "    mask_volume = brain_mask[\"data\"].sum()\n",
    "    print(f\"Brain mask volume before dilation: {mask_volume}\")\n",
    "    dwi = torchio.ScalarImage(\n",
    "        subj_dir / \"data.nii.gz\",\n",
    "        type=torchio.INTENSITY,\n",
    "        bvals=bvals,\n",
    "        bvecs=bvecs,\n",
    "        reader=pitn.io.nifti_reader,\n",
    "        channels_last=True,\n",
    "    )\n",
    "\n",
    "    subject_dict = torchio.Subject(subj_id=subj_id, dwi=dwi, brain_mask=brain_mask)\n",
    "    preproced_subj = preproc_transforms(subject_dict)\n",
    "    dilated_mask_volume = preproced_subj[\"fr_brain_mask\"][\"data\"].sum()\n",
    "    print(f\"Dilated mask volume: {dilated_mask_volume}\")\n",
    "    print(f\"Mask volume difference: {dilated_mask_volume - mask_volume}\")\n",
    "    # Subject-and-channel-wise standardization/normalization of both the LR and FR vols.\n",
    "    # Note that LR and FR images should have the same means, but *not* the same variances.\n",
    "    fr_vol = preproced_subj.fr_dti.tensor\n",
    "    fr_mask = preproced_subj.fr_brain_mask.tensor.bool()\n",
    "    masked_fr_vol = torch.masked_select(fr_vol, fr_mask).reshape(fr_vol.shape[0], -1)\n",
    "    fr_channel_means = masked_fr_vol.mean(dim=1)\n",
    "    fr_channel_means = fr_channel_means.reshape(-1, 1, 1, 1)\n",
    "    fr_channel_vars = masked_fr_vol.var(dim=1)\n",
    "    fr_channel_vars = fr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "    # Store subject-and-channel-wise means and vars in order to reverse the normalization\n",
    "    # for the final visualization/output.\n",
    "    preproced_subj[\"fr_means\"] = fr_channel_means.detach().cpu().numpy()\n",
    "    preproced_subj[\"fr_vars\"] = fr_channel_vars.detach().cpu().numpy()\n",
    "\n",
    "    lr_vol = preproced_subj.lr_dti[\"data\"]\n",
    "    lr_mask = preproced_subj.lr_brain_mask[\"data\"].bool()\n",
    "    masked_lr_vol = torch.masked_select(lr_vol, lr_mask).reshape(lr_vol.shape[0], -1)\n",
    "    lr_channel_means = masked_lr_vol.mean(dim=1)\n",
    "    lr_channel_means = lr_channel_means.reshape(-1, 1, 1, 1)\n",
    "    lr_channel_vars = masked_lr_vol.var(dim=1)\n",
    "    lr_channel_vars = lr_channel_vars.reshape(-1, 1, 1, 1)\n",
    "\n",
    "    # Store subject-and-channel-wise means and vars in order to reverse the normalization\n",
    "    # for the final visualization/output.\n",
    "    preproced_subj[\"lr_means\"] = lr_channel_means.detach().cpu().numpy()\n",
    "    preproced_subj[\"lr_vars\"] = lr_channel_vars.detach().cpu().numpy()\n",
    "\n",
    "    # Print and log some statistics of the subject data.\n",
    "    fr_vol_stats = batch_boxplot_stats(masked_fr_vol)\n",
    "    lr_vol_stats = batch_boxplot_stats(masked_lr_vol)\n",
    "    subj_stats[\"Subj ID\"].extend(\n",
    "        list(\n",
    "            itertools.repeat(\n",
    "                subj_id, len(fr_vol_stats.median) + len(lr_vol_stats.median)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    subj_stats[\"Resolution\"].extend(\n",
    "        list(\n",
    "            itertools.chain(\n",
    "                itertools.repeat(\"Full\", len(fr_vol_stats.median)),\n",
    "                itertools.repeat(\"Low\", len(lr_vol_stats.median)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    subj_stats[\"Channel Index\"].extend(dti_channel_names * 2)\n",
    "\n",
    "    subj_stats[\"Num Outliers (Lower)\"].extend(\n",
    "        list(\n",
    "            itertools.chain(\n",
    "                map(len, fr_vol_stats.low_outliers), map(len, lr_vol_stats.low_outliers)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    subj_stats[\"Low\"].extend(list(np.concatenate([fr_vol_stats.low, lr_vol_stats.low])))\n",
    "    subj_stats[\"25th Percentile\"].extend(\n",
    "        list(np.concatenate([fr_vol_stats.q1, lr_vol_stats.q1]))\n",
    "    )\n",
    "\n",
    "    subj_stats[\"Median\"].extend(\n",
    "        list(np.concatenate([fr_vol_stats.median, lr_vol_stats.median]))\n",
    "    )\n",
    "\n",
    "    subj_stats[\"75th Percentile\"].extend(\n",
    "        list(np.concatenate([fr_vol_stats.q3, lr_vol_stats.q3]))\n",
    "    )\n",
    "    subj_stats[\"High\"].extend(\n",
    "        list(np.concatenate([fr_vol_stats.high, lr_vol_stats.high]))\n",
    "    )\n",
    "    subj_stats[\"Num Outliers (Upper)\"].extend(\n",
    "        list(\n",
    "            itertools.chain(\n",
    "                map(len, fr_vol_stats.high_outliers),\n",
    "                map(len, lr_vol_stats.high_outliers),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if isinstance(data_norm_method, str) and \"channel\" in data_norm_method.casefold():\n",
    "        # Standardize the volumes.\n",
    "        preproced_subj.fr_dti.set_data(\n",
    "            pitn.data.norm.normalize_dti(fr_vol, fr_channel_means, fr_channel_vars)\n",
    "        )\n",
    "        preproced_subj.lr_dti[\"data\"] = pitn.data.norm.normalize_dti(\n",
    "            lr_vol, lr_channel_means, lr_channel_vars\n",
    "        )\n",
    "\n",
    "    subj_data[subj_id] = preproced_subj\n",
    "    print(\"=\" * 20)\n",
    "#     breakpoint()\n",
    "\n",
    "print(\"===Data Loaded & Transformed===\")\n",
    "\n",
    "subj_stats_str = tabulate(\n",
    "    subj_stats, headers=summary_stats_header, tablefmt=summary_stats_fmt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Preprocessing transformation pipeline: {str(preproc_transforms)}\\n\")\n",
    "    f.write(f\"Data Summary Statistics, no normalization:\\n {subj_stats_str}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Markdown(subj_stats_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj_dataset = torchio.SubjectsDataset(list(subj_data.values()), load_getitem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print_channel_dists(\n",
    "#     torch.stack([subj[\"fr_dti\"][\"data\"] for subj in subj_data.values()])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print_channel_dists(\n",
    "#     torch.stack([subj[\"lr_dti\"][\"data\"] for subj in subj_data.values()])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_dataset)\n",
    "num_test_subjs = int(np.ceil(num_subjs * test_percent))\n",
    "num_train_subjs = num_subjs - num_test_subjs\n",
    "subj_list = subj_dataset.dry_iter()\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Create partial function to collect list of samples and form a tuple of tensors.\n",
    "collate_fn = functools.partial(\n",
    "    pitn.samplers.collate_subj, full_res_key=\"fr_dti\", low_res_key=\"lr_dti\"\n",
    ")\n",
    "\n",
    "test_dataset = torchio.SubjectsDataset(subj_list[:num_test_subjs], load_getitem=False)\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1 and num_train_subjs == 0:\n",
    "    print(\"DEBUG: Only 1 subject with no training subjects, mixing train and test set\")\n",
    "    subj_list = subj_list[:]\n",
    "    num_train_subjs = num_test_subjs\n",
    "else:\n",
    "    subj_list = subj_list[num_test_subjs:]\n",
    "\n",
    "train_dataset = torchio.SubjectsDataset(subj_list, load_getitem=False)\n",
    "\n",
    "# Training patch sampler, random across all patches of all volumes.\n",
    "train_sampler = pitn.samplers.MultiresSampler(\n",
    "    source_img_key=\"fr_dti\",\n",
    "    low_res_key=\"lr_dti\",\n",
    "    downsample_factor=downsample_factor,\n",
    "    label_name=\"fr_brain_mask\",\n",
    "    source_spatial_patch_size=output_spatial_patch_shape,\n",
    "    low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "    label_probabilities={0: 0, 1: 1},\n",
    ")\n",
    "\n",
    "patches_per_subj = 8000\n",
    "# Hold enough for 2 epochs at a time.\n",
    "queue_max_length = patches_per_subj * num_train_subjs * 2\n",
    "\n",
    "# Set up a torchio.Queue to act as a sampler proxy for the torch DataLoader\n",
    "train_queue = torchio.Queue(\n",
    "    train_dataset,\n",
    "    max_length=queue_max_length,\n",
    "    samples_per_volume=patches_per_subj,\n",
    "    sampler=train_sampler,\n",
    "    shuffle_patches=True,\n",
    "    shuffle_subjects=True,\n",
    "    num_workers=6,\n",
    "    #     verbose=True,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_queue,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Set up testing objects.\n",
    "# Calculate the patch overlap needed for ~50% of the patch volume overlapping (which is\n",
    "# not the same as dividing each dimension by 2).\n",
    "input_vol_half_overlap = int(\n",
    "    np.floor(np.power(np.prod(input_spatial_patch_shape) / 2, 1 / 3))\n",
    ")\n",
    "# torchio requires an even-numbered overlap.\n",
    "if input_vol_half_overlap % 2 == 1:\n",
    "    input_vol_half_overlap += 1\n",
    "input_vol_half_overlap = np.repeat(input_vol_half_overlap, 3)\n",
    "\n",
    "# Repeat for the output.\n",
    "output_vol_half_overlap = np.floor(\n",
    "    np.power(np.prod(output_spatial_patch_shape) / 2, 1 / 3)\n",
    ").astype(int)\n",
    "# torchio requires an even-numbered overlap.\n",
    "if output_vol_half_overlap % 2 == 1:\n",
    "    output_vol_half_overlap += 1\n",
    "output_vol_half_overlap = np.repeat(output_vol_half_overlap, 3)\n",
    "\n",
    "# Test samplers\n",
    "test_samplers = list()\n",
    "for subj in test_dataset.dry_iter():\n",
    "    test_samplers.append(\n",
    "        pitn.samplers.MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor=downsample_factor,\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            patch_overlap=output_vol_half_overlap,\n",
    "            # Due to the oversampling in the LR->HR patch mapping, a mask is necessary\n",
    "            # to avoid sampling from out of bounds.\n",
    "            source_mask=subj[\"fr_brain_mask\"].tensor[0].bool(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "concat_test_dataset = torch.utils.data.ConcatDataset(test_samplers)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    concat_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=6,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Test subject(s) IDs: \", [s.subj_id for s in test_dataset.dry_iter()])\n",
    "print(\"Training subject(s) IDs: \", [s.subj_id for s in train_dataset.dry_iter()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Training Set Subjects: {[s.subj_id for s in test_dataset.dry_iter()]}\\n\")\n",
    "    f.write(f\"Test Set Subjects: {[s.subj_id for s in train_dataset.dry_iter()]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "debug_prob_threshold = 0.01\n",
    "class DIQTSystem(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        downsample_factor,\n",
    "        train_loss_method: str,\n",
    "        norm_method=None,\n",
    "        train_loss_log_file=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = channels\n",
    "        self._downsample_factor = downsample_factor\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = pitn.nn.models.ThreeConv(\n",
    "            self._channels, self._downsample_factor, norm_method=norm_method\n",
    "        )\n",
    "\n",
    "        ## Training parameters\n",
    "        self._lr = 10e-3\n",
    "        self._betas = (0.9, 0.999)\n",
    "        loss_methods = {\n",
    "            \"MSE\".casefold(): torch.nn.MSELoss(reduction=\"mean\"),\n",
    "            \"SSE\".casefold(): torch.nn.MSELoss(reduction=\"sum\"),\n",
    "            \"RMSE\".casefold(): lambda y_hat, y: torch.sqrt(\n",
    "                F.mse_loss(y_hat, y, reduction=\"mean\")\n",
    "            ),\n",
    "            \"L1\".casefold(): torch.nn.L1Loss(reduction=\"mean\"),\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            self._loss_fn = loss_methods[train_loss_method.casefold()]\n",
    "        except (AttributeError, KeyError) as e:\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = {\"train_loss\": list(), \"val_loss\": list(), \"test_loss\": list()}\n",
    "        self.train_loss_log_file = train_loss_log_file\n",
    "        if self.train_loss_log_file is not None:\n",
    "            with open(self.train_loss_log_file, \"a+\") as f:\n",
    "                f.write(\"epoch, batch_idx, loss\\n\")\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_with_layer(norm_layer, y):\n",
    "\n",
    "        if norm_layer is not None:\n",
    "            if not norm_layer.track_running_stats:\n",
    "                y = norm_layer(y)\n",
    "            else:\n",
    "                if isinstance(norm_layer, torch.nn.InstanceNorm3d):\n",
    "                    y = F.instance_norm(\n",
    "                        y,\n",
    "                        eps=norm_layer.eps,\n",
    "                    )\n",
    "                elif isinstance(norm_layer, torch.nn.BatchNorm3d):\n",
    "                    y = F.batch_norm(\n",
    "                        y,\n",
    "                        eps=norm_layer.eps,\n",
    "                    )\n",
    "\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        # We need both prediction and ground truth to be a standard normal distribution\n",
    "        # for a fair calculation of the loss.\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "        if self.net.norm is not None:\n",
    "            y = self.normalize_with_layer(self.net.norm, y)\n",
    "\n",
    "        loss = self._loss_fn(y_pred, y)\n",
    "        if random.random() < debug_prob_threshold:\n",
    "            breakpoint()\n",
    "        self.log(\"train_loss\", loss, logger=False)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        # Only log each epoch if a log filename was given.\n",
    "        if self.train_loss_log_file:\n",
    "\n",
    "            row_iter = itertools.product(\n",
    "                (self.current_epoch,),\n",
    "                range(len(training_step_outputs)),\n",
    "                [str(float(l[\"loss\"].detach().cpu())) for l in training_step_outputs],\n",
    "            )\n",
    "\n",
    "            loss_rows = \"\".join(\n",
    "                [\n",
    "                    f\"{epoch}, {batch_idx}, {loss}\\n\"\n",
    "                    for epoch, batch_idx, loss in row_iter\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            with open(self.train_loss_log_file, \"a+\") as f:\n",
    "                f.write(loss_rows)\n",
    "\n",
    "    #     def validation_step(self, batch, batch_idx):\n",
    "    #         pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        # We can't normalize the outputs or ground truth because it would change\n",
    "        # our units out of $mm^2/s$.\n",
    "        y_pred = self.net(x, norm_output=False)\n",
    "        #         if self.net.norm is not None:\n",
    "        #             y = self.normalize_with_layer(self.net.norm, y)\n",
    "\n",
    "        test_loss = torch.sqrt(F.mse_loss(y_pred, y, reduction=\"mean\"))\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        self.plain_log[\"test_loss\"].append(float(test_loss.cpu()))\n",
    "\n",
    "        return test_loss\n",
    "\n",
    "    def viz_step(self, x, norm_output=True):\n",
    "        \"\"\"Step for running inference for the purpose of a visualization.\n",
    "\n",
    "        Mainly deals with normalization.\"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.net.training:\n",
    "                was_training = True\n",
    "            else:\n",
    "                was_training = False\n",
    "\n",
    "            self.net.eval()\n",
    "\n",
    "            y_pred = self.net(x, norm_output=norm_output)\n",
    "\n",
    "            if isinstance(self.net.norm, torch.nn.InstanceNorm3d):\n",
    "                target_mean = torch.mean(x, dim=(2, 3, 4), keepdim=True)\n",
    "                target_var = torch.var(x, dim=(2, 3, 4), keepdim=True)\n",
    "                eps = self.net.norm.eps\n",
    "\n",
    "            elif isinstance(self.net.norm, torch.nn.BatchNorm3d):\n",
    "                target_mean = torch.mean(x, dim=(0, 2, 3, 4), keepdim=True)\n",
    "                target_var = torch.var(x, dim=(0, 2, 3, 4), keepdim=True)\n",
    "                eps = self.net.norm.eps\n",
    "            else:\n",
    "                target_mean = torch.zeros(1, 1, 1, 1, 1).to(x)\n",
    "                target_var = torch.ones(1, 1, 1, 1, 1).to(x)\n",
    "                eps = 1e-10\n",
    "\n",
    "            y_pred = pitn.data.norm.denormalize_batch(\n",
    "                y_pred, target_mean, target_var, eps=eps\n",
    "            )\n",
    "\n",
    "            if was_training:\n",
    "                self.net.train()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.net.parameters(), lr=self._lr, betas=self._betas\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_log_file = experiment_results_dir / \"train_loss.csv\"\n",
    "\n",
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "model = DIQTSystem(\n",
    "    channels=channels,\n",
    "    downsample_factor=downsample_factor,\n",
    "    train_loss_log_file=train_loss_log_file,\n",
    "    norm_method=network_norm_method,\n",
    "    train_loss_method=train_loss_name,\n",
    ")\n",
    "\n",
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Max epochs: {max_epochs}\\n\")\n",
    "    f.write(f\"Model overview: {model}\\n\")\n",
    "    f.write(f\"Training loss function: {train_loss_name}\\n\")\n",
    "\n",
    "# Create trainer object. Note: `automatic_optimization` needs to be set to `False` when\n",
    "# manually performing backprop. See\n",
    "# <https://colab.research.google.com/drive/1nGtvBFirIvtNQdppe2xBes6aJnZMjvl8?usp=sharing>\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=max_epochs, progress_bar_refresh_rate=10)\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + train_loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss_name = \"RMSE\"\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "\n",
    "with open(experiment_results_log, \"a+\") as f:\n",
    "    f.write(f\"Test loss function: {test_loss_name}\\n\")\n",
    "\n",
    "row_iter = enumerate(model.plain_log[\"test_loss\"])\n",
    "test_loss_tabular = \"\".join([f\"{batch_idx}, {loss}\\n\" for batch_idx, loss in row_iter])\n",
    "\n",
    "with open(test_loss_log_file, \"a+\") as f:\n",
    "    f.write(\"batch_idx, loss\\n\")\n",
    "    f.write(test_loss_tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cubic Spline Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cubic_spline_test_log = list()\n",
    "\n",
    "for subj in test_dataset.dry_iter():\n",
    "    print(\"---\")\n",
    "    target_shape = subj[\"fr_dti\"][\"data\"].cpu().numpy().shape\n",
    "    interp_cubic_spline = scipy.ndimage.zoom(\n",
    "        subj[\"lr_dti\"][\"data\"].cpu().numpy(),\n",
    "        zoom=(1, downsample_factor, downsample_factor, downsample_factor),\n",
    "        order=spline_interp_order,\n",
    "    )\n",
    "    if interp_cubic_spline.shape != target_shape:\n",
    "        # Crop off the end few voxels to account for the lack of padding used in full-\n",
    "        # volume inference.\n",
    "        interp_cubic_spline = interp_cubic_spline[\n",
    "            :, : target_shape[1], : target_shape[2], : target_shape[3]\n",
    "        ]\n",
    "    print(f\"Subj {subj['subj_id']} done\")\n",
    "\n",
    "    cubic_spline_test_log.append(interp_cubic_spline)\n",
    "\n",
    "cspline_loss = list()\n",
    "\n",
    "# Calculate spline loss for test images.\n",
    "for subj, cspline_pred in zip(test_dataset.dry_iter(), cubic_spline_test_log):\n",
    "    # De-normalize the ground truth volume.\n",
    "    gt = subj[\"fr_dti\"][\"data\"]\n",
    "    gt = gt.detach().cpu().numpy()\n",
    "    gt = (gt * (subj[\"fr_vars\"] + 1 ** (-10))) + subj[\"fr_means\"]\n",
    "    # De-normalize the spline prediction to match the channel-wise distribution of the\n",
    "    # ground truth.\n",
    "    cspline_pred = (cspline_pred * (subj[\"fr_vars\"] + 10 ** (-10))) + subj[\"fr_means\"]\n",
    "    # Calculate the RMSE of just the values found in the mask.\n",
    "    se = (gt - cspline_pred) ** 2\n",
    "    se = se[:, subj[\"fr_brain_mask\"][\"data\"].bool().cpu().numpy()[0]]\n",
    "    loss = np.sqrt(se.mean())\n",
    "    cspline_loss.append(loss)\n",
    "\n",
    "# Find the grand mean of the spline RMSE's\n",
    "cspline_loss_mean = np.mean(cspline_loss)\n",
    "print(cspline_loss_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = True\n",
    "\n",
    "sns.histplot(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]),\n",
    "    kde=True,\n",
    "    stat=\"probability\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    label=\"Current Model\",\n",
    "    legend=False,\n",
    ")\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "# Draw an entire other plot, invisibly, to have another y-axis.\n",
    "ax_count = ax_prob.twinx()\n",
    "sns.histplot(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]),\n",
    "    alpha=0,\n",
    "    ax=ax_count,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    ")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"--\", \"alpha\": 0.8, \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(model.plain_log[\"test_loss\"]).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Our spline mean performance.\n",
    "plt.axvline(\n",
    "    cspline_loss_mean,\n",
    "    label=\"(Ours) C-spline Mean\",\n",
    "    color=\"black\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Tanno, et. al., 2021 model comparisons.\n",
    "# Taken from Table 2, HCP exterior.\n",
    "plt.axvline(\n",
    "    31.738 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) C-spline Mean\",\n",
    "    color=\"red\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    23.139 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) RF\",\n",
    "    color=\"orange\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.609 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) ESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    13.412 * (10.0 ** (-4)),\n",
    "    label=\"(Tanno etal, 2021) Best\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    12.78 * (10.0 ** (-4)),\n",
    "    label=\"(Blumberg etal, 2018) Best\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(f\"Test Loss Histogram with Test Metric {test_loss_name}\")\n",
    "plt.savefig(experiment_results_dir / \"test_loss_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.asarray(model.plain_log[\"test_loss\"]).max())\n",
    "print(np.asarray(model.plain_log[\"test_loss\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volume of full-res ground truth, low-res downsample, and high-res\n",
    "# inferences.\n",
    "@dataclass\n",
    "class SubjResult:\n",
    "    subj_id: int\n",
    "    full_res: torch.Tensor\n",
    "    low_res: torch.Tensor\n",
    "    full_res_predicted: torch.Tensor\n",
    "    full_res_cubic_spline: np.ndarray\n",
    "\n",
    "\n",
    "test_vol_results = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj in test_dataset.dry_iter():\n",
    "\n",
    "        # Create a grid sampler for this subject.\n",
    "        subj_sampler = pitn.samplers.MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor=downsample_factor,\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            source_mask=subj[\"fr_brain_mask\"].tensor,\n",
    "            patch_overlap=0,\n",
    "        )\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            subj_sampler, batch_size=256, pin_memory=True\n",
    "        )\n",
    "        aggregator = torchio.GridAggregator(subj_sampler)\n",
    "\n",
    "        # Iterate over all batches of patches.\n",
    "        for batch in loader:\n",
    "\n",
    "            x = batch[\"lr_dti\"][\"data\"]\n",
    "            # Locations are in reference to the full-res groud truth.\n",
    "            locations = batch[\"location\"]\n",
    "            predictions = (\n",
    "                model.viz_step(x.to(model.device), norm_output=False).detach().cpu()\n",
    "            )\n",
    "\n",
    "            aggregator.add_batch(predictions, locations)\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "\n",
    "        # Calculate cubic spline as a baseline.\n",
    "        full_res_cubic_spline = scipy.ndimage.zoom(\n",
    "            subj[\"lr_dti\"][\"data\"].cpu().numpy(),\n",
    "            zoom=((1,) + (downsample_factor,) * 3),\n",
    "            order=3,\n",
    "        )\n",
    "        full_res_cubic_spline = torch.from_numpy(full_res_cubic_spline).to(fr_vol)\n",
    "        fr_vol = subj[\"fr_dti\"][\"data\"]\n",
    "        lr_vol = subj[\"lr_dti\"][\"data\"]\n",
    "\n",
    "        full_res_predicted = aggregator.get_output_tensor()\n",
    "\n",
    "        if data_norm_method is not None and \"channel\" in data_norm_method.casefold():\n",
    "\n",
    "            fr_means = torch.as_tensor(subj[\"fr_means\"]).to(fr_vol)\n",
    "            fr_vars = torch.as_tensor(subj[\"fr_vars\"]).to(fr_vol)\n",
    "            fr_vol = pitn.data.norm.denormalize_dti(fr_vol, fr_means, fr_vars)\n",
    "            lr_means = torch.as_tensor(subj[\"lr_means\"]).to(lr_vol)\n",
    "            lr_vars = torch.as_tensor(subj[\"lr_vars\"]).to(lr_vol)\n",
    "            lr_vol = pitn.data.norm.denormalize_dti(lr_vol, lr_means, lr_vars)\n",
    "\n",
    "            full_res_cubic_spline = pitn.data.norm.denormalize_dti(\n",
    "                full_res_cubic_spline, fr_means, fr_vars\n",
    "            )\n",
    "            full_res_predicted = pitn.data.norm.denormalize_dti(\n",
    "                full_res_predicted, fr_means, fr_vars\n",
    "            )\n",
    "        # Zero-out all voxels outside the mask.\n",
    "        fr_mask = subj[\"fr_brain_mask\"][\"data\"]\n",
    "        full_res_cubic_spline = full_res_cubic_spline * fr_mask.to(\n",
    "            full_res_cubic_spline\n",
    "        )\n",
    "        fr_vol = fr_vol * fr_mask.to(fr_vol)\n",
    "        lr_vol = lr_vol * subj[\"lr_brain_mask\"][\"data\"].to(lr_vol)\n",
    "\n",
    "        subj_result = SubjResult(\n",
    "            subj_id=subj[\"subj_id\"],\n",
    "            full_res=fr_vol,\n",
    "            low_res=lr_vol,\n",
    "            full_res_predicted=full_res_predicted,\n",
    "            full_res_cubic_spline=full_res_cubic_spline,\n",
    "        )\n",
    "\n",
    "        test_vol_results.append(subj_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis_subj_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for prediction.\n",
    "tensor_key = \"full_res_predicted\"\n",
    "pred_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "pred_dir_map = pred_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for cubic spline interpolation.\n",
    "tensor_key = \"full_res_cubic_spline\"\n",
    "cspline_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "cspline_dir_map = cspline_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map.\n",
    "tensor_key = \"full_res\"\n",
    "fr_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "fr_dir_map = fr_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate FA-weighted diffusion direction map for low-res input.\n",
    "tensor_key = \"low_res\"\n",
    "lr_dir_map = pitn.viz.direction_map(\n",
    "    test_vol_results[vis_subj_idx].__getattribute__(tensor_key).data.cpu().numpy()\n",
    ")\n",
    "# Set channels last for matplotlib\n",
    "lr_dir_map = lr_dir_map.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_idx = (slice(None, None, None), slice(None, None, None), 100)\n",
    "low_res_slice_idx = tuple(s // 2 if isinstance(s, int) else s for s in slice_idx)\n",
    "print(slice_idx)\n",
    "print(low_res_slice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cspline_dir_map.shape\n",
    "fr_dir_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(pred_dir_map[slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"pred_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(cspline_dir_map[slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"cubic_spline_dir_map_sample.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(fr_dir_map[slice_idx]))\n",
    "# plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"ground_truth_dir_map_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(np.rot90(lr_dir_map[low_res_slice_idx]))\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(experiment_results_dir / \"low_res_map_sample.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"jet\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error between FR and prediction.\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(np.rot90(dti[j_col]), cmap=cmap, interpolation=None)\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Per-Image Normalization\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_per_img_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"jet\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "max_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95)\n",
    "min_dti = np.quantile(np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05)\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dti,\n",
    "            vmax=max_dti,\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        axs.append(ax)\n",
    "\n",
    "color_norm = mpl.colors.Normalize(vmin=min_dti, vmax=max_dti)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap),\n",
    "    ax=axs,\n",
    "    location=\"right\",\n",
    "    fraction=0.1,\n",
    "    pad=0.03,\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Normalized over All Images\",\n",
    "    y=max_subplot_height + 0.015,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_global_norm.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel-Wise Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, low-res input, and root squared error\n",
    "# Normalize by index in the DTI coefficients.\n",
    "# Reshape and concatenate the dtis in order to compute the quantiles of images with\n",
    "# different shapes (e.g., the low-res input patch).\n",
    "\n",
    "channel_names = [\"Dxx\", \"Dxy\", \"Dyy\", \"Dxz\", \"Dyz\", \"Dzz\"]\n",
    "dti_names = [\n",
    "    \"Full-Res\",\n",
    "    \"Low-Res Input\",\n",
    "    \"Cubic Spline\",\n",
    "    \"Predicted\",\n",
    "    \"Root Squared Error\\nFR vs. Prediction\",\n",
    "]\n",
    "cmap = \"coolwarm\"\n",
    "# cmaps = [\"Reds\", \"Greys\", \"Greens\", \"Purples\", \"Greys\", \"Blues\", ]\n",
    "\n",
    "dtis = [\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res.data[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .low_res[(slice(None), *low_res_slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "    test_vol_results[vis_subj_idx].full_res_cubic_spline[(slice(None), *slice_idx)],\n",
    "    test_vol_results[vis_subj_idx]\n",
    "    .full_res_predicted[(slice(None), *slice_idx)]\n",
    "    .cpu()\n",
    "    .numpy(),\n",
    "]\n",
    "\n",
    "# Add root squared error\n",
    "dtis.append(np.sqrt((dtis[0] - dtis[-1]) ** 2))\n",
    "\n",
    "\n",
    "# Don't take the absolute max and min values, as there exist some extreme (e.g., > 3\n",
    "# orders of magnitude) outliers. Instead, take some percente quantile.\n",
    "max_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.95, axis=1\n",
    ")\n",
    "min_dtis = np.quantile(\n",
    "    np.concatenate([di.reshape(6, -1) for di in dtis], axis=1), 0.05, axis=1\n",
    ")\n",
    "\n",
    "max_dtis = np.max(np.abs([max_dtis, min_dtis]), axis=0)\n",
    "min_dtis = -1 * max_dtis\n",
    "\n",
    "nrows = len(dtis)\n",
    "ncols = len(channel_names)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7), dpi=160)\n",
    "\n",
    "grid = mpl.gridspec.GridSpec(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figure=fig,\n",
    "    hspace=0.05,\n",
    "    wspace=0.05,\n",
    ")\n",
    "\n",
    "axs = list()\n",
    "max_subplot_height = 0\n",
    "for i_row in range(nrows):\n",
    "    dti = dtis[i_row]\n",
    "    axs_cols = list()\n",
    "\n",
    "    for j_col in range(ncols):\n",
    "        ax = fig.add_subplot(grid[i_row, j_col])\n",
    "        ax.imshow(\n",
    "            np.rot90(dti[j_col]),\n",
    "            cmap=cmap,\n",
    "            interpolation=None,\n",
    "            vmin=min_dtis[j_col],\n",
    "            vmax=max_dtis[j_col],\n",
    "        )\n",
    "        if ax.get_subplotspec().is_first_col():\n",
    "            ax.set_ylabel(dti_names[i_row], size=\"small\")\n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel(channel_names[j_col])\n",
    "\n",
    "        # Update highest subplot to put the `suptitle` later on.\n",
    "        max_subplot_height = max(\n",
    "            max_subplot_height, ax.get_position(original=False).get_points()[1, 1]\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        axs_cols.append(ax)\n",
    "\n",
    "    axs.append(axs_cols)\n",
    "\n",
    "# Place colorbars on each column.\n",
    "for j_col in range(ncols):\n",
    "\n",
    "    full_col_ax = [axs[i][j_col] for i in range(nrows)]\n",
    "\n",
    "    color_norm = mpl.colors.Normalize(vmin=min_dtis[j_col], vmax=max_dtis[j_col])\n",
    "\n",
    "    color_mappable = mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap)\n",
    "    cbar = fig.colorbar(\n",
    "        color_mappable,\n",
    "        ax=full_col_ax,\n",
    "        location=\"top\",\n",
    "        orientation=\"horizontal\",\n",
    "        pad=0.01,\n",
    "        shrink=0.85,\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=8, rotation=35)\n",
    "    cbar.ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:g}\"))\n",
    "#     cbar.ax.ticklabel_format(scilimits=(3, -3), useOffset=False)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"DTI Channel Breakdown, Channel-Wise Normalization\",\n",
    "    y=max_subplot_height + 0.01,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"DTI_channel_sample_channel_wise_norm.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment is complete, move the results directory to its final location.\n",
    "if experiment_results_dir != final_experiment_results_dir:\n",
    "    print(\"Moving out of tmp location\")\n",
    "    experiment_results_dir = experiment_results_dir.rename(final_experiment_results_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
