{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain in the Net\n",
    "Replication of *Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images*\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "Source work:\n",
    "`S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:32.402513Z",
     "iopub.status.busy": "2021-04-07T17:21:32.401856Z",
     "iopub.status.idle": "2021-04-07T17:21:35.720656Z",
     "shell.execute_reply": "2021-04-07T17:21:35.720043Z",
     "shell.execute_reply.started": "2021-04-07T17:21:32.402354Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/pitn/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning:\n",
      "\n",
      "Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "from typing import Generator\n",
    "\n",
    "import ants\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import nilearn.plotting\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import torchvision\n",
    "import einops\n",
    "from natsort import natsorted\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:35.721812Z",
     "iopub.status.busy": "2021-04-07T17:21:35.721646Z",
     "iopub.status.idle": "2021-04-07T17:21:37.173496Z",
     "shell.execute_reply": "2021-04-07T17:21:37.172709Z",
     "shell.execute_reply.started": "2021-04-07T17:21:35.721792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.175126Z",
     "iopub.status.busy": "2021-04-07T17:21:37.174927Z",
     "iopub.status.idle": "2021-04-07T17:21:37.180379Z",
     "shell.execute_reply": "2021-04-07T17:21:37.179839Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.175104Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-specific scripts\n",
    "# It's easier to import it this way rather than make an entirely new package, due to\n",
    "# conflicts with local packages and anaconda installations.\n",
    "# You made me do this, poor python package management!!\n",
    "if \"PROJECT_ROOT\" in os.environ:\n",
    "    src_location = str(Path(os.environ[\"PROJECT_ROOT\"]).resolve())\n",
    "else:\n",
    "    src_location = str(Path(\"../../\").resolve())\n",
    "sys.path.append(src_location)\n",
    "import src as pitn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.181561Z",
     "iopub.status.busy": "2021-04-07T17:21:37.181405Z",
     "iopub.status.idle": "2021-04-07T17:21:37.224912Z",
     "shell.execute_reply": "2021-04-07T17:21:37.224313Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.181542Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch setup\n",
    "\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.226251Z",
     "iopub.status.busy": "2021-04-07T17:21:37.226090Z",
     "iopub.status.idle": "2021-04-07T17:21:37.375233Z",
     "shell.execute_reply": "2021-04-07T17:21:37.374606Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.226231Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2021-04-07T17:21:37.237106+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-70-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 237808e3f4bf2c600f2548b66c3df12867c6593e\n",
      "\n",
      "ants             : 0.2.7\n",
      "skimage          : 0.18.1\n",
      "nibabel          : 3.2.1\n",
      "dipy             : 1.4.0\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "einops           : 0.3.0\n",
      "pytorch_lightning: 1.2.6\n",
      "seaborn          : 0.11.1\n",
      "pandas           : 1.2.3\n",
      "torch            : 1.8.1\n",
      "matplotlib       : 3.4.1\n",
      "torchvision      : 0.2.2\n",
      "numpy            : 1.20.2\n",
      "nilearn          : 0.7.1\n",
      "torchio          : 0.18.31\n",
      "natsort          : 7.1.1\n",
      "\n",
      "CUDA Version:  11.1\n"
     ]
    }
   ],
   "source": [
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Version: \", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.376613Z",
     "iopub.status.busy": "2021-04-07T17:21:37.376445Z",
     "iopub.status.idle": "2021-04-07T17:21:37.380825Z",
     "shell.execute_reply": "2021-04-07T17:21:37.380267Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.376592Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"]) / \"hcp\"\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"]) / \"hcp\"\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Function & Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.381786Z",
     "iopub.status.busy": "2021-04-07T17:21:37.381638Z",
     "iopub.status.idle": "2021-04-07T17:21:37.387345Z",
     "shell.execute_reply": "2021-04-07T17:21:37.386759Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.381768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For more clearly designating the return values of a reader function given to\n",
    "# the `torchio.Image` object.\n",
    "ReaderOutput = collections.namedtuple(\"ReaderOutput\", [\"dwi\", \"affine\"])\n",
    "\n",
    "\n",
    "def nifti_reader(\n",
    "    f_dwi,\n",
    ") -> ReaderOutput:\n",
    "    \"\"\"Reader that reads in NIFTI files quickly.\n",
    "\n",
    "    Meant for use with the `torchio.Image` object and its sub-classes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load with nibabel first to get the correct affine matrix. See\n",
    "    # <https://github.com/ANTsX/ANTsPy/issues/52> for why I don't trust antspy for this.\n",
    "    # This does not require loading the entire NIFTI file into memory.\n",
    "    affine = nib.load(f_dwi).affine.copy()\n",
    "    affine = affine.astype(np.float32)\n",
    "    print(f\"Loading NIFTI image: {f_dwi}\", flush=True)\n",
    "    # Load entire image with antspy, then slice and (possibly) downsample that full image.\n",
    "    # A float32 is the smallest representation that doesn't lose data.\n",
    "    dwi = ants.image_read(str(f_dwi), pixeltype=\"float\")\n",
    "    print(\"\\tLoaded NIFTI image\", flush=True)\n",
    "\n",
    "    # Use `torch.tensor()` to explicitly copy the numpy array. May have issues with\n",
    "    # underlying memory getting garbage collected when using `torch.from_numpy`.\n",
    "    # <https://pytorch.org/docs/1.8.0/generated/torch.tensor.html#torch.tensor>\n",
    "    return ReaderOutput(dwi=torch.tensor(dwi.view()), affine=torch.tensor(affine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.388419Z",
     "iopub.status.busy": "2021-04-07T17:21:37.388205Z",
     "iopub.status.idle": "2021-04-07T17:21:37.412462Z",
     "shell.execute_reply": "2021-04-07T17:21:37.411906Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.388395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torchio.Transform functions/objects.\n",
    "\n",
    "\n",
    "class BValSelectionTransform(torchio.SpatialTransform):\n",
    "    \"\"\"Sub-selects scans that are within a certain range of bvals.\n",
    "\n",
    "    Expects:\n",
    "    - volumes in canonical (RAS+) format with *channels first.*\n",
    "    - bvecs to be of shape (N, 3), with N being the number of scans/bvals.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bval_range: tuple, bval_key, bvec_key, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.bval_range = bval_range\n",
    "        self.bval_key = bval_key\n",
    "        self.bvec_key = bvec_key\n",
    "\n",
    "    def apply_transform(self, subject: torchio.Subject) -> torchio.Subject:\n",
    "        print(f\"Selecting with bvals: Subject {subject.subj_id}\", flush=True)\n",
    "\n",
    "        for img in self.get_images(subject):\n",
    "            bvals = img[self.bval_key]\n",
    "            scans_to_keep = (self.bval_range[0] <= bvals) & (\n",
    "                bvals <= self.bval_range[-1]\n",
    "            )\n",
    "            img[self.bvec_key] = img[self.bvec_key][scans_to_keep, :]\n",
    "            img.set_data(img.data[scans_to_keep, ...])\n",
    "            img[self.bval_key] = img[self.bval_key][scans_to_keep]\n",
    "        print(\"\\tSelected\", flush=True)\n",
    "        return subject\n",
    "\n",
    "\n",
    "class MeanDownsampleTransform(torchio.SpatialTransform):\n",
    "    \"\"\"Mean downsampling transformation.\n",
    "\n",
    "    Expects volumes in canonical (RAS+) format with *channels first.*\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, downsample_factor: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.downsample_factor = downsample_factor\n",
    "\n",
    "    def apply_transform(self, subject: torchio.Subject) -> torchio.Subject:\n",
    "        print(f\"Downsampling: Subject {subject.subj_id}\", flush=True)\n",
    "        # Get reference to Image objects that have been included for transformation.\n",
    "\n",
    "        for img in self.get_images(subject):\n",
    "            img[\"downsample_factor\"] = self.downsample_factor\n",
    "            if self.downsample_factor == 1:\n",
    "                continue\n",
    "            # Determine dimension-specific downsample factors\n",
    "            img_ndarray = img.data.numpy()\n",
    "            dim_factors = np.asarray(\n",
    "                [\n",
    "                    self.downsample_factor,\n",
    "                ]\n",
    "                * img_ndarray.ndim\n",
    "            )\n",
    "            # Only spatial dimensions should be downsampled.\n",
    "            if img.data.ndim > 3:\n",
    "                # Don't downsample the channels\n",
    "                dim_factors[0] = 1\n",
    "                # Or anything else outside of spatial dims.\n",
    "                dim_factors[4:] = 1\n",
    "\n",
    "            downsample_vol = skimage.transform.downscale_local_mean(\n",
    "                img_ndarray, factors=tuple(dim_factors), cval=0\n",
    "            )\n",
    "            # Pad with a small number of 0's to account for sampling at the edge of the\n",
    "            # full-res image.\n",
    "            # Don't pad dims that were not scaled.\n",
    "            padding = ((dim_factors - 1).astype(bool)).astype(int).tolist()\n",
    "            padding = [(p, p) for p in padding]\n",
    "            downsample_vol = np.pad(downsample_vol, pad_width=padding, mode=\"constant\")\n",
    "\n",
    "            downsample_vol = torch.from_numpy(\n",
    "                downsample_vol.astype(img_ndarray.dtype)\n",
    "            ).to(img.data.dtype)\n",
    "            img.set_data(downsample_vol)\n",
    "\n",
    "            scaled_affine = img.affine.copy()\n",
    "            # Scale the XYZ coordinates on the main diagonal.\n",
    "            scaled_affine[(0, 1, 2), (0, 1, 2)] = (\n",
    "                scaled_affine[(0, 1, 2), (0, 1, 2)] * self.downsample_factor\n",
    "            )\n",
    "            img.affine = scaled_affine\n",
    "        print(\"\\tDownsampled\", flush=True)\n",
    "        return subject\n",
    "\n",
    "\n",
    "class FitDTITransform(torchio.SpatialTransform, torchio.IntensityTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bval_key,\n",
    "        bvec_key,\n",
    "        mask_img_key=None,\n",
    "        fit_method=\"WLS\",\n",
    "        tensor_model_kwargs=dict(),\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.bval_key = bval_key\n",
    "        self.bvec_key = bvec_key\n",
    "        self.mask_img_key = mask_img_key\n",
    "        self.fit_method = fit_method\n",
    "        self.tensor_model_kwargs = tensor_model_kwargs\n",
    "\n",
    "    def apply_transform(self, subject: torchio.Subject) -> torchio.Subject:\n",
    "\n",
    "        print(f\"Fitting to DTI: Subject {subject.subj_id}\", flush=True)\n",
    "        mask_img = subject[self.mask_img_key] if self.mask_img_key is not None else None\n",
    "        for img in self.get_images(subject):\n",
    "\n",
    "            gradient_table = dipy.core.gradients.gradient_table_from_bvals_bvecs(\n",
    "                bvals=img[self.bval_key],\n",
    "                bvecs=img[self.bvec_key],\n",
    "            )\n",
    "\n",
    "            tensor_model = dipy.reconst.dti.TensorModel(\n",
    "                gradient_table, fit_method=self.fit_method, **self.tensor_model_kwargs\n",
    "            )\n",
    "            print(f\"\\tDWI shape: {img.data.shape}\", flush=True)\n",
    "            # dipy does not like the channels being first, apparently.\n",
    "            if mask_img is not None:\n",
    "                dti = tensor_model.fit(\n",
    "                    np.moveaxis(img.numpy(), 0, -1),\n",
    "                    mask=mask_img.numpy().squeeze().astype(bool),\n",
    "                )\n",
    "            else:\n",
    "                dti = tensor_model.fit(np.moveaxis(img.numpy(), 0, -1))\n",
    "\n",
    "            # Pull only the lower-triangular part of the DTI (the non-symmetric\n",
    "            # coefficients.)\n",
    "            # Do it all in one line to minimize the time that the DTI's have to be\n",
    "            # duplicated in memory.\n",
    "            img.set_data(\n",
    "                torch.from_numpy(\n",
    "                    np.moveaxis(dti.lower_triangular().astype(np.float32), -1, 0)\n",
    "                ).to(img.data)\n",
    "            )\n",
    "            print(f\"\\tDTI shape: {img.shape}\", flush=True)\n",
    "        print(f\"\\tFitted DTI model: {img.data.shape}\", flush=True)\n",
    "\n",
    "        return subject\n",
    "\n",
    "\n",
    "class RenameImageTransform(torchio.Transform):\n",
    "    def __init__(self, name_mapping: dict, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.name_mapping = name_mapping\n",
    "\n",
    "    def apply_transform(self, subject: torchio.Subject) -> torchio.Subject:\n",
    "        for old_name, new_name in self.name_mapping.items():\n",
    "            tmp = subject[old_name]\n",
    "            subject.remove_image(old_name)\n",
    "            subject.add_image(tmp, new_name)\n",
    "        subject.update_attributes()\n",
    "        return subject\n",
    "\n",
    "\n",
    "class ImageToDictTransform(torchio.Transform):\n",
    "    \"\"\"Convert a Subject Image to a simple dict item.\n",
    "\n",
    "    Removes the `include`ed keys from calculation of the Subject's properties, such as\n",
    "    `spatial_shape`, `spacing`, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply_transform(self, subject: torchio.Subject) -> torchio.Subject:\n",
    "        for img_name in self.include:\n",
    "\n",
    "            img_dict = dict(subject[img_name])\n",
    "            subject.remove_image(img_name)\n",
    "\n",
    "            subject[img_name] = img_dict\n",
    "\n",
    "        subject.update_attributes()\n",
    "        return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.414769Z",
     "iopub.status.busy": "2021-04-07T17:21:37.414612Z",
     "iopub.status.idle": "2021-04-07T17:21:37.438120Z",
     "shell.execute_reply": "2021-04-07T17:21:37.437570Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.414750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definitions for sampling and loading patches from volumes of different resolutions in a `pytorch.utils.data.DataLoader`.\n",
    "\n",
    "\n",
    "def extract_patch(img, img_spatial_shape, index_ini, patch_size) -> torchio.Image:\n",
    "    \"\"\"Draws a patch from img, given an initial index and patch size.\"\"\"\n",
    "\n",
    "    # Just take it straight from `torchio.transforms.Copy.apply_transform`\n",
    "    # and `torchio.sampler.Sampler`!\n",
    "\n",
    "    shape = np.array(img_spatial_shape, dtype=np.uint16)\n",
    "    index_ini = np.array(index_ini, dtype=np.uint16)\n",
    "    patch_size = np.array(patch_size, dtype=np.uint16)\n",
    "    index_fin = index_ini + patch_size\n",
    "\n",
    "    crop_ini = index_ini.tolist()\n",
    "    crop_fin = (shape - index_fin).tolist()\n",
    "    start = ()\n",
    "    cropping = sum(zip(crop_ini, crop_fin), start)\n",
    "\n",
    "    low = cropping[::2]\n",
    "    high = cropping[1::2]\n",
    "    initial_idx = low\n",
    "    final_idx = np.array(img_spatial_shape) - high\n",
    "\n",
    "    i0, j0, k0 = initial_idx\n",
    "    i1, j1, k1 = final_idx\n",
    "\n",
    "    return img[:, i0:i1, j0:j1, k0:k1]\n",
    "\n",
    "\n",
    "# Custom sampler for sampling multiple volumes of different resolutions.\n",
    "class MultiresSampler(torchio.LabelSampler):\n",
    "    \"\"\"\n",
    "\n",
    "    source_img_key: Key to the Subject that will fetch the source (a.k.a., the high-res\n",
    "        or full-res) image.\n",
    "\n",
    "    low_res_key: Key to the Subject that will fetch the low-res image. This image is\n",
    "        assumed to be a dictionary with a 'data' key.\n",
    "\n",
    "    downsample_factor_key: Key to the low-res image dict that gives the downsample\n",
    "        factor.\n",
    "\n",
    "    source_spatial_patch_size: 3-tuple of `(W, H, D)` that gives the spatial size of\n",
    "        patches drawn from the source image.\n",
    "\n",
    "    low_res_spatial_patch_size: 3-tuple of `(W, H, D)` that gives the spatial size of\n",
    "        patches drawn from the low-res image.\n",
    "\n",
    "    subj_keys_to_copy: Tuple of keys to copy from the Subject into the returned sample\n",
    "        patch(es).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        source_img_key,\n",
    "        low_res_key,\n",
    "        downsample_factor_key,\n",
    "        source_spatial_patch_size: tuple,\n",
    "        low_res_spatial_patch_size: tuple,\n",
    "        label_name,\n",
    "        subj_keys_to_copy=tuple(),\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            patch_size=source_spatial_patch_size, label_name=label_name, **kwargs\n",
    "        )\n",
    "        self.source_img_key = source_img_key\n",
    "        self.low_res_key = low_res_key\n",
    "        self.downsample_factor_key = downsample_factor_key\n",
    "        self.subj_keys_to_copy = subj_keys_to_copy\n",
    "        self.source_spatial_patch_size = source_spatial_patch_size\n",
    "        self.low_res_spatial_patch_size = low_res_spatial_patch_size\n",
    "\n",
    "    def __call__(\n",
    "        self, subject: torchio.Subject, num_patches=None\n",
    "    ) -> Generator[torchio.Subject, None, None]:\n",
    "\n",
    "        # Setup copied from the `torchio.WeightedSampler.__call__` function definition.\n",
    "        subject.check_consistent_space()\n",
    "        if np.any(self.patch_size > subject.spatial_shape):\n",
    "            message = (\n",
    "                f\"Patch size {tuple(self.patch_size)} cannot be\"\n",
    "                f\" larger than image size {tuple(subject.spatial_shape)}\"\n",
    "            )\n",
    "            raise RuntimeError(message)\n",
    "        probability_map = self.get_probability_map(subject)\n",
    "        probability_map = self.process_probability_map(probability_map, subject)\n",
    "        cdf = self.get_cumulative_distribution_function(probability_map)\n",
    "\n",
    "        patches_left = num_patches if num_patches is not None else True\n",
    "        while patches_left:\n",
    "            subj_fields_transfer = dict(\n",
    "                ((k, subject[k]) for k in self.subj_keys_to_copy)\n",
    "            )\n",
    "\n",
    "            # Sample an index from the full-res image.\n",
    "            source_index_ini = self.get_random_index_ini(probability_map, cdf)\n",
    "            # Create a new subject that only contains patches.\n",
    "            # Add the patch from the full-res image into the subject.\n",
    "            patch_subj = torchio.Subject(\n",
    "                **(\n",
    "                    dict(\n",
    "                        [\n",
    "                            (\n",
    "                                self.source_img_key,\n",
    "                                torchio.ScalarImage(\n",
    "                                    tensor=extract_patch(\n",
    "                                        subject[self.source_img_key].data,\n",
    "                                        img_spatial_shape=subject[\n",
    "                                            self.source_img_key\n",
    "                                        ].shape[1:],\n",
    "                                        index_ini=source_index_ini,\n",
    "                                        patch_size=self.source_spatial_patch_size,\n",
    "                                    ),\n",
    "                                    affine=subject[self.source_img_key].affine,\n",
    "                                ),\n",
    "                            ),\n",
    "                            *subj_fields_transfer.items(),\n",
    "                        ],\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # Include the index in the subject.\n",
    "            patch_subj[\"index_ini\"] = np.array(source_index_ini).astype(int)\n",
    "            # Crop low-res image and add to the subject.\n",
    "            lr_index_ini = tuple(\n",
    "                np.array(source_index_ini).astype(int)\n",
    "                // subject[self.low_res_key][self.downsample_factor_key]\n",
    "            )\n",
    "\n",
    "            lr_patch = extract_patch(\n",
    "                subject[self.low_res_key][\"data\"],\n",
    "                img_spatial_shape=subject[self.low_res_key][\"data\"].shape[1:],\n",
    "                index_ini=lr_index_ini,\n",
    "                patch_size=self.low_res_spatial_patch_size,\n",
    "            )\n",
    "            if lr_patch.numel() == 0:\n",
    "                raise RuntimeError(\n",
    "                    f\"ERROR: Invalid low-res patch: {lr_patch}, {lr_patch.shape} |\"\n",
    "                    + f\"Index: {lr_index_ini}\"\n",
    "                )\n",
    "            # Add a dict to the subject patch, rather than a `torchio.Image`,\n",
    "            # because the fr and lr patch shapes will be different, and fail\n",
    "            # `torchio`'s shape consistency checks.)\n",
    "            lr_patch_dict = dict()\n",
    "            lr_patch_dict.update(subject[self.low_res_key])\n",
    "            lr_patch_dict.update({\"data\": lr_patch})\n",
    "\n",
    "            patch_subj[self.low_res_key] = lr_patch_dict\n",
    "            # Return the new patch subject.\n",
    "            yield patch_subj\n",
    "            if num_patches is not None:\n",
    "                patches_left -= 1\n",
    "\n",
    "\n",
    "class MultiresGridSampler(torchio.GridSampler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        source_img_key,\n",
    "        low_res_key,\n",
    "        downsample_factor_key,\n",
    "        source_spatial_patch_size: tuple,\n",
    "        low_res_spatial_patch_size: tuple,\n",
    "        subj_keys_to_copy=tuple(),\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__(patch_size=source_spatial_patch_size, **kwargs)\n",
    "        self.source_img_key = source_img_key\n",
    "        self.low_res_key = low_res_key\n",
    "        self.downsample_factor_key = downsample_factor_key\n",
    "        self.subj_keys_to_copy = subj_keys_to_copy\n",
    "        self.source_spatial_patch_size = source_spatial_patch_size\n",
    "        self.low_res_spatial_patch_size = low_res_spatial_patch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        location = self.locations[index]\n",
    "        source_index_ini = location[:3]\n",
    "\n",
    "        subj_fields_transfer = dict(\n",
    "            ((k, self.subject[k]) for k in self.subj_keys_to_copy)\n",
    "        )\n",
    "\n",
    "        # Create a new subject that only contains patches.\n",
    "        # Add the patch from the full-res image into the subject.\n",
    "        patch_subj = torchio.Subject(\n",
    "            **(\n",
    "                dict(\n",
    "                    [\n",
    "                        (\n",
    "                            self.source_img_key,\n",
    "                            torchio.ScalarImage(\n",
    "                                tensor=extract_patch(\n",
    "                                    self.subject[self.source_img_key].data,\n",
    "                                    img_spatial_shape=self.subject[\n",
    "                                        self.source_img_key\n",
    "                                    ].shape[1:],\n",
    "                                    index_ini=source_index_ini,\n",
    "                                    patch_size=self.source_spatial_patch_size,\n",
    "                                ),\n",
    "                                affine=self.subject[self.source_img_key].affine,\n",
    "                            ),\n",
    "                        ),\n",
    "                        *subj_fields_transfer.items(),\n",
    "                    ],\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Include the index in the subject.\n",
    "        patch_subj[\"index_ini\"] = np.array(source_index_ini).astype(int)\n",
    "        # Crop low-res image and add to the subject.\n",
    "        lr_index_ini = tuple(\n",
    "            np.array(source_index_ini).astype(int)\n",
    "            // self.subject[self.low_res_key][self.downsample_factor_key]\n",
    "        )\n",
    "\n",
    "        lr_patch = extract_patch(\n",
    "            self.subject[self.low_res_key][\"data\"],\n",
    "            img_spatial_shape=self.subject[self.low_res_key][\"data\"].shape[1:],\n",
    "            index_ini=lr_index_ini,\n",
    "            patch_size=self.low_res_spatial_patch_size,\n",
    "        )\n",
    "        if lr_patch.numel() == 0:\n",
    "            raise RuntimeError(\n",
    "                f\"ERROR: Invalid low-res patch: {lr_patch}, {lr_patch.shape} |\"\n",
    "                + f\"Index: {lr_index_ini}\"\n",
    "            )\n",
    "        # Add a dict to the subject patch, rather than a `torchio.Image`,\n",
    "        # because the fr and lr patch shapes will be different, and fail\n",
    "        # `torchio`'s shape consistency checks.)\n",
    "        lr_patch_dict = dict()\n",
    "        lr_patch_dict.update(self.subject[self.low_res_key])\n",
    "        lr_patch_dict.update({\"data\": lr_patch})\n",
    "\n",
    "        patch_subj[self.low_res_key] = lr_patch_dict\n",
    "\n",
    "        return patch_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.439598Z",
     "iopub.status.busy": "2021-04-07T17:21:37.439443Z",
     "iopub.status.idle": "2021-04-07T17:21:37.443885Z",
     "shell.execute_reply": "2021-04-07T17:21:37.443360Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.439579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return type wrapper\n",
    "MultiresSample = collections.namedtuple(\"MultiresSample\", (\"low_res\", \"full_res\"))\n",
    "\n",
    "# Collate function for the DataLoader to combine multiple samples.\n",
    "def collate_subj(samples, full_res_key: str, low_res_key: str):\n",
    "    full_res_stack = torch.stack([subj[full_res_key].data for subj in samples])\n",
    "    # Assume the low-res data are dicts, not `torchio.Image`'s\n",
    "    low_res_stack = torch.stack([subj[low_res_key][\"data\"] for subj in samples])\n",
    "\n",
    "    return MultiresSample(low_res=low_res_stack, full_res=full_res_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.444770Z",
     "iopub.status.busy": "2021-04-07T17:21:37.444621Z",
     "iopub.status.idle": "2021-04-07T17:21:37.448540Z",
     "shell.execute_reply": "2021-04-07T17:21:37.447977Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.444752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsample_factor = 2\n",
    "# Include b=0 shells and b=1000 shells for DTI fitting.\n",
    "bval_range = (0, 1500)\n",
    "dti_fit_method = \"WLS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.449592Z",
     "iopub.status.busy": "2021-04-07T17:21:37.449444Z",
     "iopub.status.idle": "2021-04-07T17:21:37.460734Z",
     "shell.execute_reply": "2021-04-07T17:21:37.460055Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.449574Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-5b7beb527582>:25: UserWarning:\n",
      "\n",
      "WARNING: Sub-selecting participants for dev and debugging. Subj IDs selected: ['156637', '644246', '227432', '810439', '751348', '753251', '140117', '397154']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{140117: PosixPath('/mnt/storage/data/pitn/hcp/140117/T1w/Diffusion'),\n",
       " 156637: PosixPath('/mnt/storage/data/pitn/hcp/156637/T1w/Diffusion'),\n",
       " 227432: PosixPath('/mnt/storage/data/pitn/hcp/227432/T1w/Diffusion'),\n",
       " 397154: PosixPath('/mnt/storage/data/pitn/hcp/397154/T1w/Diffusion'),\n",
       " 644246: PosixPath('/mnt/storage/data/pitn/hcp/644246/T1w/Diffusion'),\n",
       " 751348: PosixPath('/mnt/storage/data/pitn/hcp/751348/T1w/Diffusion'),\n",
       " 753251: PosixPath('/mnt/storage/data/pitn/hcp/753251/T1w/Diffusion'),\n",
       " 810439: PosixPath('/mnt/storage/data/pitn/hcp/810439/T1w/Diffusion')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: dict = dict()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "selected_ids = random.sample(selected_ids, 4)\n",
    "warnings.warn(\n",
    "    \"WARNING: Sub-selecting participants for dev and debugging. \"\n",
    "    + f\"Subj IDs selected: {selected_ids}\"\n",
    ")\n",
    "##\n",
    "\n",
    "selected_ids = natsorted(list(map(lambda s: int(s), selected_ids)))\n",
    "\n",
    "for subj_id in selected_ids:\n",
    "    subj_dirs[subj_id] = data_dir / f\"{subj_id}/T1w/Diffusion\"\n",
    "    assert subj_dirs[subj_id].exists()\n",
    "subj_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 90 scans are taken from the $b=1000 \\ s/mm^2$. However, the $b=0$ shells are still required for fitting the diffusion tensors (DTI's), so those will need to be kept, too.\n",
    "\n",
    "To find those, sub-select with the $0 < bvals < 1500$, or roughly thereabout. A b-val of $995$ or $1005$ still counts as a b=1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:21:37.461870Z",
     "iopub.status.busy": "2021-04-07T17:21:37.461696Z",
     "iopub.status.idle": "2021-04-07T17:33:45.907977Z",
     "shell.execute_reply": "2021-04-07T17:33:45.907417Z",
     "shell.execute_reply.started": "2021-04-07T17:21:37.461849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/140117/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 140117\n",
      "\tSelected\n",
      "Downsampling: Subject 140117\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 140117\n",
      "\tDWI shape: torch.Size([108, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 140117\n",
      "\tDWI shape: torch.Size([108, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/156637/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 156637\n",
      "\tSelected\n",
      "Downsampling: Subject 156637\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 156637\n",
      "\tDWI shape: torch.Size([108, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 156637\n",
      "\tDWI shape: torch.Size([108, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/227432/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 227432\n",
      "\tSelected\n",
      "Downsampling: Subject 227432\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 227432\n",
      "\tDWI shape: torch.Size([108, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 227432\n",
      "\tDWI shape: torch.Size([108, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/397154/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 397154\n",
      "\tSelected\n",
      "Downsampling: Subject 397154\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 397154\n",
      "\tDWI shape: torch.Size([108, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 397154\n",
      "\tDWI shape: torch.Size([108, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/644246/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 644246\n",
      "\tSelected\n",
      "Downsampling: Subject 644246\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 644246\n",
      "\tDWI shape: torch.Size([108, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 644246\n",
      "\tDWI shape: torch.Size([108, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/751348/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 751348\n",
      "\tSelected\n",
      "Downsampling: Subject 751348\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 751348\n",
      "\tDWI shape: torch.Size([108, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 751348\n",
      "\tDWI shape: torch.Size([108, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/753251/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 753251\n",
      "\tSelected\n",
      "Downsampling: Subject 753251\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 753251\n",
      "\tDWI shape: torch.Size([72, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 753251\n",
      "\tDWI shape: torch.Size([72, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "Loading NIFTI image: /mnt/storage/data/pitn/hcp/810439/T1w/Diffusion/data.nii.gz\n",
      "\tLoaded NIFTI image\n",
      "Selecting with bvals: Subject 810439\n",
      "\tSelected\n",
      "Downsampling: Subject 810439\n",
      "\tDownsampled\n",
      "Fitting to DTI: Subject 810439\n",
      "\tDWI shape: torch.Size([72, 145, 174, 145])\n",
      "\tDTI shape: (6, 145, 174, 145)\n",
      "\tFitted DTI model: torch.Size([6, 145, 174, 145])\n",
      "Fitting to DTI: Subject 810439\n",
      "\tDWI shape: torch.Size([72, 75, 89, 75])\n",
      "\tDTI shape: (6, 75, 89, 75)\n",
      "\tFitted DTI model: torch.Size([6, 75, 89, 75])\n",
      "===Data Loaded & Transformed===\n"
     ]
    }
   ],
   "source": [
    "# Import all image data into a sequence of `torchio.Subject` objects.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "    # Sub-select volumes with only bvals in a certain range. E.x. bvals <= 1100 mm/s^2,\n",
    "    # a.k.a. only the b=0 and b=1000 shells.\n",
    "    bvals = torch.as_tensor(np.loadtxt(subj_dir / \"bvals\").astype(int))\n",
    "    bvecs = torch.as_tensor(np.loadtxt(subj_dir / \"bvecs\"))\n",
    "    # Reshape to be N x 3\n",
    "    if bvecs.shape[0] == 3:\n",
    "        bvecs = bvecs.T\n",
    "\n",
    "    # grad = torchio.ScalarImage(subj_dir/\"grad_dev.nii.gz\")\n",
    "    brain_mask = torchio.LabelMap(\n",
    "        subj_dir / \"nodif_brain_mask.nii.gz\",\n",
    "        type=torchio.LABEL,\n",
    "        channels_last=False,\n",
    "    )\n",
    "\n",
    "    # The brain mask is binary.\n",
    "    brain_mask.set_data(brain_mask.data.bool())\n",
    "\n",
    "    dwi = torchio.ScalarImage(\n",
    "        subj_dir / \"data.nii.gz\",\n",
    "        type=torchio.INTENSITY,\n",
    "        bvals=bvals,\n",
    "        bvecs=bvecs,\n",
    "        reader=nifti_reader,\n",
    "        channels_last=True,\n",
    "    )\n",
    "\n",
    "    subject_dict = torchio.Subject(subj_id=subj_id, dwi=dwi, brain_mask=brain_mask)\n",
    "\n",
    "    preproc_transforms = torchio.Compose(\n",
    "        [\n",
    "            torchio.transforms.ToCanonical(include=(\"dwi\", \"brain_mask\"), copy=False),\n",
    "            BValSelectionTransform(\n",
    "                bval_range=bval_range,\n",
    "                bval_key=\"bvals\",\n",
    "                bvec_key=\"bvecs\",\n",
    "                include=\"dwi\",\n",
    "                copy=False,\n",
    "            ),\n",
    "            MeanDownsampleTransform(\n",
    "                downsample_factor,\n",
    "                include=(\"dwi\", \"brain_mask\"),\n",
    "                keep={\"dwi\": \"fr_dwi\", \"brain_mask\": \"fr_brain_mask\"},\n",
    "                copy=False,\n",
    "            ),\n",
    "            RenameImageTransform(\n",
    "                {\"dwi\": \"lr_dwi\", \"brain_mask\": \"lr_brain_mask\"}, copy=False\n",
    "            ),\n",
    "            FitDTITransform(\n",
    "                \"bvals\",\n",
    "                \"bvecs\",\n",
    "                \"fr_brain_mask\",\n",
    "                fit_method=dti_fit_method,\n",
    "                include=(\"fr_dwi\"),\n",
    "                copy=False,\n",
    "            ),\n",
    "            FitDTITransform(\n",
    "                \"bvals\",\n",
    "                \"bvecs\",\n",
    "                \"lr_brain_mask\",\n",
    "                fit_method=dti_fit_method,\n",
    "                include=(\"lr_dwi\"),\n",
    "                copy=False,\n",
    "            ),\n",
    "            RenameImageTransform({\"fr_dwi\": \"fr_dti\", \"lr_dwi\": \"lr_dti\"}, copy=False),\n",
    "            ImageToDictTransform(include=(\"lr_dti\", \"lr_brain_mask\"), copy=False),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    subj_data[subj_id] = preproc_transforms(subject_dict)\n",
    "\n",
    "\n",
    "print(\"===Data Loaded & Transformed===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.908956Z",
     "iopub.status.busy": "2021-04-07T17:33:45.908799Z",
     "iopub.status.idle": "2021-04-07T17:33:45.911896Z",
     "shell.execute_reply": "2021-04-07T17:33:45.911374Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.908937Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj_dataset = torchio.SubjectsDataset(list(subj_data.values()), load_getitem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.912766Z",
     "iopub.status.busy": "2021-04-07T17:33:45.912616Z",
     "iopub.status.idle": "2021-04-07T17:33:45.917935Z",
     "shell.execute_reply": "2021-04-07T17:33:45.917408Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.912748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patch parameters\n",
    "batch_size = 32\n",
    "# 6 channels for the 6 DTI components\n",
    "channels = 6\n",
    "\n",
    "# Output patch shapes\n",
    "h_out = 14\n",
    "w_out = 14\n",
    "d_out = 14\n",
    "# Output shape after shuffling.\n",
    "output_patch_shape = (channels, h_out, w_out, d_out)\n",
    "output_spatial_patch_shape = output_patch_shape[1:]\n",
    "# This is the factor that determines how over-extended the input patch should be\n",
    "# relative to the size of the input patch.\n",
    "# $input_patch_dim = \\frac{output_patch_dim}{downsample_factor} \\times input_dilation$\n",
    "# A value of 1 indicates that the input patch dims will be exactly divided by the\n",
    "# downsample factor. A dilation > 1 increases the \"spatial extent\" of the input\n",
    "# patch, providing information outside of the target HR patch.\n",
    "input_dim_dilation = 1.57\n",
    "# Input patch parameters\n",
    "h_in = round(h_out / (downsample_factor) * input_dim_dilation)\n",
    "w_in = round(w_out / (downsample_factor) * input_dim_dilation)\n",
    "d_in = round(d_out / (downsample_factor) * input_dim_dilation)\n",
    "input_patch_shape = (channels, h_in, w_in, d_in)\n",
    "input_spatial_patch_shape = input_patch_shape[1:]\n",
    "\n",
    "# Pre-shuffle output patch sizes.\n",
    "unshuffled_channels_out = channels * downsample_factor ** 3\n",
    "# Output before shuffling\n",
    "unshuffled_output_patch_shape = (unshuffled_channels_out, h_in, w_in, d_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.918873Z",
     "iopub.status.busy": "2021-04-07T17:33:45.918710Z",
     "iopub.status.idle": "2021-04-07T17:33:45.928231Z",
     "shell.execute_reply": "2021-04-07T17:33:45.927721Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.918853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating subjects loader with 0 workers\n",
      "Test subject(s) IDs:  [227432, 751348]\n",
      "Training subject(s) IDs:  [644246, 397154, 810439, 140117, 156637, 753251]\n"
     ]
    }
   ],
   "source": [
    "# Data train/validation/test split\n",
    "# test_percent = 0.2\n",
    "test_percent = 0.5\n",
    "train_percent = 1 - test_percent\n",
    "# val_percent = 0.1\n",
    "\n",
    "num_subjs = len(subj_dataset)\n",
    "num_test_subjs = int(np.ceil(num_subjs * test_percent))\n",
    "num_train_subjs = num_subjs - num_test_subjs\n",
    "subj_list = subj_dataset.dry_iter()\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# Create partial function to collect list of samples and form a tuple of tensors.\n",
    "collate_fn = functools.partial(\n",
    "    collate_subj, full_res_key=\"fr_dti\", low_res_key=\"lr_dti\"\n",
    ")\n",
    "\n",
    "test_dataset = torchio.SubjectsDataset(subj_list[:num_test_subjs], load_getitem=False)\n",
    "# Choose the remaining for training/validation.\n",
    "subj_list = subj_list[num_test_subjs:]\n",
    "train_dataset = torchio.SubjectsDataset(subj_list, load_getitem=False)\n",
    "\n",
    "# Training patch sampler, random across all patches of all volumes.\n",
    "train_sampler = MultiresSampler(\n",
    "    source_img_key=\"fr_dti\",\n",
    "    low_res_key=\"lr_dti\",\n",
    "    downsample_factor_key=\"downsample_factor\",\n",
    "    label_name=\"fr_brain_mask\",\n",
    "    source_spatial_patch_size=output_spatial_patch_shape,\n",
    "    low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "    label_probabilities={0: 0, 1: 1},\n",
    ")\n",
    "\n",
    "patches_per_subj = 8000\n",
    "queue_max_length = patches_per_subj\n",
    "\n",
    "# Set up a torchio.Queue to act as a sampler proxy for the torch DataLoader\n",
    "train_queue = torchio.Queue(\n",
    "    train_dataset,\n",
    "    max_length=queue_max_length,\n",
    "    samples_per_volume=patches_per_subj,\n",
    "    sampler=train_sampler,\n",
    "    shuffle_patches=True,\n",
    "    shuffle_subjects=True,\n",
    "    num_workers=0,\n",
    "    #     verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_queue,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Test samplers\n",
    "test_samplers = list()\n",
    "for subj in test_dataset.dry_iter():\n",
    "    test_samplers.append(\n",
    "        MultiresGridSampler(\n",
    "            subject=subj,\n",
    "            source_img_key=\"fr_dti\",\n",
    "            low_res_key=\"lr_dti\",\n",
    "            downsample_factor_key=\"downsample_factor\",\n",
    "            source_spatial_patch_size=output_spatial_patch_shape,\n",
    "            low_res_spatial_patch_size=input_spatial_patch_shape,\n",
    "            patch_overlap=(0, 0, 0),\n",
    "        )\n",
    "    )\n",
    "\n",
    "concat_test_dataset = torch.utils.data.ConcatDataset(test_samplers)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    concat_test_dataset, batch_size=batch_size, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Test subject(s) IDs: \", [s.subj_id for s in test_dataset.dry_iter()])\n",
    "print(\"Training subject(s) IDs: \", [s.subj_id for s in train_dataset.dry_iter()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.929247Z",
     "iopub.status.busy": "2021-04-07T17:33:45.929069Z",
     "iopub.status.idle": "2021-04-07T17:33:45.934393Z",
     "shell.execute_reply": "2021-04-07T17:33:45.933821Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.929224Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shuffle operation as a function.\n",
    "def espcn_shuffle(x, channels):\n",
    "    \"\"\"Implements final-layer shuffle operation from ESPCN.\n",
    "\n",
    "    x: 4D or 5D Tensor. Expects a shape of $C \\times H \\times W \\times D$, or batched\n",
    "        with a shape of $B \\times C \\times H \\times W \\times D$.\n",
    "\n",
    "    channels: Integer giving the number of channels for the shuffled output.\n",
    "    \"\"\"\n",
    "    batched = True if x.ndim == 5 else False\n",
    "\n",
    "    if batched:\n",
    "        downsample_factor = int(np.power(x.shape[1] / channels, 1 / 3))\n",
    "        y = einops.rearrange(\n",
    "            x,\n",
    "            \"b (c r1 r2 r3) h w d -> b c (h r1) (w r2) (d r3)\",\n",
    "            c=channels,\n",
    "            r1=downsample_factor,\n",
    "            r2=downsample_factor,\n",
    "            r3=downsample_factor,\n",
    "        )\n",
    "    else:\n",
    "        downsample_factor = int(np.power(x.shape[0] / channels, 1 / 3))\n",
    "        y = einops.rearrange(\n",
    "            x,\n",
    "            \"(c r1 r2 r3) h w d -> c (h r1) (w r2) (d r3)\",\n",
    "            c=channels,\n",
    "            r1=downsample_factor,\n",
    "            r2=downsample_factor,\n",
    "            r3=downsample_factor,\n",
    "        )\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.935245Z",
     "iopub.status.busy": "2021-04-07T17:33:45.935098Z",
     "iopub.status.idle": "2021-04-07T17:33:45.941834Z",
     "shell.execute_reply": "2021-04-07T17:33:45.941326Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.935227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic conv net definition.\n",
    "class ThreeConv(torch.nn.Module):\n",
    "    \"\"\"Basic three-layer 3D conv network for DIQT.\"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, downsample_factor: int):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.downsample_factor = downsample_factor\n",
    "\n",
    "        # Set up Conv layers.\n",
    "        self.conv1 = torch.nn.Conv3d(self.channels, 50, kernel_size=(3, 3, 3))\n",
    "        self.conv2 = torch.nn.Conv3d(50, 100, kernel_size=(1, 1, 1))\n",
    "        self.conv3 = torch.nn.Conv3d(\n",
    "            100, self.channels * (self.downsample_factor ** 3), kernel_size=(3, 3, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #         breakpoint()\n",
    "        y_hat = self.conv1(x)\n",
    "        y_hat = F.relu(y_hat)\n",
    "        y_hat = self.conv2(y_hat)\n",
    "        y_hat = F.relu(y_hat)\n",
    "        y_hat = self.conv3(y_hat)\n",
    "\n",
    "        # Shuffle output.\n",
    "        y_hat = espcn_shuffle(y_hat, self.channels)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.942956Z",
     "iopub.status.busy": "2021-04-07T17:33:45.942796Z",
     "iopub.status.idle": "2021-04-07T17:33:45.950735Z",
     "shell.execute_reply": "2021-04-07T17:33:45.950196Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.942936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "class DIQTSystem(pl.LightningModule):\n",
    "    def __init__(self, channels, downsample_factor):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = channels\n",
    "        self._downsample_factor = downsample_factor\n",
    "\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        self.net = ThreeConv(self._channels, self._downsample_factor)\n",
    "\n",
    "        ## Training parameters\n",
    "        self._lr = 10e-3\n",
    "        self._betas = (0.9, 0.999)\n",
    "        self._loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = {\"train_loss\": list(), \"val_loss\": list(), \"test_loss\": list()}\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "\n",
    "    def shared_calc_loss(self, x, y):\n",
    "        y_pred = self.net(x)\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss = self.shared_calc_loss(x, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.cpu()))\n",
    "        return loss\n",
    "\n",
    "    #     def validation_step(self, batch, batch_idx):\n",
    "    #         pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx):\n",
    "\n",
    "        x, y = batch\n",
    "        test_loss = self.shared_calc_loss(x, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        self.plain_log[\"test_loss\"].append(float(test_loss.cpu()))\n",
    "\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.net.parameters(), lr=self._lr, betas=self._betas\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.951623Z",
     "iopub.status.busy": "2021-04-07T17:33:45.951476Z",
     "iopub.status.idle": "2021-04-07T17:33:45.955776Z",
     "shell.execute_reply": "2021-04-07T17:33:45.955086Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.951606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-04-07T17:33:45.956676Z",
     "iopub.status.busy": "2021-04-07T17:33:45.956529Z",
     "iopub.status.idle": "2021-04-07T17:51:57.453871Z",
     "shell.execute_reply": "2021-04-07T17:51:57.453414Z",
     "shell.execute_reply.started": "2021-04-07T17:33:45.956658Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | net     | ThreeConv | 142 K \n",
      "1 | loss_fn | MSELoss   | 0     \n",
      "--------------------------------------\n",
      "142 K     Trainable params\n",
      "0         Non-trainable params\n",
      "142 K     Total params\n",
      "0.572     Total estimated model params size (MB)\n",
      "/opt/miniconda/envs/pitn/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2467d041351749108a7dcb5971799161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.05s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.13s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.15s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.20s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.07s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.09s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.14s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.03s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.12s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.11s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.77s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.89s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.82s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.80s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.90s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.00s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.78s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.92s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.88s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.88s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.77s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.86s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.89s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.87s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.86s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.83s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.78s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.95s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.91s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.81s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.91s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.83s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.72s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.02s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.02s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.04s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.92s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.10s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.92s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.70s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.85s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.93s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.83s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.96s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.17s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.84s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.14s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.95s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.90s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.13s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.08s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.77s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.85s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.90s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n",
      "Queue is empty: \n",
      "\n",
      "Creating subjects loader with 0 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.90s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.73s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.88s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.13s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.80s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches list is empty.\n",
      "Filling queue from 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.15s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DIQTSystem(channels=channels, downsample_factor=downsample_factor)\n",
    "# Create trainer object. Note: `automatic_optimization` needs to be set to `False` when\n",
    "# manually performing backprop. See\n",
    "# <https://colab.research.google.com/drive/1nGtvBFirIvtNQdppe2xBes6aJnZMjvl8?usp=sharing>\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=max_epochs, progress_bar_refresh_rate=5)\n",
    "\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-04-07T17:52:37.873478Z",
     "iopub.status.busy": "2021-04-07T17:52:37.872976Z",
     "iopub.status.idle": "2021-04-07T17:52:38.362241Z",
     "shell.execute_reply": "2021-04-07T17:52:38.361751Z",
     "shell.execute_reply.started": "2021-04-07T17:52:37.873419Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(848.7994, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(471877.9375, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(19437.3750, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(31135.6836, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(64984.0898, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(37901.9727, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(8604.9336, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(54.3919, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(3525.9443, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(5971.4731, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(4212.4712, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1019.5009, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(887.3729, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(2187.2383, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(908.7343, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(27.7388, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(314.1709, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(429.6877, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(344.4519, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(208.9445, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(87.5313, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(15.2610, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(7.2560, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(44.3620, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(90.9586, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(116.9035, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(93.7604, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(14.8889, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(125.4730, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(14.1034, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(12.1698, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(41.7191, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(50.8127, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(45.9521, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(35.0108, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(24.1766, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(15.8356, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(10.0375, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(6.1570, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(4.3096, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(2.8756, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.9533, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.7374, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.9787, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(2.4271, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(3.0745, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(3.3988, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(3.4515, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(3.6349, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(3.0355, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(2.6666, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(2.2671, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.4835, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.0903, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6178, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5376, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6538, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.9416, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.9462, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.0968, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1902, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.2166, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.9780, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.8701, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5941, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5948, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4101, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3003, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4809, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1887, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2824, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2727, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3524, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3373, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3923, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4676, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3915, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3336, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2315, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4843, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2602, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2372, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1869, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2146, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1786, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2357, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2982, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3300, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4377, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3515, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1994, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2257, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2833, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1827, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3632, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2510, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2143, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1757, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2092, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2029, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2366, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2077, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1862, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1645, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1651, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1674, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2555, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1721, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2282, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1987, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1925, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2142, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2792, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1426, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2142, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1786, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1892, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1972, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2606, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2852, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1732, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2136, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1443, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1974, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1771, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1248, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1797, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1937, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1449, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2057, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4167, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2308, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1906, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1577, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2866, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1733, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2270, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1655, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1842, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1913, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3001, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2176, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1490, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2039, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1931, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2067, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2157, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2178, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1784, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2107, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2220, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2072, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2075, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1697, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1588, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2840, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1872, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1764, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1853, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1822, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(129.0121, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2239, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1805, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2177, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1758, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3641, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2086, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2278, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2943, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2014, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1321, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2107, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1957, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1889, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2149, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2187, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1805, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1667, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1878, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1938, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2012, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1728, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1341, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2122, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1595, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2205, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2070, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1594, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1510, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2252, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1889, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1443, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1902, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1924, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1709, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2146, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1078, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1857, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2003, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2496, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1934, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1886, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1738, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2153, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2752, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1619, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2024, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2079, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1589, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2392, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4193, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1838, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1984, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(128.9373, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2298, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3720, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3524, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2150, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2608, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1835, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1937, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2006, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1651, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1856, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1262, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2159, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1815, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2154, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1871, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1770, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2063, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3751, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2159, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1875, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2608, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2519, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2401, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2452, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1925, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3746, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2465, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1465, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2153, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1605, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1501, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4072, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2067, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3033, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1831, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2034, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3670, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2090, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2282, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2104, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1863, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1631, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1758, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4964, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1379, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1927, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2793, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1754, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1693, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1446, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1659, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1698, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2410, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2301, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2141, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2501, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2132, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2109, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1237, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2551, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1578, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2008, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2376, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1936, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1769, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1880, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1769, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1833, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2191, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1785, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2043, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1927, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2427, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1675, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4515, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1863, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1945, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5513, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1765, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2195, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1484, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3288, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.9177, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1724, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1903, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1663, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5246, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1382, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4562, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1573, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2968, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2521, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1783, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2009, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1739, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3433, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1601, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1877, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3187, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3184, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5105, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1997, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1299, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1974, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1363, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1595, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3121, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5294, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1649, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1376, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1241, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1748, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2219, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1595, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2007, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1525, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1390, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1665, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2402, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1556, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1475, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1794, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1743, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1632, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1831, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1597, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1931, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1393, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2183, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2056, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1966, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1915, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1455, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1760, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1654, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4073, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2329, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1963, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1338, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1941, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1539, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1455, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1626, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1952, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1916, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2294, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4819, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1894, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2029, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2586, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1988, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2060, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1484, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1325, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5370, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2127, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1392, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3538, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1224, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1944, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2163, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1599, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4542, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5367, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2072, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5867, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1913, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1469, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1500, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1706, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2205, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1429, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4300, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3753, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1541, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1280, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1240, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6540, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1668, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5512, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1836, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1958, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1567, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1972, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2104, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1685, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1504, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3781, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1795, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1119, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4226, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1590, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1919, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1562, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3643, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1866, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1191, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1760, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4862, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1674, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3999, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5853, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1802, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1488, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5731, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1362, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1660, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4464, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1692, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1848, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1804, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2184, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1756, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2015, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2089, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5071, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1611, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1908, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1819, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1470, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1561, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1742, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1652, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1615, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4405, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4762, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1728, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3737, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1847, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1874, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4847, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0949, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1954, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2088, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1927, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1810, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4356, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1521, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1887, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2339, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4249, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1863, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1847, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1548, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1799, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1499, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5809, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1795, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1306, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6979, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3903, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1679, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1785, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1277, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1859, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1627, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5126, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3527, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1209, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2292, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3022, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4210, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1947, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2062, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5103, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1440, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5074, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1273, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1652, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4937, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1770, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1807, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2296, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1925, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1850, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4787, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1940, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1443, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1516, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1933, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1570, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1677, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0967, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2540, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.4103, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1974, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1209, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1859, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3945, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.9007, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3360, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1924, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1813, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7940, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1275, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1578, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1875, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1648, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1801, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.8471, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7576, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3067, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1940, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1562, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1635, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5427, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2831, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1194, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1746, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7415, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3672, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1514, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1638, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1392, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7145, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4005, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0963, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1953, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4837, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1414, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1782, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3111, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1589, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1555, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.0754, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1376, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1670, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6922, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3334, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1106, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2593, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1740, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1253, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3226, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1645, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7558, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1234, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2049, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1777, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.8398, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5289, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1480, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3979, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2097, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1757, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1647, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1455, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1743, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2060, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1623, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2290, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1314, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3647, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1189, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1267, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.8790, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1270, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3876, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1789, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1400, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5191, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2220, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2331, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1483, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2659, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3035, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1630, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2780, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1826, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1392, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3599, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1839, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2371, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1433, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2460, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2202, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2329, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2146, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5483, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1395, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1551, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4027, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2734, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.5355, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1285, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2270, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1479, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2413, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1565, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3409, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2215, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1783, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2801, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2993, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5951, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3317, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2179, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1639, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1765, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1753, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1282, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1646, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6871, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1278, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1389, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1793, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1664, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2986, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7451, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1348, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7689, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1640, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1685, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2172, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1629, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6941, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1815, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1647, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3193, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.8586, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1666, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6657, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1070, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7647, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2317, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2719, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3159, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1588, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1410, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3008, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1370, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2269, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1544, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1639, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2001, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1574, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1101, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1734, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1333, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1771, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2062, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3429, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6917, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7906, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1459, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2567, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1269, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1668, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2031, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2239, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.2567, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1408, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1457, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6978, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3009, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1838, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2076, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1262, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2486, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6913, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1366, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3230, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6705, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2537, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.8037, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4413, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0981, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.0146, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1540, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1261, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6911, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7101, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4840, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1235, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1475, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1557, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4048, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7761, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1320, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1713, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.5940, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1359, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1424, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1630, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2008, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1663, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1541, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1690, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1509, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1525, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1999, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1300, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4494, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2395, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3406, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1620, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1565, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7461, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.9551, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1543, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.0537, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7672, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5015, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.6823, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1815, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2411, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1667, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3871, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1849, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1652, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1906, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7380, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.9878, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5989, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1275, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1597, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7089, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.7954, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3318, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4825, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1643, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1762, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1714, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1157, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.3536, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1122, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.8040, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1547, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6911, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1602, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1374, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1159, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1022, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1120, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1071, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2509, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0920, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0748, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0985, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1241, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0941, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2208, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1029, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0991, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1020, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0868, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0937, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1039, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2327, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0731, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1266, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1906, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1119, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1005, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2587, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0962, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1193, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1180, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1185, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0967, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1054, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1193, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1111, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0767, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1336, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1055, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1045, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1124, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0924, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1093, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1012, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0955, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1172, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1463, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0952, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2468, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1425, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1104, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0915, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1319, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0887, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.0880, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1146, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1561, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1111, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1064, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1147, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2058, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0985, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1299, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1416, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1030, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2566, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0931, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1580, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0875, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1584, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1738, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1037, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0746, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1249, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1087, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0881, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1341, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1201, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1748, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1071, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1013, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1112, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1427, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1134, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1092, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0727, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1141, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1364, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1129, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0996, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1250, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1089, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0923, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1367, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1022, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1014, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1200, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2457, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1377, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1206, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0963, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.0849, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2336, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1049, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0982, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1049, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0929, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2423, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1021, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1070, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2037, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2608, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1366, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1310, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0900, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1177, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0984, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1197, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0974, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0860, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1212, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1032, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1110, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1288, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.2404, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1253, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1183, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1193, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1571, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0884, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0975, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1623, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1252, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1020, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1205, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1415, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0957, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0998, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0674, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2293, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2255, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0968, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1106, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1022, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1741, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1237, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1106, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1020, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0953, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0939, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1229, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1362, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1183, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1030, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1048, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1016, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1050, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2441, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0854, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2312, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2356, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1045, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1066, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0882, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1027, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0954, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1049, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1073, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1119, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1019, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1281, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2302, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2146, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1462, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1698, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0917, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1137, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0900, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0882, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0883, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1146, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1057, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1148, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1032, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1116, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1268, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1597, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0936, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0923, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1652, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0874, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1009, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1002, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2112, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1736, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1239, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0888, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(1.1435, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0930, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1267, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1222, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0883, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1682, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0632, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1112, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0888, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1128, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0879, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1002, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0755, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0856, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1157, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0929, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1383, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0874, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1177, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1001, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0680, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1179, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1975, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0904, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1814, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1050, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  ...],\n",
       " 'val_loss': [],\n",
       " 'test_loss': []}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.plain_log[\"train_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test samplers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "11b1253407964b00bae2e177b35742e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2467d041351749108a7dcb5971799161": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c2c44d14095744f6815e88c9241f0803",
        "IPY_MODEL_fda6e646606541c6a54f7eb727b890d8",
        "IPY_MODEL_a87e5783e9d040eb982ac2adac9619b1"
       ],
       "layout": "IPY_MODEL_ec9ce66924b146da8d398a9d9a30b487"
      }
     },
     "285062ef73ba49208f8ae93fe64cd999": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "31b98b680c8546e18694489e9a15351b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "64e66521d538487ea0880681f47753a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "761fbc2521a546b6bd579b1800881584": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "7e85393aa2c04318b8454959ba2c12be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a87e5783e9d040eb982ac2adac9619b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_11b1253407964b00bae2e177b35742e0",
       "style": "IPY_MODEL_31b98b680c8546e18694489e9a15351b",
       "value": " 1500/1500 [01:48&lt;00:00, 13.77it/s, loss=13, v_num=22]"
      }
     },
     "c2c44d14095744f6815e88c9241f0803": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_64e66521d538487ea0880681f47753a4",
       "style": "IPY_MODEL_7e85393aa2c04318b8454959ba2c12be",
       "value": "Epoch 9: 100%"
      }
     },
     "ec9ce66924b146da8d398a9d9a30b487": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "fda6e646606541c6a54f7eb727b890d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_761fbc2521a546b6bd579b1800881584",
       "max": 1500,
       "style": "IPY_MODEL_285062ef73ba49208f8ae93fe64cd999",
       "value": 1500
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
