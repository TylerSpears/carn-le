{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24056d6f-f342-44a6-a26e-32737ba04299",
   "metadata": {},
   "source": [
    "# Deconvolution and PSF Estimation from the Richardson-Lucy Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32521f47-beb3-4cc1-867c-a7265823902c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e64965d-6032-46dd-a257-c680c720533f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f915e00-8213-4cf1-8291-1db7e8389f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import ants\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dipy.viz\n",
    "import dipy.viz.regtools\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import mpl_toolkits\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython\n",
    "\n",
    "# Try importing GPUtil for printing GPU specs.\n",
    "# May not be installed if using CPU only.\n",
    "try:\n",
    "    import GPUtil\n",
    "except ImportError:\n",
    "    warnings.warn(\"WARNING: Package GPUtil not found, cannot print GPU specs\")\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, Markdown\n",
    "import ipyplot\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "import box\n",
    "from box import Box\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, edgeitems=2, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(\n",
    "    sci_mode=False, edgeitems=2, threshold=100, linewidth=88, profile=\"short\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21972cc-4e9c-4d04-91a9-0a69f7eff885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = f\"direnv exec {os.getcwd()} /usr/bin/env\"\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece95d1-a870-4c68-be94-dfd93ed6332e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-specific scripts\n",
    "# It's easier to import it this way rather than make an entirely new package, due to\n",
    "# conflicts with local packages and anaconda installations.\n",
    "# You made me do this, poor python package management!!\n",
    "if \"PROJECT_ROOT\" in os.environ:\n",
    "    lib_location = str(Path(os.environ[\"PROJECT_ROOT\"]).resolve())\n",
    "else:\n",
    "    lib_location = str(Path(\"../../../\").resolve())\n",
    "if lib_location not in sys.path:\n",
    "    sys.path.insert(0, lib_location)\n",
    "import lib as pitn\n",
    "\n",
    "# Include the top-level lib module along with its submodules.\n",
    "%aimport lib\n",
    "# Grab all submodules of lib, not including modules outside of the package.\n",
    "includes = list(\n",
    "    filter(\n",
    "        lambda m: m.startswith(\"lib.\"),\n",
    "        map(lambda x: x[1].__name__, inspect.getmembers(pitn, inspect.ismodule)),\n",
    "    )\n",
    ")\n",
    "# Run aimport magic with constructed includes.\n",
    "ipy = IPython.get_ipython()\n",
    "ipy.run_line_magic(\"aimport\", \", \".join(includes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d5b91-9d87-4346-95b5-eae6e9b50ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8286d002-ca4a-4476-8d6e-74e5931715bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c4dc6-decb-4bcf-8b98-d33bf0032c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # GPU information\n",
    "    # Taken from\n",
    "    # <https://www.thepythoncode.com/article/get-hardware-system-information-python>.\n",
    "    # If GPUtil is not installed, skip this step.\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        print(\"=\" * 50, \"GPU Specs\", \"=\" * 50)\n",
    "        list_gpus = []\n",
    "        for gpu in gpus:\n",
    "            # get the GPU id\n",
    "            gpu_id = gpu.id\n",
    "            # name of GPU\n",
    "            gpu_name = gpu.name\n",
    "            driver_version = gpu.driver\n",
    "            cuda_version = torch.version.cuda\n",
    "            # get total memory\n",
    "            gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "            gpu_uuid = gpu.uuid\n",
    "            list_gpus.append(\n",
    "                (\n",
    "                    gpu_id,\n",
    "                    gpu_name,\n",
    "                    driver_version,\n",
    "                    cuda_version,\n",
    "                    gpu_total_memory,\n",
    "                    gpu_uuid,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            tabulate(\n",
    "                list_gpus,\n",
    "                headers=(\n",
    "                    \"id\",\n",
    "                    \"Name\",\n",
    "                    \"Driver Version\",\n",
    "                    \"CUDA Version\",\n",
    "                    \"Total Memory\",\n",
    "                    \"uuid\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d110e4-2e74-4bc5-bc4a-7e35d80ca42f",
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2021-11-30T18:21:05.225553+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-90-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 0c2fd3efebc6346e7fa2ae08902e7677240f6ee5\n",
      "\n",
      "skimage    : 0.18.1\n",
      "torch      : 1.10.0\n",
      "ipywidgets : 7.6.3\n",
      "box        : 5.4.1\n",
      "numpy      : 1.20.2\n",
      "dipy       : 1.4.1\n",
      "nibabel    : 3.2.1\n",
      "seaborn    : 0.11.1\n",
      "torchvision: 0.11.1\n",
      "GPUtil     : 1.4.0\n",
      "ants       : 0.2.7\n",
      "sys        : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "scipy      : 1.5.3\n",
      "matplotlib : 3.4.1\n",
      "natsort    : 7.1.1\n",
      "json       : 2.0.9\n",
      "pandas     : 1.2.3\n",
      "IPython    : 7.23.1\n",
      "\n",
      "================================================== GPU Specs ==================================================\n",
      "  id  Name              Driver Version      CUDA Version  Total Memory    uuid\n",
      "----  ----------------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  NVIDIA TITAN RTX  470.82.00                   11.3  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeaf0b7-1ab7-4693-a0d0-96f2615f6b94",
   "metadata": {},
   "source": [
    "## Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74effbbb-2572-4dc9-8cdd-93da7051b83b",
   "metadata": {},
   "source": [
    "### Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18ea53-836d-4eb4-a398-df5c89467a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = Box(default_box=True)\n",
    "\n",
    "# Data params.\n",
    "params.num_channels = 1\n",
    "\n",
    "# Training and testing params.\n",
    "params.batch_size = 128\n",
    "params.num_epochs = 20\n",
    "params.rel_tol = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7471b4f-35d0-4a9a-a496-8caad5f55010",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af80ec0-6819-409e-add9-d3c6bef0f235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up data directories.\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "fmnist_root_dir = data_dir / \"fashion_mnist\"\n",
    "\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b01715-d16e-44cc-99ca-462138aeb49b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(\n",
    "    str(fmnist_root_dir),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    str(fmnist_root_dir),\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030fbab-1467-4a85-ba6e-03854e447c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    skimage.transform.downscale_local_mean(np.asarray(test_data[6][0][0]), (2, 2)),\n",
    "    cmap=\"gray\",\n",
    ")\n",
    "plt.show()\n",
    "plt.imshow(np.asarray(test_data[6][0][0]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdb9f1-a904-4207-a424-df18ce35126a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up dataloaders.\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=params.batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f735af-ef7c-4cdd-815f-171a8ede6207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lr_psf_update_coeff(psf, img_source, img_distort, conv_stride=2):\n",
    "    \"\"\"Update coefficient for the PSF, batched.\n",
    "\n",
    "    psf - shape out_channels x in_channels x H x W\n",
    "    img_source - shape batch x in_channels x H x W\n",
    "    img_distort - similar shape to img_source, but reduced as needed according to\n",
    "        conv_stride and the PSF/kernel size.\n",
    "    \"\"\"\n",
    "\n",
    "    # pytorch \"convolution\" is cross correlation in a signal processing context.\n",
    "    cross_corr = F.conv2d\n",
    "\n",
    "    psf_kernel_size = tuple(psf.shape[-2:])\n",
    "    # Use convolution by transposing the kernel.\n",
    "    actual_vs_pred = img_distort / (\n",
    "        cross_corr(img_source, torch.transpose(psf, -2, -1), stride=conv_stride) + 1e-5\n",
    "    )\n",
    "\n",
    "    batch_size = img_source.shape[0]\n",
    "    img_source = img_source.reshape(1, batch_size, *psf_kernel_size)\n",
    "    # print(img_source.shape)\n",
    "    # print(img_distort.shape)\n",
    "    # print(actual_vs_pred.shape)\n",
    "    grad = cross_corr(\n",
    "        img_source, actual_vs_pred, groups=batch_size\n",
    "    )  # , stride=conv_stride)\n",
    "    grad = grad.reshape(batch_size, 1, *psf_kernel_size)\n",
    "    # print(grad.shape)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10fe97-6f59-487f-b77a-3f00974768f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train & test loop.\n",
    "psf_shape = (3, 3)\n",
    "init_psf = torch.rand(1, 1, *psf_shape)\n",
    "\n",
    "# Track error during training.\n",
    "error_over_epochs = dict()\n",
    "\n",
    "tol_reached = False\n",
    "psf = init_psf\n",
    "with torch.no_grad():\n",
    "    for epoch in range(params.num_epochs):\n",
    "        error_over_epochs[epoch] = list()\n",
    "        for batch in train_dataloader:\n",
    "            source_img = batch[0]\n",
    "\n",
    "            source_patch = F.unfold(source_img, kernel_size=psf_shape, stride=psf_shape)\n",
    "            source_patch = source_patch.view(-1, 1, *psf_shape)\n",
    "\n",
    "            distort_patch = F.interpolate(\n",
    "                source_patch,\n",
    "                scale_factor=(1 / 2, 1 / 2),\n",
    "                mode=\"area\",\n",
    "                recompute_scale_factor=False,\n",
    "            )\n",
    "            # distort_patch = F.pad(distort_patch, (1, 1, 1, 1))\n",
    "            psf_update = lr_psf_update_coeff(\n",
    "                psf, source_patch, distort_patch, conv_stride=2\n",
    "            )\n",
    "            psf_ip1 = list(functools.reduce(lambda x, y: x * y, psf_update, psf[0]))[-1]\n",
    "            psf_ip1 = psf_ip1.view(*psf.shape)\n",
    "            # avg_psf_update = psf_update.mean(dim=(0, 1))[None, ]\n",
    "            # psf_ip1 = psf * avg_psf_update\n",
    "\n",
    "            try:\n",
    "                mse = F.mse_loss(psf, psf_ip1).item()\n",
    "                if np.isnan(mse) or np.isinf(mse):\n",
    "                    raise RuntimeError(f\"ERROR: Invalid MSE value {mse}\")\n",
    "            except RuntimeError as e:\n",
    "                print(\"PSF_i and PSF_i+1 MSE: \", mse)\n",
    "                plt.matshow(psf[0, 0].cpu().numpy())\n",
    "                plt.axis(\"off\")\n",
    "                plt.colorbar()\n",
    "                raise e\n",
    "                # break\n",
    "            error_over_epochs[epoch].append(mse)\n",
    "\n",
    "            psf = psf_ip1\n",
    "\n",
    "plt.matshow(psf[0, 0].cpu().numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1563e8d-7879-43cb-a822-3a2d3d683981",
   "metadata": {},
   "source": [
    "### Autograd Deconvolution Kernel with SGD and Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597f44d-01ed-4259-82a7-f8f45471f723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = torch.randn(3, 4, 1, requires_grad=True)\n",
    "# z = torch.randn(3, 4, 1, requires_grad=False)\n",
    "# sgd = torch.optim.SGD([x], 0.01)\n",
    "# y = x / z\n",
    "# old_x = x.clone()\n",
    "# loss = y.sum()\n",
    "# sgd.zero_grad()\n",
    "# loss.backward()\n",
    "# sgd.step()\n",
    "\n",
    "# y = x / z\n",
    "# loss = y.sum()\n",
    "# sgd.zero_grad()\n",
    "# loss.backward()\n",
    "# sgd.step()\n",
    "# print((x - old_x)[0, 0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1409437-0f01-43b2-91fd-adf8dd52bd46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train & test loop.\n",
    "psf_shape = (5, 5)\n",
    "psf = torch.rand(1, 1, *psf_shape, requires_grad=True)\n",
    "init_psf = psf.clone()\n",
    "optim = torch.optim.SGD(\n",
    "    [\n",
    "        psf,\n",
    "    ],\n",
    "    lr=0.01,\n",
    ")\n",
    "print(psf)\n",
    "# Track error during training.\n",
    "error_over_epochs = dict()\n",
    "\n",
    "tol_reached = False\n",
    "count = 0\n",
    "for epoch in range(params.num_epochs):\n",
    "    error_over_epochs[epoch] = list()\n",
    "    for batch in train_dataloader:\n",
    "        source_img = batch[0]\n",
    "\n",
    "        distort_img = F.interpolate(\n",
    "            source_img,\n",
    "            scale_factor=(1 / 2, 1 / 2),\n",
    "            mode=\"area\",\n",
    "            recompute_scale_factor=False,\n",
    "        )\n",
    "        distort_img.requires_grad_(False)\n",
    "\n",
    "        padded_distorted = F.interpolate(\n",
    "            distort_img,\n",
    "            scale_factor=(2, 2),\n",
    "            mode=\"nearest\",\n",
    "            recompute_scale_factor=False,\n",
    "        )\n",
    "        # padded_distorted = torch.zeros_like(source_img)\n",
    "        # padded_distorted[..., ::2, ::2] = distort_img\n",
    "        recovered = F.conv2d(F.pad(padded_distorted, (2, 2, 2, 2)), psf)\n",
    "        loss = F.mse_loss(recovered, source_img)\n",
    "        # Update the PSF with gradients.\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        # print(loss)\n",
    "        optim.step()\n",
    "\n",
    "        error_over_epochs[epoch].append(loss.item())\n",
    "        # if count >= 20:\n",
    "        #     break\n",
    "\n",
    "        # source_patch = F.unfold(source_img, kernel_size=psf_shape, stride=psf_shape)\n",
    "        # source_patch = source_patch.view(-1, 1, *psf_shape)\n",
    "print(psf)\n",
    "print(torch.abs(psf - init_psf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fce2ac-030e-4920-95ae-d7ea27f9fcf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(list(itertools.chain.from_iterable(error_over_epochs.values())))\n",
    "print(torch.median(torch.as_tensor(list(itertools.chain.from_iterable(error_over_epochs.values())))).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd593b24-3453-488d-89a6-b0b987aba151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=params.batch_size, shuffle=False\n",
    ")\n",
    "viz_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "losses = list()\n",
    "with torch.no_grad():\n",
    "\n",
    "    viz_test_samples = Box(source=list(), observed=list(), pred=list())\n",
    "    num_viz_samples = 7\n",
    "    i_viz_sample = 0\n",
    "    for batch in viz_loader:\n",
    "        source_img = batch[0]\n",
    "\n",
    "        distort_img = F.interpolate(\n",
    "            source_img,\n",
    "            scale_factor=(1 / 2, 1 / 2),\n",
    "            mode=\"area\",\n",
    "            recompute_scale_factor=False,\n",
    "        )\n",
    "\n",
    "        padded_distorted = F.interpolate(\n",
    "            distort_img,\n",
    "            scale_factor=(2, 2),\n",
    "            mode=\"nearest\",\n",
    "            recompute_scale_factor=False,\n",
    "        )\n",
    "        recovered = F.conv2d(F.pad(padded_distorted, (2, 2, 2, 2)), psf)\n",
    "\n",
    "        viz_test_samples.source.append(source_img[0])\n",
    "        viz_test_samples.observed.append(\n",
    "            F.interpolate(\n",
    "                distort_img,\n",
    "                scale_factor=(2, 2),\n",
    "                mode=\"nearest\",\n",
    "                recompute_scale_factor=False,\n",
    "            )[0]\n",
    "        )\n",
    "        viz_test_samples.pred.append(recovered[0])\n",
    "\n",
    "        i_viz_sample += 1\n",
    "        if i_viz_sample >= num_viz_samples:\n",
    "            break\n",
    "\n",
    "    for batch in test_loader:\n",
    "        source_img = batch[0]\n",
    "\n",
    "        distort_img = F.interpolate(\n",
    "            source_img,\n",
    "            scale_factor=(1 / 2, 1 / 2),\n",
    "            mode=\"area\",\n",
    "            recompute_scale_factor=False,\n",
    "        )\n",
    "\n",
    "        padded_distorted = F.interpolate(\n",
    "            distort_img,\n",
    "            scale_factor=(2, 2),\n",
    "            mode=\"nearest\",\n",
    "            recompute_scale_factor=False,\n",
    "        )\n",
    "        recovered = F.conv2d(F.pad(padded_distorted, (2, 2, 2, 2)), psf)\n",
    "        loss = F.mse_loss(recovered, source_img)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "total_loss = torch.as_tensor(losses).mean()\n",
    "print(total_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af79be-60c9-4db5-a391-e7784738e104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz_grid = torchvision.utils.make_grid(\n",
    "    list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [viz_test_samples.source, viz_test_samples.observed, viz_test_samples.pred]\n",
    "        )\n",
    "    ),\n",
    "    nrow=7,\n",
    ")\n",
    "plt.figure(dpi=120)\n",
    "\n",
    "# plt.imshow(viz_grid.T, cmap='gray')\n",
    "plt.imshow(torch.movedim(viz_grid, 0, -1).cpu().numpy(), cmap=\"gray\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d642f08-08d8-49f5-9680-df5dd5a032d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458f5f2-37aa-4c36-b6c3-5ca54752fa10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from scipy import misc\n",
    "from scipy import fftpack\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "img = misc.face()[:, :, 0]\n",
    "print(img.shape)\n",
    "kernel = np.ones((21, 21)) / 21 ** 2\n",
    "print(kernel.shape)\n",
    "sz = (\n",
    "    img.shape[0] - kernel.shape[0],\n",
    "    img.shape[1] - kernel.shape[1],\n",
    ")  # total amount of padding\n",
    "print(sz)\n",
    "kernel = np.pad(\n",
    "    kernel, (((sz[0] + 1) // 2, sz[0] // 2), ((sz[1] + 1) // 2, sz[1] // 2)), \"constant\"\n",
    ")\n",
    "print(kernel.shape)\n",
    "kernel = fftpack.ifftshift(kernel)\n",
    "print(kernel.shape)\n",
    "filtered = np.real(fftpack.ifft2(fftpack.fft2(img) * fftpack.fft2(kernel)))\n",
    "plt.imshow(filtered, vmin=0, vmax=255)\n",
    "plt.show()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909ae7e-34f5-4635-90b5-5193e7dc6f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = 256\n",
    "print(size ** 2)\n",
    "noise = np.random.randn(size, size)\n",
    "plt.matshow(noise)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "N = fftpack.fft2(noise)\n",
    "plt.matshow(np.abs(N) ** 2)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "np.mean(np.abs(N) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1e5f4-57fa-4233-b7ea-d219a19cbc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.abs(N))\n",
    "print(np.sqrt(N.real ** 2 + N.imag ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969a40a-92ad-480a-a4d1-1f4afe9c7475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
